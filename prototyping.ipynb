{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "import qplib as qp\n",
    "from qplib import log, na, nk, num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_32940\\2998472621.py:93: UserWarning: registration of accessor <class '__main__.IndexQuery'> under name 'q' for type <class 'pandas.core.indexes.base.Index'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_index_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_32940\\2998472621.py:223: UserWarning: registration of accessor <class '__main__.SeriesQuery'> under name 'q' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_series_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_32940\\2998472621.py:349: UserWarning: registration of accessor <class '__main__.DataFrameQuery'> under name 'q' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_32940\\2998472621.py:1028: UserWarning: registration of accessor <class '__main__.DataFrameQueryInteractiveMode'> under name 'qi' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('qi')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_60fb1_row0_col0, #T_60fb1_row0_col1, #T_60fb1_row0_col2, #T_60fb1_row0_col3, #T_60fb1_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_60fb1\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_60fb1_level0_row0\" class=\"row_heading level0 row0\" >596</th>\n",
       "      <td id=\"T_60fb1_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_60fb1_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_60fb1_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_60fb1_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_60fb1_row0_col4\" class=\"data row0 col4\" >2024-07-05 14:07:49.539200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244806f4d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2a2d6_row0_col0, #T_2a2d6_row0_col1, #T_2a2d6_row0_col2, #T_2a2d6_row0_col3, #T_2a2d6_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2a2d6\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2a2d6_level0_row0\" class=\"row_heading level0 row0\" >597</th>\n",
       "      <td id=\"T_2a2d6_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_2a2d6_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_2a2d6_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_2a2d6_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_2a2d6_row0_col4\" class=\"data row0 col4\" >2024-07-05 14:07:49.543804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244806fd550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_32940\\2998472621.py:1241: DtypeWarning: Columns (2,3,7,12,16,20,23,47,52,53,61,62,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cards = pd.read_csv('data/cards.csv').format()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_234f1_row0_col0, #T_234f1_row0_col1, #T_234f1_row0_col2, #T_234f1_row0_col3, #T_234f1_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_234f1\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_234f1_level0_row0\" class=\"row_heading level0 row0\" >598</th>\n",
       "      <td id=\"T_234f1_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_234f1_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_234f1_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_234f1_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_234f1_row0_col4\" class=\"data row0 col4\" >2024-07-05 14:07:51.156656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24482a53ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_be5c5_row0_col0, #T_be5c5_row0_col1, #T_be5c5_row0_col2, #T_be5c5_row0_col3, #T_be5c5_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_be5c5\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_be5c5_level0_row0\" class=\"row_heading level0 row0\" >599</th>\n",
       "      <td id=\"T_be5c5_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_be5c5_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_be5c5_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_be5c5_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_be5c5_row0_col4\" class=\"data row0 col4\" >2024-07-05 14:07:51.161664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244839288f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.pd_util import _check_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "from qplib.pd_util import diff as mv_diff\n",
    "\n",
    "\n",
    "\n",
    "from qplib.types import qp_int, qp_float, qp_num, qp_bool, qp_datetime, qp_date, qp_na, qp_nk, qp_yn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_operators1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'bigger_equal': '>=',\n",
    "    'smaller_equal': '<=',\n",
    "    'bigger': '>',\n",
    "    'smaller': '<',\n",
    "    'strict_equal': '==',\n",
    "    'equal': '=',\n",
    "    'regex_match': '~~',\n",
    "    'regex_search': '~',\n",
    "    'strict_contains': '(())',\n",
    "    'contains': '()',\n",
    "\n",
    "    'lambda_condition': '?',\n",
    "    'lambda_condition_col': 'col?',\n",
    "    })\n",
    "_operators2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'is_str': 'is str',\n",
    "    'is_int': 'is int',\n",
    "    'is_float': 'is float',\n",
    "    'is_num': 'is num',\n",
    "    'is_bool': 'is bool',\n",
    "\n",
    "    'is_datetime': 'is datetime',\n",
    "    'is_date': 'is date',\n",
    "\n",
    "    'is_any': 'is any',\n",
    "    'is_na': 'is na',\n",
    "    'is_nk': 'is nk',\n",
    "    'is_yn': 'is yn',\n",
    "    'is_yes': 'is yes',\n",
    "    'is_no': 'is no',\n",
    "    })\n",
    "_operators = qpDict({**_operators1, **_operators2})\n",
    "_operators_only_df = qpDict({\n",
    "    'lambda_condition_col': _operators['lambda_condition_col'],\n",
    "    })\n",
    "\n",
    "_modifiers1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'set_x': ['x=', 'x ='],\n",
    "    'set_col': ['col=', 'col ='],\n",
    "    'set_row': ['row=', 'row ='],\n",
    "    'set_col_tags': ['col#=', 'col# =', 'col #=', 'col # ='],\n",
    "    'set_row_tags': ['row#=', 'row# =', 'row #=', 'row # ='],\n",
    "    })\n",
    "_modifiers2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'to_str': 'to str',\n",
    "    'to_int': 'to int',\n",
    "    'to_float': 'to float',\n",
    "    'to_num': 'to num',\n",
    "    'to_bool': 'to bool',\n",
    "\n",
    "    'to_datetime': 'to datetime',\n",
    "    'to_date': 'to date',\n",
    "\n",
    "    'to_na': 'to na',\n",
    "    'to_nk': 'to nk',\n",
    "    'to_yn': 'to yn',\n",
    "    })\n",
    "_modifiers = qpDict({**_modifiers1, **_modifiers2})\n",
    "_modifiers_only_df = qpDict({\n",
    "    'set_col': _modifiers['set_col'],\n",
    "    'set_row': _modifiers['set_row'],\n",
    "    'set_col_tags': _modifiers['set_col_tags'],\n",
    "    'set_row_tags': _modifiers['set_row_tags'],\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_index_accessor('q')\n",
    "class IndexQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Indices.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, idx: pd.Index):\n",
    "        idx.qp._operators = _operators\n",
    "        idx.qp._operators_only_df = _operators_only_df\n",
    "        idx.qp._modifiers = _modifiers\n",
    "        idx.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.idx = idx \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_index(self.idx)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        idx = self.idx\n",
    "        idx.qp = self.idx.qp\n",
    "        idx.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in idx])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter index', 'modify index'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter index':\n",
    "                ast = _parse_expression(idx, expression, 'filter index', verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(idx, condition, _operators, verbosity, index=idx)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                        log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='idx.q', input=idx.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify index':\n",
    "                ast = _parse_expression_modify(idx, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = idx.to_series()\n",
    "                    se.qp = idx.qp\n",
    "                    idx = pd.Index(_apply_modification(se, index_expression, modification, verbosity, index=idx))\n",
    "                    idx.qp = self.idx.qp\n",
    "        \n",
    "\n",
    "\n",
    "        idx_filtered = idx[index_expression]\n",
    "        idx_filtered.qp = idx.qp\n",
    "\n",
    "        return idx_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_series_accessor('q')\n",
    "class SeriesQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Series.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, se: pd.Series):\n",
    "        se.qp._operators = _operators\n",
    "        se.qp._operators_only_df = _operators_only_df\n",
    "        se.qp._modifiers = _modifiers\n",
    "        se.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.se = se \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_series(self.se)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        se = copy.deepcopy(self.se)\n",
    "        se.qp = self.se.qp\n",
    "        se.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in se])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter series', 'modify series'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter series':\n",
    "                ast = _parse_expression(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(se, condition, _operators, verbosity, series=se)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                    log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='se.q', input=se.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify series':\n",
    "                ast = _parse_expression_modify(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = _apply_modification(se, index_expression, modification, verbosity, series=se)\n",
    "                    se.qp = self.se.qp\n",
    "\n",
    "\n",
    "        se_filtered = se[index_expression]\n",
    "        se_filtered.qp = se.qp\n",
    "        return se_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data and metadata in pandas DataFrames.\n",
    "\n",
    "    each query consists of 3 string expressions, any of which can be left empty:\n",
    "        1. column filter: '=col1', '!=col2', '()1 // ()2'\n",
    "        2. row filter: 'is date', 'is int && >0', '? len(str(x)) > 5'\n",
    "        3. (meta-)data modification: 'x= str(x)', 'col#= integer column', 'row#= positive'\n",
    "\n",
    "    eg.: df.q('=col1', 'is int && >0', 'row#= positive')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "        col=: set whole column to a value\n",
    "        row=: set whole row to a value\n",
    "        col#=: tag columns\n",
    "        row#=: tag rows\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        _check_df(df)\n",
    "        self.df = df\n",
    "        self.df.qp._operators = _operators\n",
    "        self.df.qp._modifiers = _modifiers\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self,\n",
    "            *expressions,  #string expressions for filtering and modifying data\n",
    "            diff=None,  #[None, 'mix', 'old', 'new', 'new+']\n",
    "            max_cols=200,  #maximum number of columns to display. None: show all\n",
    "            max_rows=20,  #maximum number of rows to display. None: show all\n",
    "            inplace=True,  #make modifications inplace or just return a new dataframe\n",
    "            verbosity=3,  #verbosity level for logging. 0: no logging, 1: errors, 2: warnings, 3: info, 4: debug\n",
    "            **kwargs\n",
    "            ):\n",
    "\n",
    "        ###########################################\n",
    "        #                  setup                  #\n",
    "        ###########################################\n",
    "\n",
    "        #input string for logging\n",
    "        input_str = \".q(\"\n",
    "        for i,expression in enumerate(expressions):\n",
    "            if (i+1)%3 == 1:\n",
    "                input_str += f\"\\n\\t{expression !r},\"\n",
    "            else:\n",
    "                input_str += f\" {expression !r},\"\n",
    "   \n",
    "        if diff is not None:\n",
    "            input_str += f\"\\n\\tdiff='{diff}',\"\n",
    "        if max_cols is not None:\n",
    "            input_str += f\"\\n\\tmax_cols={max_cols},\"\n",
    "        if max_rows is not None:\n",
    "            input_str += f\"\\n\\tmax_rows={max_rows},\"\n",
    "        \n",
    "        input_str += f\"\\n\\tinplace={inplace},\"\n",
    "        input_str += f\"\\n\\tverbosity={verbosity},\"\n",
    "\n",
    "        for kwarg in kwargs:\n",
    "            input_str += f\"\\n\\t{kwarg}='{kwargs[kwarg]}'\"\n",
    "\n",
    "        self.df.qp._input = input_str + \"\\n\\t)\"\n",
    "\n",
    "\n",
    "    \n",
    "        if inplace is False:\n",
    "            df = self.df.copy()\n",
    "        else:\n",
    "            df = self.df\n",
    "            \n",
    "        df.qp = self.df.qp\n",
    "\n",
    "        \n",
    "\n",
    "        #inserting metadata row at the top, sadly a bit hacky\n",
    "        #because there does not seem to be an inplace function for that\n",
    "        if '#' not in df.index:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a row named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata row now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df_old = df.copy()\n",
    "            index_old = df.index\n",
    "            index_new = pd.Index(['#', *index_old])\n",
    "            \n",
    "            df.loc['#'] = ''\n",
    "            df.set_index(index_new, inplace=True)\n",
    "            df.loc[index_old, :] = df_old\n",
    "            df.loc['#'] = ''\n",
    "\n",
    "        #inserting metadata column at the start\n",
    "        if '#' not in df.columns:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a column named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata column now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df.insert(0, '#', '')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        ###########################################\n",
    "        #               run queries               #\n",
    "        ###########################################\n",
    "\n",
    "        cols_filtered = cols_filtered_condition = pd.Index([True for col in df.columns])\n",
    "        rows_filtered = rows_filtered_condition = rows_filtered_col = pd.Index([True for row in df.index])\n",
    "        \n",
    "\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['col', 'row', 'modify'][i_expression%3]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            #filter columns\n",
    "            if expression_type == 'col':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    if condition['by_tag'] == 'row or col metadata':\n",
    "                        cols_filtered_new = _apply_condition(df.loc['#'], condition, _operators, verbosity, df=df)\n",
    "                    else:\n",
    "                        cols_filtered_new = _apply_condition(df.columns, condition, _operators, verbosity, df=df)\n",
    "\n",
    "                    cols_filtered_condition = _update_index(cols_filtered_condition, cols_filtered_new, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                cols_filtered = _update_index(cols_filtered, cols_filtered_condition, ast['connector'], i_expression, verbosity=verbosity)\n",
    "\n",
    "                if cols_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no columns fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            #filter rows\n",
    "            elif expression_type == 'row':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    for i_col,col in enumerate(df.columns[cols_filtered_condition][1:]):  #ignore metadata column\n",
    "                        if condition['by_tag'] == 'row or col metadata':\n",
    "                            rows_filtered_new = _apply_condition(df['#'], condition, _operators, verbosity, df=df)\n",
    "                        else:\n",
    "                            rows_filtered_new = _apply_condition(df[col], condition, _operators, verbosity, df=df)\n",
    "\n",
    "                        rows_filtered_col = _update_index(rows_filtered_col, rows_filtered_new, condition['which_cols'], i_col, verbosity=verbosity)\n",
    "                    rows_filtered_condition = _update_index(rows_filtered_condition, rows_filtered_col, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                rows_filtered = _update_index(rows_filtered, rows_filtered_condition, ast['connector'], i_expression-1, verbosity=verbosity)\n",
    "\n",
    "                if rows_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no rows fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "\n",
    "\n",
    "            #modify data\n",
    "            elif expression_type == 'modify':\n",
    "                cols_filtered_no_metadata = [col for col in df.columns[cols_filtered] if not col.startswith('#')]\n",
    "                rows_filtered_no_metadata = [row for row in df.index[rows_filtered] if row != '#']\n",
    "\n",
    "                ast = _parse_expression_modify(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                            \n",
    "                    #tag columns\n",
    "                    if modification['modifier'] in _modifiers['set_col_tags']:\n",
    "                        df.loc['#', cols_filtered_no_metadata] = df.loc['#', cols_filtered_no_metadata].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #tag rows\n",
    "                    elif modification['modifier'] in _modifiers['set_row_tags']:\n",
    "                        df.loc[rows_filtered_no_metadata, '#'] = df.loc[rows_filtered_no_metadata, '#'].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #modify filtered data\n",
    "                    else:\n",
    "                        df.loc[:, :] = _apply_modification_df(df, rows_filtered_no_metadata, cols_filtered_no_metadata, modification, verbosity).loc[:, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################\n",
    "        #            display settings            #\n",
    "        ##########################################\n",
    "   \n",
    "        df_filtered = df.loc[rows_filtered, cols_filtered]\n",
    "        df_filtered.qp = self.df.qp\n",
    "    \n",
    "        if diff is None:\n",
    "\n",
    "            cols_num = len(df.columns[cols_filtered])\n",
    "            rows_num = len(df.index[rows_filtered])\n",
    "\n",
    "            if verbosity >= 2:\n",
    "                if max_cols is not None and max_cols < cols_num:\n",
    "                    log(f'showing {max_cols} out of {cols_num} columns', level='warning', source='df.q', input=df.qp._input)\n",
    "                if max_rows is not None and max_rows < rows_num:\n",
    "                    log(f'showing {max_rows} out of {rows_num} rows', level='warning', source='df.q', input=df.qp._input)\n",
    " \n",
    "            pd.set_option('display.max_columns', max_cols)\n",
    "            pd.set_option('display.max_rows', max_rows)\n",
    "            pd.set_option('display.min_rows', max_rows)\n",
    "\n",
    "            return df_filtered\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            #show difference before and after filtering\n",
    "            result = qp.diff(\n",
    "                df_filtered, self.df, show=diff,\n",
    "                max_cols=max_cols, max_rows=max_rows,\n",
    "                verbosity=verbosity)  \n",
    "            return  result\n",
    "\n",
    "\n",
    "\n",
    "def _parse_expression(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'connector': None,\n",
    "        'conditions': [],\n",
    "        }\n",
    "    \n",
    "    if expression[:2] not in ['&&', '//', '>>']:\n",
    "        expression = '>>' + expression\n",
    "\n",
    "    ast['connector'] = expression[:2]\n",
    "\n",
    "\n",
    "    expressions = re.split('(&&|//|>>)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {'expression': expressions[ind], 'mode': mode}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&', '//', '>>']:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if expressions[ind-1] == '&&':  #and\n",
    "            condition['condition_connector'] = '&&'\n",
    "        elif expressions[ind-1] == '//':  #inclusive or\n",
    "            condition['condition_connector'] = '//'\n",
    "        elif expressions[ind-1] == '>>':  #reset\n",
    "            condition['condition_connector'] = '>>'\n",
    "\n",
    "        \n",
    "        #row conditions also specify in which cols the condition is applied. default: any\n",
    "        if mode == 'row':\n",
    "            if condition_str.startswith('any'):\n",
    "                condition['which_cols'] = 'any'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            elif condition_str.startswith('all'):\n",
    "                condition['which_cols'] = 'all'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            else:\n",
    "                condition['which_cols'] = 'any'\n",
    "\n",
    "\n",
    "        #rows and cols can be filtered by metadata\n",
    "        if condition_str.startswith('#'):\n",
    "            condition['by_tag'] = 'row or col metadata'\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['by_tag'] = False\n",
    "\n",
    "        #wip\n",
    "        # if condition_str.startswith('x#'):\n",
    "        #     condition['by_tag_value'] = 'value metadata'\n",
    "        #     condition_str = condition_str[1:].lstrip()\n",
    "        # else:\n",
    "        #     condition['by_tag_value'] = False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #should the condition be negated. default: False\n",
    "        if condition_str.startswith('!'):\n",
    "            condition['negate'] = True\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['negate'] = False\n",
    "\n",
    "\n",
    "        #operator for condition. default: =\n",
    "        for operator in _operators.values_flat():\n",
    "            if condition_str.startswith(operator):\n",
    "                condition['operator'] = operator\n",
    "                condition_str = condition_str[len(operator):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'operator' not in condition:\n",
    "            if verbosity >= 3:\n",
    "                log(f'no operator found in condition \"{condition_str}\". Using default operator \"=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['operator'] = '='\n",
    "\n",
    "\n",
    "        if mode in ['filter series', 'filter index'] and condition['operator'] in _operators_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "        \n",
    "        if condition['operator'] in _operators2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #value for comparison\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['conditions'].append(condition)\n",
    "\n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "        \n",
    "    return ast\n",
    "\n",
    "def _parse_expression_modify(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'modifications': [],\n",
    "        }\n",
    "    \n",
    "\n",
    "    expressions = re.split('(&&)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&']:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #modifier to use. default: \"set x:\"\n",
    "        for modifier in _modifiers.values_flat():\n",
    "            if condition_str.startswith(modifier):\n",
    "                condition['modifier'] = modifier\n",
    "                condition_str = condition_str[len(modifier):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'modifier' not in condition:\n",
    "            if verbosity > 3:\n",
    "                log(f'no modifier found in condition \"{condition_str}\". Using default modifier \"x=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['modifier'] = 'x='\n",
    "\n",
    "        if mode in ['modify series', 'modify index'] and condition['modifier'] in _modifiers_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "\n",
    "        if condition['modifier'] in _modifiers2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #expression used for modification\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['modifications'].append(condition)\n",
    "        \n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "    \n",
    "    return ast\n",
    "\n",
    "\n",
    "def _apply_condition(pd_object, condition, operators, verbosity=3, df=None, series=None, index=None):\n",
    "    \"\"\"\n",
    "    filters a pandas object using a query condition\n",
    "    \"\"\"\n",
    "\n",
    "    value = condition['value']\n",
    "\n",
    "    if isinstance(pd_object, pd.Index):\n",
    "        pd_object = pd_object.to_series()\n",
    "\n",
    "    \n",
    "    match condition['operator']:\n",
    "        #numeric comparison\n",
    "        case operators.bigger_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') >= pd.to_numeric(value)\n",
    "        case operators.smaller_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') <= pd.to_numeric(value)\n",
    "        case operators.bigger:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') > pd.to_numeric(value)\n",
    "        case operators.smaller:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') < pd.to_numeric(value)\n",
    "        \n",
    "        \n",
    "        #regex comparison\n",
    "        case operators.regex_match:\n",
    "            filtered = pd_object.astype(str).str.fullmatch(value) \n",
    "        case operators.regex_search:\n",
    "            filtered = pd_object.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "        #string equality comparison\n",
    "        case operators.strict_equal:\n",
    "            filtered = pd_object.astype(str) == value\n",
    "        case operators.equal:\n",
    "            value_lenient = [value]\n",
    "            try:\n",
    "                value_lenient.append(str(float(value)))\n",
    "                value_lenient.append(str(int(float(value))))\n",
    "            except:\n",
    "                value_lenient.append(value.lower())\n",
    "            filtered = pd_object.astype(str).str.lower().isin(value_lenient)\n",
    "        \n",
    "        #substring comparison\n",
    "        case operators.strict_contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=True, regex=False)\n",
    "        case operators.contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "\n",
    "        #lambda function\n",
    "        case operators.lambda_condition:\n",
    "            filtered_no_metadata = pd_object.iloc[1:].apply(lambda x, df=df.iloc[1:,1:], series=series, index=index, pd=pd, np=np: eval(value))\n",
    "            filtered = pd.concat([pd.Series({'#': True}), filtered_no_metadata], axis=0)\n",
    "        case operators.lambda_condition_col:\n",
    "            filtered_no_metadata = eval(value, {'col': pd_object.iloc[1:], 'df': df.iloc[1:,1:], 'pd': pd, 'np': np, 'qp': qp})\n",
    "            filtered = pd.concat([pd.Series({'#': True}), filtered_no_metadata], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        #type checks\n",
    "        case operators.is_bool:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, bool))\n",
    "        case operators.is_str:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, str))\n",
    "        case operators.is_int:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, int))\n",
    "        case operators.is_float:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, float))\n",
    "        case operators.is_num:\n",
    "            filtered = pd_object.apply(lambda x: qp_num(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_date:\n",
    "            filtered = pd_object.apply(lambda x: qp_date(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_datetime:\n",
    "            filtered = pd_object.apply(lambda x: qp_datetime(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_any:\n",
    "            filtered = pd_object.apply(lambda x: True)\n",
    "        case operators.is_na:\n",
    "            filtered = pd_object.apply(lambda x: qp_na(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_nk:\n",
    "            filtered = pd_object.apply(lambda x: qp_nk(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yn:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yes:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', yes=1)) == 1\n",
    "        case operators.is_no:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', no=0)) == 0\n",
    "\n",
    "        case _:\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" is not implemented', level='error', source='_apply_condition()', input=pd_object.qp._input)\n",
    "            filtered = None\n",
    "\n",
    "\n",
    "    if condition['negate']:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    if condition['mode'] in ['col', 'row']:\n",
    "        filtered.iloc[0] = True  #metadata row/column should always be included\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def _apply_modification(pd_object, indices, modification, verbosity=3, series=None, index=None):\n",
    "    modifiers = pd_object.qp._modifiers\n",
    "\n",
    "    #data modification\n",
    "    if modification['modifier'] in modifiers['set_x']:\n",
    "        pd_object[indices] = pd_object[indices].map(lambda x, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "\n",
    "    #type conversion\n",
    "    elif modification['modifier'] == modifiers['to_str']:\n",
    "        pd_object[indices] = pd_object[indices].map(str)\n",
    "    elif modification['modifier'] == modifiers['to_int']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_int)\n",
    "    elif modification['modifier'] == modifiers['to_float']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_float)\n",
    "    elif modification['modifier'] == modifiers['to_num']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_num)\n",
    "    elif modification['modifier'] == modifiers['to_bool']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_bool)\n",
    "    \n",
    "    elif modification['modifier'] == modifiers['to_date']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_date)\n",
    "    elif modification['modifier'] == modifiers['to_datetime']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_datetime)\n",
    "    elif modification['modifier'] == modifiers['to_na']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_na)\n",
    "    elif modification['modifier'] == modifiers['to_nk']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_nk)\n",
    "    elif modification['modifier'] == modifiers['to_yn']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_yn)\n",
    "\n",
    "    return pd_object\n",
    "\n",
    "def _apply_modification_df(df, rows, cols, modification, verbosity=3):\n",
    "    modifiers = df.qp._modifiers\n",
    "\n",
    "    if pd.__version__ >= '2.1.0':\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_yn)\n",
    "\n",
    "    else:\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_yn) \n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def _update_index(values, values_new, connector, i, verbosity=3):\n",
    "    if i == 0:\n",
    "        values = values_new\n",
    "    elif connector == '>>':\n",
    "        values = values_new\n",
    "    elif connector in ['&&', 'all']:\n",
    "        values &= values_new\n",
    "    elif connector in ['//', 'any']:\n",
    "        values |= values_new\n",
    "    else:\n",
    "        if verbosity >= 1:\n",
    "            log(f'connector \"{connector}\" is not implemented', level='error', source='_update_index()')\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for df.q() for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self, num_filters=5):\n",
    "        kwargs = {'df': fixed(self.df)}\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #            tab0 queries&diff            #\n",
    "        ###########################################\n",
    "\n",
    "        ui_label_filter_cols = widgets.Label(value='filter columns')\n",
    "        ui_label_filter_rows = widgets.Label(value='filter rows')\n",
    "        ui_label_modify_data = widgets.Label(value='modify data')\n",
    "        ui_expressions = [ui_label_filter_cols, ui_label_filter_rows, ui_label_modify_data]\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(num_filters):\n",
    "            if i == 0:\n",
    "                placeholder_col = '=name'\n",
    "                placeholder_row = '()john'\n",
    "                placeholder_modify = 'x= x.upper() '\n",
    "            elif i == 1:\n",
    "                placeholder_col = '// =age'\n",
    "                placeholder_row = '&& <0 // >120'\n",
    "                placeholder_modify = 'row#= \"implausible age\" '\n",
    "            elif i == 2:\n",
    "                placeholder_col = '// =weight // =height'\n",
    "                placeholder_row = '!is num'\n",
    "                placeholder_modify = 'to num'\n",
    "            else:\n",
    "                placeholder_col = ''\n",
    "                placeholder_row = ''\n",
    "                placeholder_modify = ''\n",
    "            \n",
    "\n",
    "            col = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_col,\n",
    "                options=['=' + col for col in self.df.columns if col != '#'],\n",
    "                )\n",
    "            kwargs[f'col_expression{i}'] = col\n",
    "            ui_expressions.append(col)\n",
    "            \n",
    "            row = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_row,\n",
    "                options=[\n",
    "                    '>0', '<0', '>=0', '<=0',  #numerical comparison\n",
    "                    '=abc', '!=abc', '==AbC', '!==AbC',  #equality checks\n",
    "                    '()abc', '(())AbC',  #substring checks\n",
    "                    '~*a.c', '~~*a.c',  #regex checks\n",
    "                    \n",
    "                    '? len(x) > 3',  #lambda function condition for each value\n",
    "                    'col? col > df[\"age\"]',  #lambda function condition for whole columns\n",
    "\n",
    "                    #type checks\n",
    "                    'is str', 'is int', 'is float', 'is num', 'is bool',\n",
    "                    'is date', 'is datetime',\n",
    "                    'is any', 'is na', 'is nk',\n",
    "                    'is yn', 'is yes', 'is no'\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'row_expression{i}'] = row\n",
    "            ui_expressions.append(row)\n",
    "            \n",
    "            modify = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_modify,\n",
    "                options=[\n",
    "                    'x= x.upper() ', 'col= df[\"ID\"]', 'row= df.loc[0]',  #change data\n",
    "                    'col#= \"tag\" ', 'col#= x + \"tag\" ', 'row#= \"tag\" ', 'row#= x + \"tag\"',  #change metadata\n",
    "\n",
    "                    #change type\n",
    "                    'to str', 'to int', 'to float', 'to num', 'to bool',\n",
    "                    'to date', 'to datetime',\n",
    "                    'to na', 'to nk', 'to yn',\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'modify_expression{i}'] = modify\n",
    "            ui_expressions.append(modify)\n",
    "        \n",
    "\n",
    "        #show differences\n",
    "        ui_diff = widgets.ToggleButtons(\n",
    "            options=[None, 'mix', 'old', 'new', 'new+'],\n",
    "            description='show differences mode:',\n",
    "            tooltips=[\n",
    "                'dont show differences, just show the new (filtered) dataframe.',\n",
    "                'show new (filtered) dataframe plus all the removed (filtered) values from the old dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show old (unfiltered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe but also adds metadata columns with the prefix \"#\". If a value changed, the metadata column contains the old value. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['diff'] = ui_diff\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #              tab1 settings              #\n",
    "        ###########################################\n",
    "\n",
    "        ui_inplace = widgets.ToggleButtons(\n",
    "            options=[True, False],\n",
    "            value=False,\n",
    "            description='make modifications inplace:',\n",
    "            tooltips=[\n",
    "                'make modifications inplace, e.g. change the original dataframe',\n",
    "                'return a new dataframe with the modifications',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['inplace'] = ui_inplace\n",
    "\n",
    "        ui_verbosity = widgets.ToggleButtons(\n",
    "            options=[0, 1, 2, 3, 4],\n",
    "            value=3,\n",
    "            description='verbosity level:',\n",
    "            tooltips=[\n",
    "                'no logging',\n",
    "                'only errors',\n",
    "                'errors and warnings',\n",
    "                'errors, warnings and info',\n",
    "                'errors, warnings, info and debug',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['verbosity'] = ui_verbosity\n",
    "\n",
    "\n",
    "\n",
    "        cols_num = len(self.df.columns)\n",
    "        rows_num = len(self.df.index)\n",
    "        if '#' not in self.df.columns:\n",
    "            cols_num = len(self.df.columns) + 1\n",
    "        if '#' not in self.df.index:\n",
    "            rows_num = len(self.df.index) + 1\n",
    "\n",
    "        ui_max_cols = widgets.IntSlider(\n",
    "            value=200,\n",
    "            min=0,\n",
    "            max=cols_num*2-1,  #*2 because of metadata columns which get added by diff='new+'\n",
    "            description='columns',\n",
    "            )\n",
    "        kwargs['max_cols'] = ui_max_cols\n",
    "\n",
    "        ui_max_rows = widgets.IntSlider(\n",
    "            value=20,\n",
    "            min=0,\n",
    "            max=rows_num,\n",
    "            description='rows',\n",
    "            )\n",
    "        kwargs['max_rows'] = ui_max_rows\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #                tab2 info                #\n",
    "        ###########################################\n",
    "\n",
    "\n",
    "        ui_gridbox = widgets.GridBox(ui_expressions, layout=widgets.Layout(grid_template_columns=\"repeat(3, 330px)\"))   \n",
    "        tab0 = VBox([ui_gridbox, ui_diff])\n",
    "        tab1 = VBox([ui_inplace, ui_verbosity, HBox([ui_max_cols, ui_max_rows])])\n",
    "        ui_tab = widgets.Tab(\n",
    "            children=[tab0, tab1],\n",
    "            titles=['queries', 'settings'],\n",
    "            )\n",
    "        ui = VBox([ui_tab])\n",
    "        display(ui)\n",
    "\n",
    "\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "\n",
    "        display(out)\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "\n",
    "    df = kwargs.pop('df')\n",
    "    expressions = [val for key, val in kwargs.items() if 'expression' in key]\n",
    "\n",
    "\n",
    "    result = df.q(\n",
    "        *expressions,\n",
    "        diff=kwargs['diff'],\n",
    "        max_cols=kwargs['max_cols'],\n",
    "        max_rows=kwargs['max_rows'],\n",
    "        inplace=kwargs['inplace'],\n",
    "        verbosity=kwargs['verbosity'],\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    display(result)\n",
    "    print('input code: ', df.qp._input)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "df = qp.get_df().format()\n",
    "\n",
    "\n",
    "# df.qi()\n",
    "\n",
    "\n",
    "cards = pd.read_csv('data/cards.csv').format()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83f15_row0_col0, #T_83f15_row0_col1, #T_83f15_row0_col2, #T_83f15_row0_col3, #T_83f15_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83f15\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83f15_level0_row0\" class=\"row_heading level0 row0\" >607</th>\n",
       "      <td id=\"T_83f15_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_83f15_row0_col1\" class=\"data row0 col1\" >no operator found in condition \"toughness\". Using default operator \"=\"</td>\n",
       "      <td id=\"T_83f15_row0_col2\" class=\"data row0 col2\" >_parse_expression</td>\n",
       "      <td id=\"T_83f15_row0_col3\" class=\"data row0 col3\" >.q(\n",
       "\t'toughness', '', 'to int',\n",
       "\t'toughness', '? x < df[\"toughness\"].max()', '',\n",
       "\t'name',\n",
       "\tmax_cols=200,\n",
       "\tmax_rows=20,\n",
       "\tinplace=True,\n",
       "\tverbosity=3,\n",
       "\t)</td>\n",
       "      <td id=\"T_83f15_row0_col4\" class=\"data row0 col4\" >2024-07-05 14:09:46.816743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244a34f9a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e9944_row0_col0, #T_e9944_row0_col1, #T_e9944_row0_col2, #T_e9944_row0_col3, #T_e9944_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e9944\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e9944_level0_row0\" class=\"row_heading level0 row0\" >608</th>\n",
       "      <td id=\"T_e9944_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_e9944_row0_col1\" class=\"data row0 col1\" >no operator found in condition \"toughness\". Using default operator \"=\"</td>\n",
       "      <td id=\"T_e9944_row0_col2\" class=\"data row0 col2\" >_parse_expression</td>\n",
       "      <td id=\"T_e9944_row0_col3\" class=\"data row0 col3\" >.q(\n",
       "\t'toughness', '', 'to int',\n",
       "\t'toughness', '? x < df[\"toughness\"].max()', '',\n",
       "\t'name',\n",
       "\tmax_cols=200,\n",
       "\tmax_rows=20,\n",
       "\tinplace=True,\n",
       "\tverbosity=3,\n",
       "\t)</td>\n",
       "      <td id=\"T_e9944_row0_col4\" class=\"data row0 col4\" >2024-07-05 14:09:47.424695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244a34bd040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcards\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoughness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mto int\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoughness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m? x < df[\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoughness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m].max()\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 553\u001b[0m, in \u001b[0;36mDataFrameQuery.__call__\u001b[1;34m(self, diff, max_cols, max_rows, inplace, verbosity, *expressions, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m         rows_filtered_new \u001b[38;5;241m=\u001b[39m _apply_condition(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m], condition, _operators, verbosity, df\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m         rows_filtered_new \u001b[38;5;241m=\u001b[39m \u001b[43m_apply_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_operators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m     rows_filtered_col \u001b[38;5;241m=\u001b[39m _update_index(rows_filtered_col, rows_filtered_new, condition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhich_cols\u001b[39m\u001b[38;5;124m'\u001b[39m], i_col, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n\u001b[0;32m    556\u001b[0m rows_filtered_condition \u001b[38;5;241m=\u001b[39m _update_index(rows_filtered_condition, rows_filtered_col, condition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition_connector\u001b[39m\u001b[38;5;124m'\u001b[39m], i_condition, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n",
      "Cell \u001b[1;32mIn[50], line 847\u001b[0m, in \u001b[0;36m_apply_condition\u001b[1;34m(pd_object, condition, operators, verbosity, df, series, index)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;66;03m#lambda function\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition:\n\u001b[1;32m--> 847\u001b[0m     filtered_no_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mpd_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    848\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mSeries({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}), filtered_no_metadata], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition_col:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[50], line 847\u001b[0m, in \u001b[0;36m_apply_condition.<locals>.<lambda>\u001b[1;34m(x, df, series, index, pd, np)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;66;03m#lambda function\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition:\n\u001b[1;32m--> 847\u001b[0m     filtered_no_metadata \u001b[38;5;241m=\u001b[39m pd_object\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x, df\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m1\u001b[39m:], series\u001b[38;5;241m=\u001b[39mseries, index\u001b[38;5;241m=\u001b[39mindex, pd\u001b[38;5;241m=\u001b[39mpd, np\u001b[38;5;241m=\u001b[39mnp: \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    848\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mSeries({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}), filtered_no_metadata], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition_col:\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:6189\u001b[0m, in \u001b[0;36mSeries.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6181\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m   6183\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6187\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6188\u001b[0m ):\n\u001b[1;32m-> 6189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:11968\u001b[0m, in \u001b[0;36mNDFrame.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11961\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m  11962\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11963\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11966\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11967\u001b[0m ):\n\u001b[1;32m> 11968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11971\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:11941\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11937\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11939\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11941\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11943\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:6129\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6124\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6128\u001b[0m     )\n\u001b[1;32m-> 6129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:1089\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[1;32m-> 1089\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m \u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value_typ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value_typ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(values, meth)(axis)\n\u001b[0;32m   1093\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:315\u001b[0m, in \u001b[0;36m_get_values\u001b[1;34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mor\u001b[39;00m _na_ok_dtype(dtype):\n\u001b[1;32m--> 315\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m         np\u001b[38;5;241m.\u001b[39mputmask(values, mask, fill_value)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# np.where will promote if needed\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cards.q(\n",
    "    'toughness', '', 'to int',\n",
    "    'toughness', '? x < df[\"toughness\"].max()', '',\n",
    "    'name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         169278 function calls (169224 primitive calls) in 0.420 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 349 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    83233    0.128    0.000    0.186    0.000 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\strings\\object_array.py:144(<lambda>)\n",
      "        2    0.120    0.060    0.306    0.153 {pandas._libs.lib.map_infer_mask}\n",
      "    83234    0.059    0.000    0.059    0.000 {method 'upper' of 'str' objects}\n",
      "        3    0.043    0.014    0.043    0.014 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "        3    0.011    0.004    0.012    0.004 {pandas._libs.lib.maybe_convert_objects}\n",
      "        2    0.011    0.005    0.011    0.005 {built-in method pandas._libs.missing.isnaobj}\n",
      "        2    0.010    0.005    0.010    0.005 {built-in method pandas._libs.lib.ensure_string_array}\n",
      "        4    0.006    0.002    0.008    0.002 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\cast.py:1544(construct_1d_object_array_from_listlike)\n",
      "        3    0.006    0.002    0.006    0.002 {pandas._libs.lib.infer_dtype}\n",
      "       15    0.003    0.000    0.003    0.000 {built-in method numpy.empty}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x2899c2065d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cProfile, pstats\n",
    "import statistics\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "\n",
    "cols = [True for col in cards.columns]\n",
    "rows = [True for row in cards.index]\n",
    "times = []\n",
    "\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True)\n",
    "# print(a)\n",
    "# a = cards.index[rows]\n",
    "# cards.loc[rows, cols]\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n",
    "times.append(stats.total_tt)\n",
    "\n",
    "\n",
    "# print(statistics.mean(times), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "for i in range(100):\n",
    "    cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20989580000000002 [0.2695525, 0.1782757, 0.1733644, 0.17382249999999996, 0.18152440000000003, 0.1757844, 0.17239650000000006, 0.17846470000000003, 0.2548654000000002, 0.34090750000000003]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.types import qp_date, qp_na\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('dat/cards.csv')\n",
    "\n",
    "# cards1 = cards.q('=toughness', '>1 && <4', modify='int(x)+10', inplace=False)\n",
    "\n",
    "# diff(cards1, cards, show='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def qp_int(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return int(float(x))  #float first to handle strings like '1.0'\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to integer.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_float(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to float.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "            \n",
    "def qp_num(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return pd.to_numeric(x)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to numeric.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "            \n",
    "def qp_bool(x, errors='coerce', na=None):\n",
    "    if str(x).lower() in ['y', 'yes', 'true', '1', '1.0', 'positive', 'pos']:\n",
    "        return True\n",
    "    elif str(x).lower() in ['n', 'no', 'false', '0', '0.0', 'negative', 'neg']:\n",
    "        return False\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to boolean.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "\n",
    "def qp_date(x, errors='coerce', na=pd.NaT):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '-')\n",
    "    try:\n",
    "        if re.match(r'\\D*(1|2)\\d\\d\\d', x):\n",
    "            return pd.to_datetime(x, dayfirst=False).date()\n",
    "        else:\n",
    "            return pd.to_datetime(x, dayfirst=True).date()\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to date.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaT\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "       \n",
    "def qp_datetime(x, errors='coerce', na=pd.NaT):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '-')\n",
    "    try:\n",
    "        if re.match(r'\\D*(1|2\\d\\d\\d)', x):\n",
    "            return pd.to_datetime(x, dayfirst=False)\n",
    "        else:\n",
    "            return pd.to_datetime(x, dayfirst=True)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to datetime.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaT\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "\n",
    "def qp_na(x, errors='ignore', na=None):\n",
    "    possible_nas = [\n",
    "        'not available', 'na', 'n/a', 'n.a', 'n.a.', 'na.', 'n.a',\n",
    "        'not a number', 'nan',\n",
    "        'null', 'nil',\n",
    "        'none',\n",
    "        '',\n",
    "        ]\n",
    "    \n",
    "    if pd.isna(x) or str(x).lower() in possible_nas:\n",
    "        return na\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{na}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return None\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_nk(x, errors='ignore', nk='unknown'):\n",
    "    possible_nks = [\n",
    "        'unk', 'unknown', 'not known', 'not known.',\n",
    "        'nk', 'n.k.', 'n.k', 'n/k',\n",
    "        'not specified', 'not specified.',\n",
    "        ]\n",
    "    \n",
    "    if str(x).lower() in possible_nks:\n",
    "        return nk\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{nk}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return None\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_yn(x, errors='coerce', yes='yes', no='no', na=None):\n",
    "    if str(x).lower() in ['y', 'yes', 'true', '1', '1.0', 'positive', 'pos']:\n",
    "        return yes\n",
    "    elif str(x).lower() in ['n', 'no', 'false', '0', '0.0', 'negative', 'neg']:\n",
    "        return no\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{yes}\" or \"{no}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"123,456.789\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mlib.pyx:2368\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"123,456.789\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#assign resulting substring to a\u001b[39;00m\n\u001b[0;32m      4\u001b[0m a \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+([,.]\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123,456.789 0123\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m456_789a4b5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\tools\\numeric.py:222\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    220\u001b[0m coerce_numeric \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     values, new_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]  # noqa: E501\u001b[39;49;00m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mlib.pyx:2410\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"123,456.789\" at position 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_789']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the regex pattern to match a sequence of numbers allowing for different kinds of separators\n",
    "pattern = r\"\\d+([,.\\s_]\\d+)*\"\n",
    "\n",
    "# Example string to match against\n",
    "example_string = \"123,456.789 0123\\t456_789\"\n",
    "\n",
    "# Perform the search\n",
    "matches = re.findall(pattern, example_string)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bashlike\" wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataframe qp.util.logs for tracking log entries\n",
      "use qp.log(message, level, source) or qp.log(message) to add log entries\n",
      "logs are saved in qp.util.logs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_046c4_row0_col0, #T_046c4_row0_col1, #T_046c4_row0_col2, #T_046c4_row0_col3, #T_046c4_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_046c4\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_046c4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_046c4_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_046c4_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_046c4_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_046c4_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_046c4_row0_col4\" class=\"data row0 col4\" >2024-07-05 13:18:31.314188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244d95bcd40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53799_row0_col0, #T_53799_row0_col1, #T_53799_row0_col2, #T_53799_row0_col3, #T_53799_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53799\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53799_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_53799_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_53799_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_53799_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_53799_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_53799_row0_col4\" class=\"data row0 col4\" >2024-07-05 13:18:32.023793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244da4d5d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c733646be40b456095f0b3c1fce0cae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9e2b10bad44070b49673d21cd3facd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dis\n",
    "import qplib as qp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = qp.get_df().format()\n",
    "\n",
    "df.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_32940\\2771104761.py:1: DtypeWarning: Columns (2,3,7,12,16,20,23,47,52,53,61,62,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cards = pd.read_csv('data/cards.csv').format()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_701e4_row0_col0, #T_701e4_row0_col1, #T_701e4_row0_col2, #T_701e4_row0_col3, #T_701e4_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_701e4\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_701e4_level0_row0\" class=\"row_heading level0 row0\" >440</th>\n",
       "      <td id=\"T_701e4_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_701e4_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_701e4_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_701e4_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_701e4_row0_col4\" class=\"data row0 col4\" >2024-07-05 13:23:24.101741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244e6336870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f3895_row0_col0, #T_f3895_row0_col1, #T_f3895_row0_col2, #T_f3895_row0_col3, #T_f3895_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f3895\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f3895_level0_row0\" class=\"row_heading level0 row0\" >441</th>\n",
       "      <td id=\"T_f3895_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_f3895_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_f3895_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_f3895_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_f3895_row0_col4\" class=\"data row0 col4\" >2024-07-05 13:23:24.111492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x244ee4d3d70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cards = pd.read_csv('data/cards.csv').format()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675363c33f0348c294caca6a658c2beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac00328c7c745409864a9d893414cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cards.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_45788_row0_col0, #T_45788_row0_col1, #T_45788_row0_col2, #T_45788_row0_col3, #T_45788_row0_col4 {\n",
       "  background-color: orange;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45788\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_45788_level0_row0\" class=\"row_heading level0 row0\" >521</th>\n",
       "      <td id=\"T_45788_row0_col0\" class=\"data row0 col0\" >Warning</td>\n",
       "      <td id=\"T_45788_row0_col1\" class=\"data row0 col1\" >showing 20 out of 83233 rows</td>\n",
       "      <td id=\"T_45788_row0_col2\" class=\"data row0 col2\" >df.q</td>\n",
       "      <td id=\"T_45788_row0_col3\" class=\"data row0 col3\" >.q(\n",
       "\t'=toughness', 'is any', 'to float',\n",
       "\tmax_cols=200,\n",
       "\tmax_rows=20,\n",
       "\tinplace=True,\n",
       "\tverbosity=3,\n",
       "\t)</td>\n",
       "      <td id=\"T_45788_row0_col4\" class=\"data row0 col4\" >2024-07-05 13:33:45.494284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2448016b0b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>toughness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83222</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83223</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83224</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83225</th>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83226</th>\n",
       "      <td></td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83227</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83228</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83229</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83230</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83231</th>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      #  toughness\n",
       "#                 \n",
       "0              4.0\n",
       "1              4.0\n",
       "2              3.0\n",
       "3              3.0\n",
       "4              NaN\n",
       "5              NaN\n",
       "6              NaN\n",
       "7              4.0\n",
       "8              4.0\n",
       "...   ..       ...\n",
       "83222          NaN\n",
       "83223          NaN\n",
       "83224          NaN\n",
       "83225          3.0\n",
       "83226         17.0\n",
       "83227          NaN\n",
       "83228          NaN\n",
       "83229          NaN\n",
       "83230          NaN\n",
       "83231          3.0\n",
       "\n",
       "[83233 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards.q(\n",
    "    '=toughness', 'is any', 'to float',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcards\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=toughness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis any\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mto float\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=toughness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis float && ? x == df[\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoughness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m].max()\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m=name // =text // =toughness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MartinVölkl-GouyaIns\\Gouya Insights\\Data Management GoIn - Dokumente\\09_Tech\\python\\qplib_dev\\qplib\\pd_query.py:561\u001b[0m, in \u001b[0;36mDataFrameQuery.__call__\u001b[1;34m(self, diff, max_cols, max_rows, inplace, verbosity, *expressions, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m         rows_filtered_new \u001b[38;5;241m=\u001b[39m _apply_condition(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m], condition, _operators, verbosity, df\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 561\u001b[0m         rows_filtered_new \u001b[38;5;241m=\u001b[39m \u001b[43m_apply_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_operators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m     rows_filtered_col \u001b[38;5;241m=\u001b[39m _update_index(rows_filtered_col, rows_filtered_new, condition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhich_cols\u001b[39m\u001b[38;5;124m'\u001b[39m], i_col, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n\u001b[0;32m    564\u001b[0m rows_filtered_condition \u001b[38;5;241m=\u001b[39m _update_index(rows_filtered_condition, rows_filtered_col, condition[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition_connector\u001b[39m\u001b[38;5;124m'\u001b[39m], i_condition, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n",
      "File \u001b[1;32mc:\\Users\\MartinVölkl-GouyaIns\\Gouya Insights\\Data Management GoIn - Dokumente\\09_Tech\\python\\qplib_dev\\qplib\\pd_query.py:855\u001b[0m, in \u001b[0;36m_apply_condition\u001b[1;34m(pd_object, condition, operators, verbosity, df, series, index)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m#lambda function\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition:\n\u001b[1;32m--> 855\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[43mpd_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition_col:\n\u001b[0;32m    857\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(value, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m'\u001b[39m: pd_object, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m: df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m: pd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m'\u001b[39m: np, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqp\u001b[39m\u001b[38;5;124m'\u001b[39m: qp})\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MartinVölkl-GouyaIns\\Gouya Insights\\Data Management GoIn - Dokumente\\09_Tech\\python\\qplib_dev\\qplib\\pd_query.py:855\u001b[0m, in \u001b[0;36m_apply_condition.<locals>.<lambda>\u001b[1;34m(x, df, series, index, pd, np)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m#lambda function\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition:\n\u001b[1;32m--> 855\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m pd_object\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x, df\u001b[38;5;241m=\u001b[39mdf, series\u001b[38;5;241m=\u001b[39mseries, index\u001b[38;5;241m=\u001b[39mindex, pd\u001b[38;5;241m=\u001b[39mpd, np\u001b[38;5;241m=\u001b[39mnp: \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m operators\u001b[38;5;241m.\u001b[39mlambda_condition_col:\n\u001b[0;32m    857\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(value, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m'\u001b[39m: pd_object, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m: df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m: pd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m'\u001b[39m: np, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqp\u001b[39m\u001b[38;5;124m'\u001b[39m: qp})\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:6189\u001b[0m, in \u001b[0;36mSeries.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6181\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m   6183\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6187\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6188\u001b[0m ):\n\u001b[1;32m-> 6189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:11968\u001b[0m, in \u001b[0;36mNDFrame.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11961\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m  11962\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11963\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11966\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11967\u001b[0m ):\n\u001b[1;32m> 11968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11971\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:11941\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11937\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11939\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11941\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11943\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\series.py:6129\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6124\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6128\u001b[0m     )\n\u001b[1;32m-> 6129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py:1092\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[0;32m   1089\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(\n\u001b[0;32m   1090\u001b[0m     values, skipna, fill_value_typ\u001b[38;5;241m=\u001b[39mfill_value_typ, mask\u001b[38;5;241m=\u001b[39mmask\n\u001b[0;32m   1091\u001b[0m )\n\u001b[1;32m-> 1092\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "cards.q(\n",
    "    '=toughness', 'is any', 'to float',\n",
    "\t'=toughness', 'is float && ? x == df[\"toughness\"].max()', '',\n",
    "\t'', '', '',\n",
    "\t'', '', '',\n",
    "\t'', '', '',\n",
    "\t'=name // =text // =toughness', '', '',\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5ee32_row0_col0, #T_5ee32_row0_col1, #T_5ee32_row0_col2, #T_5ee32_row0_col3, #T_5ee32_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5ee32\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5ee32_level0_row0\" class=\"row_heading level0 row0\" >87</th>\n",
       "      <td id=\"T_5ee32_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_5ee32_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_5ee32_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_5ee32_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_5ee32_row0_col4\" class=\"data row0 col4\" >2024-07-04 16:52:33.374622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x270b7629f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2963c_row0_col0, #T_2963c_row0_col1, #T_2963c_row0_col2, #T_2963c_row0_col3, #T_2963c_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2963c\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2963c_level0_row0\" class=\"row_heading level0 row0\" >88</th>\n",
       "      <td id=\"T_2963c_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_2963c_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_2963c_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_2963c_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_2963c_row0_col4\" class=\"data row0 col4\" >2024-07-04 16:52:33.386517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x270b762a8a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MartinVölkl-GouyaIns\\Gouya Insights\\Data Management GoIn - Dokumente\\08_Python\\git_test\\qplib\\qplib\\types.py:97: UserWarning: Parsing dates in %m-%d-%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, dayfirst=True).date()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>date of birth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp systole</th>\n",
       "      <th>bp diastole</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>10001</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>170</td>\n",
       "      <td>70.2</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>10kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>10002</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>1990-09-14</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>175.5cm</td>\n",
       "      <td>68</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>Highe</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>10003</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>1985-08-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>72.5lb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15 mg once a day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>20001</td>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>1980-04-06</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>280</td>\n",
       "      <td>na</td>\n",
       "      <td>140</td>\n",
       "      <td>90mmHg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>no</td>\n",
       "      <td>20mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>20002</td>\n",
       "      <td>Eva White</td>\n",
       "      <td>2007-11-05</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>135mmhg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>yes</td>\n",
       "      <td>20 Mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>20003</td>\n",
       "      <td>Frank Miller</td>\n",
       "      <td>1983-06-30</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>185</td>\n",
       "      <td>75kg</td>\n",
       "      <td>125</td>\n",
       "      <td>75</td>\n",
       "      <td>High</td>\n",
       "      <td>yes</td>\n",
       "      <td>25g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>30001</td>\n",
       "      <td>Grace Taylor</td>\n",
       "      <td>1975-05-28</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>30002</td>\n",
       "      <td>Harry Clark</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ft 1in</td>\n",
       "      <td>80.3</td>\n",
       "      <td>122</td>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>30003</td>\n",
       "      <td>Ivy Green</td>\n",
       "      <td>1955-01-09</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-10</td>\n",
       "      <td>130lbs</td>\n",
       "      <td></td>\n",
       "      <td>95</td>\n",
       "      <td>high</td>\n",
       "      <td>None</td>\n",
       "      <td>30 MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>30004</td>\n",
       "      <td>Jack Williams</td>\n",
       "      <td>1950-09-10</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>30005</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1945-10-11</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>200</td>\n",
       "      <td>-65</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>yes</td>\n",
       "      <td>40ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #     ID           name date of birth   age gender   height  weight  \\\n",
       "#                                                                        \n",
       "0     10001       John Doe    1995-01-02  None      M      170    70.2   \n",
       "1     10002     Jane Smith    1990-09-14    30      F  175.5cm      68   \n",
       "2     10003  Alice Johnson    1985-08-23   NaN      F     None  72.5lb   \n",
       "3     20001      Bob Brown    1980-04-06  None      M      280      na   \n",
       "4     20002      Eva White    2007-11-05  40.0  Other      NaN           \n",
       "5     20003   Frank Miller    1983-06-30  None      M      185    75kg   \n",
       "6     30001   Grace Taylor    1975-05-28  None      F        1    None   \n",
       "7     30002    Harry Clark           NaT  None    NaN  6ft 1in    80.3   \n",
       "8     30003      Ivy Green    1955-01-09         None      -10  130lbs   \n",
       "9     30004  Jack Williams    1950-09-10  None      M               82   \n",
       "10    30005       John Doe    1945-10-11    35      F      200     -65   \n",
       "\n",
       "   bp systole bp diastole cholesterol diabetes              dose  \n",
       "#                                                                 \n",
       "0          20          80      Normal       no              10kg  \n",
       "1         130          85       Highe      yes               NaN  \n",
       "2         NaN         nan         NaN     None  15 mg once a day  \n",
       "3         140      90mmHg        GOOD       no              20mg  \n",
       "4     135mmhg         NaN        n.a.      yes             20 Mg  \n",
       "5         125          75        High      yes               25g  \n",
       "6         NAN         NaN      Normal       no               NaN  \n",
       "7         122        None         n/a     None              None  \n",
       "8                      95        high     None             30 MG  \n",
       "9         130           0                   no                35  \n",
       "10         45         NaN      Normal      yes              40ml  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qplib as qp\n",
    "\n",
    "df = qp.get_df().format()\n",
    "\n",
    "df.q(\n",
    "\t'=name',\n",
    "\t\t'is any',\n",
    "\t\t\t'x = x.title()',\n",
    "\t'=date of birth',\n",
    "\t\t'is any',\n",
    "\t\t\t'to date',\n",
    "\t'=age',\n",
    "\t\t'!is num // <0',\n",
    "\t\t\t'x=None',\n",
    "\t'=gender',\n",
    "\t\t\"? str(x).lower()  in  ['m', 'male', 'mal']\",\n",
    "\t\t\t'x = \"M\"',\n",
    "    '=gender',\n",
    "\t\t\"? str(x).lower()  in  ['f', 'female', 'ff']\",\n",
    "\t\t\t'x = \"F\"',\n",
    "    '=diabetes',\n",
    "\t\t'is any',\n",
    "\t\t\t'to yn',\n",
    "\t'is any',\n",
    "\t\t'is any',\n",
    "\t\t\t'',\n",
    "\tdiff=None,\n",
    "\tinplace=False,\n",
    "\tverbosity=3,\n",
    "\t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
