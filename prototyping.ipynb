{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "import qplib as qp\n",
    "from qplib import log, na, nk, num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:93: UserWarning: registration of accessor <class '__main__.IndexQuery'> under name 'q' for type <class 'pandas.core.indexes.base.Index'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_index_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:223: UserWarning: registration of accessor <class '__main__.SeriesQuery'> under name 'q' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_series_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:349: UserWarning: registration of accessor <class '__main__.DataFrameQuery'> under name 'q' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:1025: UserWarning: registration of accessor <class '__main__.DataFrameQueryInteractiveMode'> under name 'qi' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('qi')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:1230: DtypeWarning: Columns (2,3,7,12,16,20,23,47,52,53,61,62,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cards = pd.read_csv('data/cards.csv').format()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataframe qp.util.logs for tracking log entries\n",
      "use qp.log(message, level, source) or qp.log(message) to add log entries\n",
      "logs are saved in qp.util.logs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fc6ab_row0_col0, #T_fc6ab_row0_col1, #T_fc6ab_row0_col2, #T_fc6ab_row0_col3, #T_fc6ab_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fc6ab\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fc6ab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fc6ab_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_fc6ab_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_fc6ab_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_fc6ab_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_fc6ab_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:36:56.638555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e1750b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dd7cf_row0_col0, #T_dd7cf_row0_col1, #T_dd7cf_row0_col2, #T_dd7cf_row0_col3, #T_dd7cf_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dd7cf\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dd7cf_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_dd7cf_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_dd7cf_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_dd7cf_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_dd7cf_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_dd7cf_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:36:58.485038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e646ba40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6edf2_row0_col0, #T_6edf2_row0_col1, #T_6edf2_row0_col2, #T_6edf2_row0_col3, #T_6edf2_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6edf2\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6edf2_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_6edf2_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_6edf2_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_6edf2_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_6edf2_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_6edf2_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:37:02.090504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e640c380>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6069_row0_col0, #T_c6069_row0_col1, #T_c6069_row0_col2, #T_c6069_row0_col3, #T_c6069_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6069\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6069_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_c6069_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_c6069_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_c6069_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_c6069_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_c6069_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:37:02.100506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e646ba40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb46804a2bf4d90b645d98394855c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d892fe59ded9489dbbf48251e15814a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.pd_util import _check_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "from qplib.pd_util import diff as mv_diff\n",
    "\n",
    "\n",
    "\n",
    "from qplib.types import qp_int, qp_float, qp_num, qp_bool, qp_datetime, qp_date, qp_na, qp_nk, qp_yn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_operators1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'bigger_equal': '>=',\n",
    "    'smaller_equal': '<=',\n",
    "    'bigger': '>',\n",
    "    'smaller': '<',\n",
    "    'strict_equal': '==',\n",
    "    'equal': '=',\n",
    "    'regex_match': '~~',\n",
    "    'regex_search': '~',\n",
    "    'strict_contains': '(())',\n",
    "    'contains': '()',\n",
    "\n",
    "    'lambda_condition': '?',\n",
    "    'lambda_condition_col': 'col?',\n",
    "    })\n",
    "_operators2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'is_str': 'is str',\n",
    "    'is_int': 'is int',\n",
    "    'is_float': 'is float',\n",
    "    'is_num': 'is num',\n",
    "    'is_bool': 'is bool',\n",
    "\n",
    "    'is_datetime': 'is datetime',\n",
    "    'is_date': 'is date',\n",
    "\n",
    "    'is_any': 'is any',\n",
    "    'is_na': 'is na',\n",
    "    'is_nk': 'is nk',\n",
    "    'is_yn': 'is yn',\n",
    "    'is_yes': 'is yes',\n",
    "    'is_no': 'is no',\n",
    "    })\n",
    "_operators = qpDict({**_operators1, **_operators2})\n",
    "_operators_only_df = qpDict({\n",
    "    'lambda_condition_col': _operators['lambda_condition_col'],\n",
    "    })\n",
    "\n",
    "_modifiers1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'set_x': ['x=', 'x ='],\n",
    "    'set_col': ['col=', 'col ='],\n",
    "    'set_row': ['row=', 'row ='],\n",
    "    'set_col_tags': ['col#=', 'col# =', 'col #=', 'col # ='],\n",
    "    'set_row_tags': ['row#=', 'row# =', 'row #=', 'row # ='],\n",
    "    })\n",
    "_modifiers2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'to_str': 'to str',\n",
    "    'to_int': 'to int',\n",
    "    'to_float': 'to float',\n",
    "    'to_num': 'to num',\n",
    "    'to_bool': 'to bool',\n",
    "\n",
    "    'to_datetime': 'to datetime',\n",
    "    'to_date': 'to date',\n",
    "\n",
    "    'to_na': 'to na',\n",
    "    'to_nk': 'to nk',\n",
    "    'to_yn': 'to yn',\n",
    "    })\n",
    "_modifiers = qpDict({**_modifiers1, **_modifiers2})\n",
    "_modifiers_only_df = qpDict({\n",
    "    'set_col': _modifiers['set_col'],\n",
    "    'set_row': _modifiers['set_row'],\n",
    "    'set_col_tags': _modifiers['set_col_tags'],\n",
    "    'set_row_tags': _modifiers['set_row_tags'],\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_index_accessor('q')\n",
    "class IndexQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Indices.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, idx: pd.Index):\n",
    "        idx.qp._operators = _operators\n",
    "        idx.qp._operators_only_df = _operators_only_df\n",
    "        idx.qp._modifiers = _modifiers\n",
    "        idx.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.idx = idx \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_index(self.idx)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        idx = self.idx\n",
    "        idx.qp = self.idx.qp\n",
    "        idx.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in idx])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter index', 'modify index'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter index':\n",
    "                ast = _parse_expression(idx, expression, 'filter index', verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(idx, condition, _operators, verbosity, index=idx)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                        log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='idx.q', input=idx.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify index':\n",
    "                ast = _parse_expression_modify(idx, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = idx.to_series()\n",
    "                    se.qp = idx.qp\n",
    "                    idx = pd.Index(_apply_modification(se, index_expression, modification, verbosity, index=idx))\n",
    "                    idx.qp = self.idx.qp\n",
    "        \n",
    "\n",
    "\n",
    "        idx_filtered = idx[index_expression]\n",
    "        idx_filtered.qp = idx.qp\n",
    "\n",
    "        return idx_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_series_accessor('q')\n",
    "class SeriesQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Series.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, se: pd.Series):\n",
    "        se.qp._operators = _operators\n",
    "        se.qp._operators_only_df = _operators_only_df\n",
    "        se.qp._modifiers = _modifiers\n",
    "        se.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.se = se \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_series(self.se)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        se = copy.deepcopy(self.se)\n",
    "        se.qp = self.se.qp\n",
    "        se.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in se])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter series', 'modify series'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter series':\n",
    "                ast = _parse_expression(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(se, condition, _operators, verbosity, series=se)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                    log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='se.q', input=se.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify series':\n",
    "                ast = _parse_expression_modify(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = _apply_modification(se, index_expression, modification, verbosity, series=se)\n",
    "                    se.qp = self.se.qp\n",
    "\n",
    "\n",
    "        se_filtered = se[index_expression]\n",
    "        se_filtered.qp = se.qp\n",
    "        return se_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data and metadata in pandas DataFrames.\n",
    "\n",
    "    each query consists of 3 string expressions, any of which can be left empty:\n",
    "        1. column filter: '=col1', '!=col2', '()1 // ()2'\n",
    "        2. row filter: 'is date', 'is int && >0', '? len(str(x)) > 5'\n",
    "        3. (meta-)data modification: 'x= str(x)', 'col#= integer column', 'row#= positive'\n",
    "\n",
    "    eg.: df.q('=col1', 'is int && >0', 'row#= positive')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "        col=: set whole column to a value\n",
    "        row=: set whole row to a value\n",
    "        col#=: tag columns\n",
    "        row#=: tag rows\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        _check_df(df)\n",
    "        self.df = df\n",
    "        self.df.qp._operators = _operators\n",
    "        self.df.qp._modifiers = _modifiers\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self,\n",
    "            *expressions,  #string expressions for filtering and modifying data\n",
    "            diff=None,  #[None, 'mix', 'old', 'new', 'new+']\n",
    "            max_cols=200,  #maximum number of columns to display. None: show all\n",
    "            max_rows=20,  #maximum number of rows to display. None: show all\n",
    "            inplace=True,  #make modifications inplace or just return a new dataframe\n",
    "            verbosity=3,  #verbosity level for logging. 0: no logging, 1: errors, 2: warnings, 3: info, 4: debug\n",
    "            **kwargs\n",
    "            ):\n",
    "\n",
    "        ###########################################\n",
    "        #                  setup                  #\n",
    "        ###########################################\n",
    "\n",
    "        #input string for logging\n",
    "        input_str = \".q(\"\n",
    "        for i,expression in enumerate(expressions):\n",
    "            if (i+1)%3 == 1:\n",
    "                input_str += f\"\\n\\t{expression !r},\"\n",
    "            else:\n",
    "                input_str += f\" {expression !r},\"\n",
    "   \n",
    "        if diff is not None:\n",
    "            input_str += f\"\\n\\tdiff='{diff}',\"\n",
    "        if max_cols is not None:\n",
    "            input_str += f\"\\n\\tmax_cols={max_cols},\"\n",
    "        if max_rows is not None:\n",
    "            input_str += f\"\\n\\tmax_rows={max_rows},\"\n",
    "        \n",
    "        input_str += f\"\\n\\tinplace={inplace},\"\n",
    "        input_str += f\"\\n\\tverbosity={verbosity},\"\n",
    "\n",
    "        for kwarg in kwargs:\n",
    "            input_str += f\"\\n\\t{kwarg}='{kwargs[kwarg]}'\"\n",
    "\n",
    "        self.df.qp._input = input_str + \"\\n\\t)\"\n",
    "\n",
    "\n",
    "    \n",
    "        if inplace is False:\n",
    "            df = self.df.copy()\n",
    "        else:\n",
    "            df = self.df\n",
    "            \n",
    "        df.qp = self.df.qp\n",
    "\n",
    "        \n",
    "\n",
    "        #inserting metadata row at the top, sadly a bit hacky\n",
    "        #because there does not seem to be an inplace function for that\n",
    "        if '#' not in df.index:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a row named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata row now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df_old = df.copy()\n",
    "            index_old = df.index\n",
    "            index_new = pd.Index(['#', *index_old])\n",
    "            \n",
    "            df.loc['#'] = ''\n",
    "            df.set_index(index_new, inplace=True)\n",
    "            df.loc[index_old, :] = df_old\n",
    "            df.loc['#'] = ''\n",
    "\n",
    "        #inserting metadata column at the start\n",
    "        if '#' not in df.columns:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a column named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata column now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df.insert(0, '#', '')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        ###########################################\n",
    "        #               run queries               #\n",
    "        ###########################################\n",
    "\n",
    "        cols_filtered = cols_filtered_condition = pd.Index([True for col in df.columns])\n",
    "        rows_filtered = rows_filtered_condition = rows_filtered_col = pd.Index([True for row in df.index])\n",
    "        \n",
    "\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['col', 'row', 'modify'][i_expression%3]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            #filter columns\n",
    "            if expression_type == 'col':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    if condition['by_tag'] == 'row or col metadata':\n",
    "                        cols_filtered_new = _apply_condition(df.loc['#'], condition, _operators, verbosity, df=df)\n",
    "                    else:\n",
    "                        cols_filtered_new = _apply_condition(df.columns, condition, _operators, verbosity, df=df)\n",
    "\n",
    "                    cols_filtered_condition = _update_index(cols_filtered_condition, cols_filtered_new, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                cols_filtered = _update_index(cols_filtered, cols_filtered_condition, ast['connector'], i_expression, verbosity=verbosity)\n",
    "\n",
    "                if cols_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no columns fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            #filter rows\n",
    "            elif expression_type == 'row':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    for i_col,col in enumerate(df.columns[cols_filtered_condition][1:]):  #ignore metadata column\n",
    "                        if condition['by_tag'] == 'row or col metadata':\n",
    "                            rows_filtered_new = _apply_condition(df['#'], condition, _operators, verbosity, df=df)\n",
    "                        else:\n",
    "                            rows_filtered_new = _apply_condition(df[col], condition, _operators, verbosity, df=df)\n",
    "\n",
    "                        rows_filtered_col = _update_index(rows_filtered_col, rows_filtered_new, condition['which_cols'], i_col, verbosity=verbosity)\n",
    "                    rows_filtered_condition = _update_index(rows_filtered_condition, rows_filtered_col, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                rows_filtered = _update_index(rows_filtered, rows_filtered_condition, ast['connector'], i_expression-1, verbosity=verbosity)\n",
    "\n",
    "                if rows_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no rows fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "\n",
    "\n",
    "            #modify data\n",
    "            elif expression_type == 'modify':\n",
    "                cols_filtered_no_metadata = [col for col in df.columns[cols_filtered] if not col.startswith('#')]\n",
    "                rows_filtered_no_metadata = [row for row in df.index[rows_filtered] if row != '#']\n",
    "\n",
    "                ast = _parse_expression_modify(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                            \n",
    "                    #tag columns\n",
    "                    if modification['modifier'] in _modifiers['set_col_tags']:\n",
    "                        df.loc['#', cols_filtered_no_metadata] = df.loc['#', cols_filtered_no_metadata].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #tag rows\n",
    "                    elif modification['modifier'] in _modifiers['set_row_tags']:\n",
    "                        df.loc[rows_filtered_no_metadata, '#'] = df.loc[rows_filtered_no_metadata, '#'].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #modify filtered data\n",
    "                    else:\n",
    "                        df.loc[:, :] = _apply_modification_df(df, rows_filtered_no_metadata, cols_filtered_no_metadata, modification, verbosity).loc[:, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################\n",
    "        #            display settings            #\n",
    "        ##########################################\n",
    "   \n",
    "        df_filtered = df.loc[rows_filtered, cols_filtered]\n",
    "        df_filtered.qp = self.df.qp\n",
    "    \n",
    "        if diff is None:\n",
    "\n",
    "            cols_num = len(df.columns[cols_filtered])\n",
    "            rows_num = len(df.index[rows_filtered])\n",
    "\n",
    "            if verbosity >= 2:\n",
    "                if max_cols is not None and max_cols < cols_num:\n",
    "                    log(f'showing {max_cols} out of {cols_num} columns', level='warning', source='df.q', input=df.qp._input)\n",
    "                if max_rows is not None and max_rows < rows_num:\n",
    "                    log(f'showing {max_rows} out of {rows_num} rows', level='warning', source='df.q', input=df.qp._input)\n",
    " \n",
    "            pd.set_option('display.max_columns', max_cols)\n",
    "            pd.set_option('display.max_rows', max_rows)\n",
    "            pd.set_option('display.min_rows', max_rows)\n",
    "\n",
    "            return df_filtered\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            #show difference before and after filtering\n",
    "            result = qp.diff(\n",
    "                df_filtered, self.df, show=diff,\n",
    "                max_cols=max_cols, max_rows=max_rows,\n",
    "                verbosity=verbosity)  \n",
    "            return  result\n",
    "\n",
    "\n",
    "\n",
    "def _parse_expression(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'connector': None,\n",
    "        'conditions': [],\n",
    "        }\n",
    "    \n",
    "    if expression[:2] not in ['&&', '//', '>>']:\n",
    "        expression = '>>' + expression\n",
    "\n",
    "    ast['connector'] = expression[:2]\n",
    "\n",
    "\n",
    "    expressions = re.split('(&&|//|>>)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {'expression': expressions[ind], 'mode': mode}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&', '//', '>>']:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if expressions[ind-1] == '&&':  #and\n",
    "            condition['condition_connector'] = '&&'\n",
    "        elif expressions[ind-1] == '//':  #inclusive or\n",
    "            condition['condition_connector'] = '//'\n",
    "        elif expressions[ind-1] == '>>':  #reset\n",
    "            condition['condition_connector'] = '>>'\n",
    "\n",
    "        \n",
    "        #row conditions also specify in which cols the condition is applied. default: any\n",
    "        if mode == 'row':\n",
    "            if condition_str.startswith('any'):\n",
    "                condition['which_cols'] = 'any'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            elif condition_str.startswith('all'):\n",
    "                condition['which_cols'] = 'all'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            else:\n",
    "                condition['which_cols'] = 'any'\n",
    "\n",
    "\n",
    "        #rows and cols can be filtered by metadata\n",
    "        if condition_str.startswith('#'):\n",
    "            condition['by_tag'] = 'row or col metadata'\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['by_tag'] = False\n",
    "\n",
    "        #wip\n",
    "        # if condition_str.startswith('x#'):\n",
    "        #     condition['by_tag_value'] = 'value metadata'\n",
    "        #     condition_str = condition_str[1:].lstrip()\n",
    "        # else:\n",
    "        #     condition['by_tag_value'] = False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #should the condition be negated. default: False\n",
    "        if condition_str.startswith('!'):\n",
    "            condition['negate'] = True\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['negate'] = False\n",
    "\n",
    "\n",
    "        #operator for condition. default: =\n",
    "        for operator in _operators.values_flat():\n",
    "            if condition_str.startswith(operator):\n",
    "                condition['operator'] = operator\n",
    "                condition_str = condition_str[len(operator):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'operator' not in condition:\n",
    "            if verbosity >= 3:\n",
    "                log(f'no operator found in condition \"{condition_str}\". Using default operator \"=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['operator'] = '='\n",
    "\n",
    "\n",
    "        if mode in ['filter series', 'filter index'] and condition['operator'] in _operators_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "        \n",
    "        if condition['operator'] in _operators2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #value for comparison\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['conditions'].append(condition)\n",
    "\n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "        \n",
    "    return ast\n",
    "\n",
    "def _parse_expression_modify(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'modifications': [],\n",
    "        }\n",
    "    \n",
    "\n",
    "    expressions = re.split('(&&)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&']:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #modifier to use. default: \"set x:\"\n",
    "        for modifier in _modifiers.values_flat():\n",
    "            if condition_str.startswith(modifier):\n",
    "                condition['modifier'] = modifier\n",
    "                condition_str = condition_str[len(modifier):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'modifier' not in condition:\n",
    "            if verbosity > 3:\n",
    "                log(f'no modifier found in condition \"{condition_str}\". Using default modifier \"x=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['modifier'] = 'x='\n",
    "\n",
    "        if mode in ['modify series', 'modify index'] and condition['modifier'] in _modifiers_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "\n",
    "        if condition['modifier'] in _modifiers2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #expression used for modification\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['modifications'].append(condition)\n",
    "        \n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "    \n",
    "    return ast\n",
    "\n",
    "\n",
    "def _apply_condition(pd_object, condition, operators, verbosity=3, df=None, series=None, index=None):\n",
    "    \"\"\"\n",
    "    filters a pandas object using a query condition\n",
    "    \"\"\"\n",
    "\n",
    "    value = condition['value']\n",
    "\n",
    "    if isinstance(pd_object, pd.Index):\n",
    "        pd_object = pd_object.to_series()\n",
    "\n",
    "    \n",
    "    match condition['operator']:\n",
    "        #numeric comparison\n",
    "        case operators.bigger_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') >= pd.to_numeric(value)\n",
    "        case operators.smaller_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') <= pd.to_numeric(value)\n",
    "        case operators.bigger:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') > pd.to_numeric(value)\n",
    "        case operators.smaller:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') < pd.to_numeric(value)\n",
    "        \n",
    "        \n",
    "        #regex comparison\n",
    "        case operators.regex_match:\n",
    "            filtered = pd_object.astype(str).str.fullmatch(value) \n",
    "        case operators.regex_search:\n",
    "            filtered = pd_object.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "        #string equality comparison\n",
    "        case operators.strict_equal:\n",
    "            filtered = pd_object.astype(str) == value\n",
    "        case operators.equal:\n",
    "            value_lenient = [value]\n",
    "            try:\n",
    "                value_lenient.append(str(float(value)))\n",
    "                value_lenient.append(str(int(float(value))))\n",
    "            except:\n",
    "                value_lenient.append(value.lower())\n",
    "            filtered = pd_object.astype(str).str.lower().isin(value_lenient)\n",
    "        \n",
    "        #substring comparison\n",
    "        case operators.strict_contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=True, regex=False)\n",
    "        case operators.contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "\n",
    "        #lambda function\n",
    "        case operators.lambda_condition:\n",
    "            filtered = pd_object.apply(lambda x, df=df, series=series, index=index, pd=pd, np=np: eval(value))\n",
    "        case operators.lambda_condition_col:\n",
    "            filtered = eval(value, {'col': pd_object, 'df': df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "\n",
    "\n",
    "        #type checks\n",
    "        case operators.is_bool:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, bool))\n",
    "        case operators.is_str:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, str))\n",
    "        case operators.is_int:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, int))\n",
    "        case operators.is_float:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, float))\n",
    "        case operators.is_num:\n",
    "            filtered = pd_object.apply(lambda x: qp_num(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_date:\n",
    "            filtered = pd_object.apply(lambda x: qp_date(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_datetime:\n",
    "            filtered = pd_object.apply(lambda x: qp_datetime(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_any:\n",
    "            filtered = pd_object.apply(lambda x: True)\n",
    "        case operators.is_na:\n",
    "            filtered = pd_object.apply(lambda x: qp_na(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_nk:\n",
    "            filtered = pd_object.apply(lambda x: qp_nk(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yn:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yes:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', yes=1)) == 1\n",
    "        case operators.is_no:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', no=0)) == 0\n",
    "\n",
    "        case _:\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" is not implemented', level='error', source='_apply_condition()', input=pd_object.qp._input)\n",
    "            filtered = None\n",
    "\n",
    "\n",
    "    if condition['negate']:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    if condition['mode'] in ['col', 'row']:\n",
    "        filtered.iloc[0] = True  #metadata row/column should always be included\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def _apply_modification(pd_object, indices, modification, verbosity=3, series=None, index=None):\n",
    "    modifiers = pd_object.qp._modifiers\n",
    "\n",
    "    #data modification\n",
    "    if modification['modifier'] in modifiers['set_x']:\n",
    "        pd_object[indices] = pd_object[indices].map(lambda x, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "\n",
    "    #type conversion\n",
    "    elif modification['modifier'] == modifiers['to_str']:\n",
    "        pd_object[indices] = pd_object[indices].map(str)\n",
    "    elif modification['modifier'] == modifiers['to_int']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_int)\n",
    "    elif modification['modifier'] == modifiers['to_float']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_float)\n",
    "    elif modification['modifier'] == modifiers['to_num']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_num)\n",
    "    elif modification['modifier'] == modifiers['to_bool']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_bool)\n",
    "    \n",
    "    elif modification['modifier'] == modifiers['to_date']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_date)\n",
    "    elif modification['modifier'] == modifiers['to_datetime']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_datetime)\n",
    "    elif modification['modifier'] == modifiers['to_na']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_na)\n",
    "    elif modification['modifier'] == modifiers['to_nk']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_nk)\n",
    "    elif modification['modifier'] == modifiers['to_yn']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_yn)\n",
    "\n",
    "    return pd_object\n",
    "\n",
    "def _apply_modification_df(df, rows, cols, modification, verbosity=3):\n",
    "    modifiers = df.qp._modifiers\n",
    "\n",
    "    if pd.__version__ >= '2.1.0':\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_yn)\n",
    "\n",
    "    else:\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_yn) \n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def _update_index(values, values_new, connector, i, verbosity=3):\n",
    "    if i == 0:\n",
    "        values = values_new\n",
    "    elif connector == '>>':\n",
    "        values = values_new\n",
    "    elif connector in ['&&', 'all']:\n",
    "        values &= values_new\n",
    "    elif connector in ['//', 'any']:\n",
    "        values |= values_new\n",
    "    else:\n",
    "        if verbosity >= 1:\n",
    "            log(f'connector \"{connector}\" is not implemented', level='error', source='_update_index()')\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for df.q() for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self, num_filters=5):\n",
    "        kwargs = {'df': fixed(self.df)}\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #            tab0 queries&diff            #\n",
    "        ###########################################\n",
    "\n",
    "        ui_label_filter_cols = widgets.Label(value='filter columns')\n",
    "        ui_label_filter_rows = widgets.Label(value='filter rows')\n",
    "        ui_label_modify_data = widgets.Label(value='modify data')\n",
    "        ui_expressions = [ui_label_filter_cols, ui_label_filter_rows, ui_label_modify_data]\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(num_filters):\n",
    "            if i == 0:\n",
    "                placeholder_col = '=name'\n",
    "                placeholder_row = '()john'\n",
    "                placeholder_modify = 'x= x.upper() '\n",
    "            elif i == 1:\n",
    "                placeholder_col = '// =age'\n",
    "                placeholder_row = '&& <0 // >120'\n",
    "                placeholder_modify = 'row#= \"implausible age\" '\n",
    "            elif i == 2:\n",
    "                placeholder_col = '// =weight // =height'\n",
    "                placeholder_row = '!is num'\n",
    "                placeholder_modify = 'to num'\n",
    "            else:\n",
    "                placeholder_col = ''\n",
    "                placeholder_row = ''\n",
    "                placeholder_modify = ''\n",
    "            \n",
    "\n",
    "            col = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_col,\n",
    "                options=['=' + col for col in self.df.columns if col != '#'],\n",
    "                )\n",
    "            kwargs[f'col_expression{i}'] = col\n",
    "            ui_expressions.append(col)\n",
    "            \n",
    "            row = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_row,\n",
    "                options=[\n",
    "                    '>0', '<0', '>=0', '<=0',  #numerical comparison\n",
    "                    '=abc', '!=abc', '==AbC', '!==AbC',  #equality checks\n",
    "                    '()abc', '(())AbC',  #substring checks\n",
    "                    '~*a.c', '~~*a.c',  #regex checks\n",
    "                    \n",
    "                    '? len(x) > 3',  #lambda function condition for each value\n",
    "                    'col? col > df[\"age\"]',  #lambda function condition for whole columns\n",
    "\n",
    "                    #type checks\n",
    "                    'is str', 'is int', 'is float', 'is num', 'is bool',\n",
    "                    'is date', 'is datetime',\n",
    "                    'is any', 'is na', 'is nk',\n",
    "                    'is yn', 'is yes', 'is no'\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'row_expression{i}'] = row\n",
    "            ui_expressions.append(row)\n",
    "            \n",
    "            modify = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_modify,\n",
    "                options=[\n",
    "                    'x= x.upper() ', 'col= df[\"ID\"]', 'row= df.loc[0]',  #change data\n",
    "                    'col#= \"tag\" ', 'col#= x + \"tag\" ', 'row#= \"tag\" ', 'row#= x + \"tag\"',  #change metadata\n",
    "\n",
    "                    #change type\n",
    "                    'to str', 'to int', 'to float', 'to num', 'to bool',\n",
    "                    'to date', 'to datetime',\n",
    "                    'to na', 'to nk', 'to yn',\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'modify_expression{i}'] = modify\n",
    "            ui_expressions.append(modify)\n",
    "        \n",
    "\n",
    "        #show differences\n",
    "        ui_diff = widgets.ToggleButtons(\n",
    "            options=[None, 'mix', 'old', 'new', 'new+'],\n",
    "            description='show differences mode:',\n",
    "            tooltips=[\n",
    "                'dont show differences, just show the new (filtered) dataframe.',\n",
    "                'show new (filtered) dataframe plus all the removed (filtered) values from the old dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show old (unfiltered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe but also adds metadata columns with the prefix \"#\". If a value changed, the metadata column contains the old value. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['diff'] = ui_diff\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #              tab1 settings              #\n",
    "        ###########################################\n",
    "\n",
    "        ui_inplace = widgets.ToggleButtons(\n",
    "            options=[True, False],\n",
    "            value=False,\n",
    "            description='make modifications inplace:',\n",
    "            tooltips=[\n",
    "                'make modifications inplace, e.g. change the original dataframe',\n",
    "                'return a new dataframe with the modifications',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['inplace'] = ui_inplace\n",
    "\n",
    "        ui_verbosity = widgets.ToggleButtons(\n",
    "            options=[0, 1, 2, 3, 4],\n",
    "            value=3,\n",
    "            description='verbosity level:',\n",
    "            tooltips=[\n",
    "                'no logging',\n",
    "                'only errors',\n",
    "                'errors and warnings',\n",
    "                'errors, warnings and info',\n",
    "                'errors, warnings, info and debug',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['verbosity'] = ui_verbosity\n",
    "\n",
    "\n",
    "\n",
    "        cols_num = len(self.df.columns)\n",
    "        rows_num = len(self.df.index)\n",
    "        if '#' not in self.df.columns:\n",
    "            cols_num = len(self.df.columns) + 1\n",
    "        if '#' not in self.df.index:\n",
    "            rows_num = len(self.df.index) + 1\n",
    "\n",
    "        ui_max_cols = widgets.IntSlider(\n",
    "            value=200,\n",
    "            min=0,\n",
    "            max=cols_num*2-1,  #*2 because of metadata columns which get added by diff='new+'\n",
    "            description='columns',\n",
    "            )\n",
    "        kwargs['max_cols'] = ui_max_cols\n",
    "\n",
    "        ui_max_rows = widgets.IntSlider(\n",
    "            value=20,\n",
    "            min=0,\n",
    "            max=rows_num,\n",
    "            description='rows',\n",
    "            )\n",
    "        kwargs['max_rows'] = ui_max_rows\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #                tab2 info                #\n",
    "        ###########################################\n",
    "\n",
    "\n",
    "        ui_gridbox = widgets.GridBox(ui_expressions, layout=widgets.Layout(grid_template_columns=\"repeat(3, 330px)\"))   \n",
    "        tab0 = VBox([ui_gridbox, ui_diff])\n",
    "        tab1 = VBox([ui_inplace, ui_verbosity, HBox([ui_max_cols, ui_max_rows])])\n",
    "        ui_tab = widgets.Tab(\n",
    "            children=[tab0, tab1],\n",
    "            titles=['queries', 'settings'],\n",
    "            )\n",
    "        ui = VBox([ui_tab])\n",
    "        display(ui)\n",
    "\n",
    "\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "\n",
    "        display(out)\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "\n",
    "    df = kwargs.pop('df')\n",
    "    expressions = [val for key, val in kwargs.items() if 'expression' in key]\n",
    "\n",
    "\n",
    "    result = df.q(\n",
    "        *expressions,\n",
    "        diff=kwargs['diff'],\n",
    "        max_cols=kwargs['max_cols'],\n",
    "        max_rows=kwargs['max_rows'],\n",
    "        inplace=kwargs['inplace'],\n",
    "        verbosity=kwargs['verbosity'],\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    display(result)\n",
    "    print('input code: ', df.qp._input)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "df = qp.get_df().format()\n",
    "\n",
    "\n",
    "df.qi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af21f0e21dd7425aba1163fe2f403dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513579024c644827a3f4609f09994a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cards.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         169278 function calls (169224 primitive calls) in 0.420 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 349 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    83233    0.128    0.000    0.186    0.000 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\strings\\object_array.py:144(<lambda>)\n",
      "        2    0.120    0.060    0.306    0.153 {pandas._libs.lib.map_infer_mask}\n",
      "    83234    0.059    0.000    0.059    0.000 {method 'upper' of 'str' objects}\n",
      "        3    0.043    0.014    0.043    0.014 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "        3    0.011    0.004    0.012    0.004 {pandas._libs.lib.maybe_convert_objects}\n",
      "        2    0.011    0.005    0.011    0.005 {built-in method pandas._libs.missing.isnaobj}\n",
      "        2    0.010    0.005    0.010    0.005 {built-in method pandas._libs.lib.ensure_string_array}\n",
      "        4    0.006    0.002    0.008    0.002 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\cast.py:1544(construct_1d_object_array_from_listlike)\n",
      "        3    0.006    0.002    0.006    0.002 {pandas._libs.lib.infer_dtype}\n",
      "       15    0.003    0.000    0.003    0.000 {built-in method numpy.empty}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x2899c2065d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cProfile, pstats\n",
    "import statistics\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "\n",
    "cols = [True for col in cards.columns]\n",
    "rows = [True for row in cards.index]\n",
    "times = []\n",
    "\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True)\n",
    "# print(a)\n",
    "# a = cards.index[rows]\n",
    "# cards.loc[rows, cols]\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n",
    "times.append(stats.total_tt)\n",
    "\n",
    "\n",
    "# print(statistics.mean(times), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "for i in range(100):\n",
    "    cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20989580000000002 [0.2695525, 0.1782757, 0.1733644, 0.17382249999999996, 0.18152440000000003, 0.1757844, 0.17239650000000006, 0.17846470000000003, 0.2548654000000002, 0.34090750000000003]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.types import qp_date, qp_na\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('dat/cards.csv')\n",
    "\n",
    "# cards1 = cards.q('=toughness', '>1 && <4', modify='int(x)+10', inplace=False)\n",
    "\n",
    "# diff(cards1, cards, show='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bashlike\" wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
