{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "import qplib as qp\n",
    "from qplib import log, na, nk, num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:93: UserWarning: registration of accessor <class '__main__.IndexQuery'> under name 'q' for type <class 'pandas.core.indexes.base.Index'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_index_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:223: UserWarning: registration of accessor <class '__main__.SeriesQuery'> under name 'q' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_series_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:349: UserWarning: registration of accessor <class '__main__.DataFrameQuery'> under name 'q' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:1025: UserWarning: registration of accessor <class '__main__.DataFrameQueryInteractiveMode'> under name 'qi' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('qi')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:1230: DtypeWarning: Columns (2,3,7,12,16,20,23,47,52,53,61,62,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cards = pd.read_csv('data/cards.csv').format()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataframe qp.util.logs for tracking log entries\n",
      "use qp.log(message, level, source) or qp.log(message) to add log entries\n",
      "logs are saved in qp.util.logs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fc6ab_row0_col0, #T_fc6ab_row0_col1, #T_fc6ab_row0_col2, #T_fc6ab_row0_col3, #T_fc6ab_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fc6ab\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fc6ab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fc6ab_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_fc6ab_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_fc6ab_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_fc6ab_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_fc6ab_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:36:56.638555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e1750b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dd7cf_row0_col0, #T_dd7cf_row0_col1, #T_dd7cf_row0_col2, #T_dd7cf_row0_col3, #T_dd7cf_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dd7cf\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dd7cf_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_dd7cf_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_dd7cf_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_dd7cf_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_dd7cf_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_dd7cf_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:36:58.485038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e646ba40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6edf2_row0_col0, #T_6edf2_row0_col1, #T_6edf2_row0_col2, #T_6edf2_row0_col3, #T_6edf2_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6edf2\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6edf2_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_6edf2_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_6edf2_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_6edf2_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_6edf2_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_6edf2_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:37:02.090504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e640c380>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6069_row0_col0, #T_c6069_row0_col1, #T_c6069_row0_col2, #T_c6069_row0_col3, #T_c6069_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6069\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6069_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_c6069_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_c6069_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_c6069_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_c6069_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_c6069_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:37:02.100506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e646ba40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb46804a2bf4d90b645d98394855c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d892fe59ded9489dbbf48251e15814a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.pd_util import _check_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "from qplib.pd_util import diff as mv_diff\n",
    "\n",
    "\n",
    "\n",
    "from qplib.types import qp_int, qp_float, qp_num, qp_bool, qp_datetime, qp_date, qp_na, qp_nk, qp_yn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_operators1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'bigger_equal': '>=',\n",
    "    'smaller_equal': '<=',\n",
    "    'bigger': '>',\n",
    "    'smaller': '<',\n",
    "    'strict_equal': '==',\n",
    "    'equal': '=',\n",
    "    'regex_match': '~~',\n",
    "    'regex_search': '~',\n",
    "    'strict_contains': '(())',\n",
    "    'contains': '()',\n",
    "\n",
    "    'lambda_condition': '?',\n",
    "    'lambda_condition_col': 'col?',\n",
    "    })\n",
    "_operators2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'is_str': 'is str',\n",
    "    'is_int': 'is int',\n",
    "    'is_float': 'is float',\n",
    "    'is_num': 'is num',\n",
    "    'is_bool': 'is bool',\n",
    "\n",
    "    'is_datetime': 'is datetime',\n",
    "    'is_date': 'is date',\n",
    "\n",
    "    'is_any': 'is any',\n",
    "    'is_na': 'is na',\n",
    "    'is_nk': 'is nk',\n",
    "    'is_yn': 'is yn',\n",
    "    'is_yes': 'is yes',\n",
    "    'is_no': 'is no',\n",
    "    })\n",
    "_operators = qpDict({**_operators1, **_operators2})\n",
    "_operators_only_df = qpDict({\n",
    "    'lambda_condition_col': _operators['lambda_condition_col'],\n",
    "    })\n",
    "\n",
    "_modifiers1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'set_x': ['x=', 'x ='],\n",
    "    'set_col': ['col=', 'col ='],\n",
    "    'set_row': ['row=', 'row ='],\n",
    "    'set_col_tags': ['col#=', 'col# =', 'col #=', 'col # ='],\n",
    "    'set_row_tags': ['row#=', 'row# =', 'row #=', 'row # ='],\n",
    "    })\n",
    "_modifiers2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'to_str': 'to str',\n",
    "    'to_int': 'to int',\n",
    "    'to_float': 'to float',\n",
    "    'to_num': 'to num',\n",
    "    'to_bool': 'to bool',\n",
    "\n",
    "    'to_datetime': 'to datetime',\n",
    "    'to_date': 'to date',\n",
    "\n",
    "    'to_na': 'to na',\n",
    "    'to_nk': 'to nk',\n",
    "    'to_yn': 'to yn',\n",
    "\n",
    "    'get_num': 'get num',\n",
    "    })\n",
    "_modifiers = qpDict({**_modifiers1, **_modifiers2})\n",
    "_modifiers_only_df = qpDict({\n",
    "    'set_col': _modifiers['set_col'],\n",
    "    'set_row': _modifiers['set_row'],\n",
    "    'set_col_tags': _modifiers['set_col_tags'],\n",
    "    'set_row_tags': _modifiers['set_row_tags'],\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_index_accessor('q')\n",
    "class IndexQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Indices.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, idx: pd.Index):\n",
    "        idx.qp._operators = _operators\n",
    "        idx.qp._operators_only_df = _operators_only_df\n",
    "        idx.qp._modifiers = _modifiers\n",
    "        idx.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.idx = idx \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_index(self.idx)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        idx = self.idx\n",
    "        idx.qp = self.idx.qp\n",
    "        idx.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in idx])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter index', 'modify index'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter index':\n",
    "                ast = _parse_expression(idx, expression, 'filter index', verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(idx, condition, _operators, verbosity, index=idx)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                        log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='idx.q', input=idx.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify index':\n",
    "                ast = _parse_expression_modify(idx, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = idx.to_series()\n",
    "                    se.qp = idx.qp\n",
    "                    idx = pd.Index(_apply_modification(se, index_expression, modification, verbosity, index=idx))\n",
    "                    idx.qp = self.idx.qp\n",
    "        \n",
    "\n",
    "\n",
    "        idx_filtered = idx[index_expression]\n",
    "        idx_filtered.qp = idx.qp\n",
    "\n",
    "        return idx_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_series_accessor('q')\n",
    "class SeriesQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Series.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, se: pd.Series):\n",
    "        se.qp._operators = _operators\n",
    "        se.qp._operators_only_df = _operators_only_df\n",
    "        se.qp._modifiers = _modifiers\n",
    "        se.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.se = se \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_series(self.se)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        se = copy.deepcopy(self.se)\n",
    "        se.qp = self.se.qp\n",
    "        se.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in se])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter series', 'modify series'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter series':\n",
    "                ast = _parse_expression(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(se, condition, _operators, verbosity, series=se)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                    log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='se.q', input=se.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify series':\n",
    "                ast = _parse_expression_modify(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = _apply_modification(se, index_expression, modification, verbosity, series=se)\n",
    "                    se.qp = self.se.qp\n",
    "\n",
    "\n",
    "        se_filtered = se[index_expression]\n",
    "        se_filtered.qp = se.qp\n",
    "        return se_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data and metadata in pandas DataFrames.\n",
    "\n",
    "    each query consists of 3 string expressions, any of which can be left empty:\n",
    "        1. column filter: '=col1', '!=col2', '()1 // ()2'\n",
    "        2. row filter: 'is date', 'is int && >0', '? len(str(x)) > 5'\n",
    "        3. (meta-)data modification: 'x= str(x)', 'col#= integer column', 'row#= positive'\n",
    "\n",
    "    eg.: df.q('=col1', 'is int && >0', 'row#= positive')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "        col=: set whole column to a value\n",
    "        row=: set whole row to a value\n",
    "        col#=: tag columns\n",
    "        row#=: tag rows\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        _check_df(df)\n",
    "        self.df = df\n",
    "        self.df.qp._operators = _operators\n",
    "        self.df.qp._modifiers = _modifiers\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self,\n",
    "            *expressions,  #string expressions for filtering and modifying data\n",
    "            diff=None,  #[None, 'mix', 'old', 'new', 'new+']\n",
    "            max_cols=200,  #maximum number of columns to display. None: show all\n",
    "            max_rows=20,  #maximum number of rows to display. None: show all\n",
    "            inplace=True,  #make modifications inplace or just return a new dataframe\n",
    "            verbosity=3,  #verbosity level for logging. 0: no logging, 1: errors, 2: warnings, 3: info, 4: debug\n",
    "            **kwargs\n",
    "            ):\n",
    "\n",
    "        ###########################################\n",
    "        #                  setup                  #\n",
    "        ###########################################\n",
    "\n",
    "        #input string for logging\n",
    "        input_str = \".q(\"\n",
    "        for i,expression in enumerate(expressions):\n",
    "            if (i+1)%3 == 1:\n",
    "                input_str += f\"\\n\\t{expression !r},\"\n",
    "            else:\n",
    "                input_str += f\" {expression !r},\"\n",
    "   \n",
    "        if diff is not None:\n",
    "            input_str += f\"\\n\\tdiff='{diff}',\"\n",
    "        if max_cols is not None:\n",
    "            input_str += f\"\\n\\tmax_cols={max_cols},\"\n",
    "        if max_rows is not None:\n",
    "            input_str += f\"\\n\\tmax_rows={max_rows},\"\n",
    "        \n",
    "        input_str += f\"\\n\\tinplace={inplace},\"\n",
    "        input_str += f\"\\n\\tverbosity={verbosity},\"\n",
    "\n",
    "        for kwarg in kwargs:\n",
    "            input_str += f\"\\n\\t{kwarg}='{kwargs[kwarg]}'\"\n",
    "\n",
    "        self.df.qp._input = input_str + \"\\n\\t)\"\n",
    "\n",
    "\n",
    "    \n",
    "        if inplace is False:\n",
    "            df = self.df.copy()\n",
    "        else:\n",
    "            df = self.df\n",
    "            \n",
    "        df.qp = self.df.qp\n",
    "\n",
    "        \n",
    "\n",
    "        #inserting metadata row at the top, sadly a bit hacky\n",
    "        #because there does not seem to be an inplace function for that\n",
    "        if '#' not in df.index:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a row named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata row now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df_old = df.copy()\n",
    "            index_old = df.index\n",
    "            index_new = pd.Index(['#', *index_old])\n",
    "            \n",
    "            df.loc['#'] = ''\n",
    "            df.set_index(index_new, inplace=True)\n",
    "            df.loc[index_old, :] = df_old\n",
    "            df.loc['#'] = ''\n",
    "\n",
    "        #inserting metadata column at the start\n",
    "        if '#' not in df.columns:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a column named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata column now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df.insert(0, '#', '')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        ###########################################\n",
    "        #               run queries               #\n",
    "        ###########################################\n",
    "\n",
    "        cols_filtered = cols_filtered_condition = pd.Index([True for col in df.columns])\n",
    "        rows_filtered = rows_filtered_condition = rows_filtered_col = pd.Index([True for row in df.index])\n",
    "        \n",
    "\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['col', 'row', 'modify'][i_expression%3]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            #filter columns\n",
    "            if expression_type == 'col':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    if condition['by_tag'] == 'row or col metadata':\n",
    "                        cols_filtered_new = _apply_condition(df.loc['#'], condition, _operators, verbosity, df=df)\n",
    "                    else:\n",
    "                        cols_filtered_new = _apply_condition(df.columns, condition, _operators, verbosity, df=df)\n",
    "\n",
    "                    cols_filtered_condition = _update_index(cols_filtered_condition, cols_filtered_new, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                cols_filtered = _update_index(cols_filtered, cols_filtered_condition, ast['connector'], i_expression, verbosity=verbosity)\n",
    "\n",
    "                if cols_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no columns fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            #filter rows\n",
    "            elif expression_type == 'row':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    for i_col,col in enumerate(df.columns[cols_filtered_condition][1:]):  #ignore metadata column\n",
    "                        if condition['by_tag'] == 'row or col metadata':\n",
    "                            rows_filtered_new = _apply_condition(df['#'], condition, _operators, verbosity, df=df)\n",
    "                        else:\n",
    "                            rows_filtered_new = _apply_condition(df[col], condition, _operators, verbosity, df=df)\n",
    "\n",
    "                        rows_filtered_col = _update_index(rows_filtered_col, rows_filtered_new, condition['which_cols'], i_col, verbosity=verbosity)\n",
    "                    rows_filtered_condition = _update_index(rows_filtered_condition, rows_filtered_col, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                rows_filtered = _update_index(rows_filtered, rows_filtered_condition, ast['connector'], i_expression-1, verbosity=verbosity)\n",
    "\n",
    "                if rows_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no rows fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "\n",
    "\n",
    "            #modify data\n",
    "            elif expression_type == 'modify':\n",
    "                cols_filtered_no_metadata = [col for col in df.columns[cols_filtered] if not col.startswith('#')]\n",
    "                rows_filtered_no_metadata = [row for row in df.index[rows_filtered] if row != '#']\n",
    "\n",
    "                ast = _parse_expression_modify(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                            \n",
    "                    #tag columns\n",
    "                    if modification['modifier'] in _modifiers['set_col_tags']:\n",
    "                        df.loc['#', cols_filtered_no_metadata] = df.loc['#', cols_filtered_no_metadata].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #tag rows\n",
    "                    elif modification['modifier'] in _modifiers['set_row_tags']:\n",
    "                        df.loc[rows_filtered_no_metadata, '#'] = df.loc[rows_filtered_no_metadata, '#'].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #modify filtered data\n",
    "                    else:\n",
    "                        df.loc[:, :] = _apply_modification_df(df, rows_filtered_no_metadata, cols_filtered_no_metadata, modification, verbosity).loc[:, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################\n",
    "        #            display settings            #\n",
    "        ##########################################\n",
    "   \n",
    "        df_filtered = df.loc[rows_filtered, cols_filtered]\n",
    "        df_filtered.qp = self.df.qp\n",
    "    \n",
    "        if diff is None:\n",
    "\n",
    "            cols_num = len(df.columns[cols_filtered])\n",
    "            rows_num = len(df.index[rows_filtered])\n",
    "\n",
    "            if verbosity >= 2:\n",
    "                if max_cols is not None and max_cols < cols_num:\n",
    "                    log(f'showing {max_cols} out of {cols_num} columns', level='warning', source='df.q', input=df.qp._input)\n",
    "                if max_rows is not None and max_rows < rows_num:\n",
    "                    log(f'showing {max_rows} out of {rows_num} rows', level='warning', source='df.q', input=df.qp._input)\n",
    " \n",
    "            pd.set_option('display.max_columns', max_cols)\n",
    "            pd.set_option('display.max_rows', max_rows)\n",
    "            pd.set_option('display.min_rows', max_rows)\n",
    "\n",
    "            return df_filtered\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            #show difference before and after filtering\n",
    "            result = qp.diff(\n",
    "                df_filtered, self.df, show=diff,\n",
    "                max_cols=max_cols, max_rows=max_rows,\n",
    "                verbosity=verbosity)  \n",
    "            return  result\n",
    "\n",
    "\n",
    "\n",
    "def _parse_expression(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'connector': None,\n",
    "        'conditions': [],\n",
    "        }\n",
    "    \n",
    "    if expression[:2] not in ['&&', '//', '>>']:\n",
    "        expression = '>>' + expression\n",
    "\n",
    "    ast['connector'] = expression[:2]\n",
    "\n",
    "\n",
    "    expressions = re.split('(&&|//|>>)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {'expression': expressions[ind], 'mode': mode}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&', '//', '>>']:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if expressions[ind-1] == '&&':  #and\n",
    "            condition['condition_connector'] = '&&'\n",
    "        elif expressions[ind-1] == '//':  #inclusive or\n",
    "            condition['condition_connector'] = '//'\n",
    "        elif expressions[ind-1] == '>>':  #reset\n",
    "            condition['condition_connector'] = '>>'\n",
    "\n",
    "        \n",
    "        #row conditions also specify in which cols the condition is applied. default: any\n",
    "        if mode == 'row':\n",
    "            if condition_str.startswith('any'):\n",
    "                condition['which_cols'] = 'any'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            elif condition_str.startswith('all'):\n",
    "                condition['which_cols'] = 'all'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            else:\n",
    "                condition['which_cols'] = 'any'\n",
    "\n",
    "\n",
    "        #rows and cols can be filtered by metadata\n",
    "        if condition_str.startswith('#'):\n",
    "            condition['by_tag'] = 'row or col metadata'\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['by_tag'] = False\n",
    "\n",
    "        #wip\n",
    "        # if condition_str.startswith('x#'):\n",
    "        #     condition['by_tag_value'] = 'value metadata'\n",
    "        #     condition_str = condition_str[1:].lstrip()\n",
    "        # else:\n",
    "        #     condition['by_tag_value'] = False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #should the condition be negated. default: False\n",
    "        if condition_str.startswith('!'):\n",
    "            condition['negate'] = True\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['negate'] = False\n",
    "\n",
    "\n",
    "        #operator for condition. default: =\n",
    "        for operator in _operators.values_flat():\n",
    "            if condition_str.startswith(operator):\n",
    "                condition['operator'] = operator\n",
    "                condition_str = condition_str[len(operator):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'operator' not in condition:\n",
    "            if verbosity >= 3:\n",
    "                log(f'no operator found in condition \"{condition_str}\". Using default operator \"=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['operator'] = '='\n",
    "\n",
    "\n",
    "        if mode in ['filter series', 'filter index'] and condition['operator'] in _operators_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "        \n",
    "        if condition['operator'] in _operators2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #value for comparison\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['conditions'].append(condition)\n",
    "\n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "        \n",
    "    return ast\n",
    "\n",
    "def _parse_expression_modify(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'modifications': [],\n",
    "        }\n",
    "    \n",
    "\n",
    "    expressions = re.split('(&&)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&']:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #modifier to use. default: \"set x:\"\n",
    "        for modifier in _modifiers.values_flat():\n",
    "            if condition_str.startswith(modifier):\n",
    "                condition['modifier'] = modifier\n",
    "                condition_str = condition_str[len(modifier):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'modifier' not in condition:\n",
    "            if verbosity > 3:\n",
    "                log(f'no modifier found in condition \"{condition_str}\". Using default modifier \"x=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['modifier'] = 'x='\n",
    "\n",
    "        if mode in ['modify series', 'modify index'] and condition['modifier'] in _modifiers_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "\n",
    "        if condition['modifier'] in _modifiers2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #expression used for modification\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['modifications'].append(condition)\n",
    "        \n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "    \n",
    "    return ast\n",
    "\n",
    "\n",
    "def _apply_condition(pd_object, condition, operators, verbosity=3, df=None, series=None, index=None):\n",
    "    \"\"\"\n",
    "    filters a pandas object using a query condition\n",
    "    \"\"\"\n",
    "\n",
    "    value = condition['value']\n",
    "\n",
    "    if isinstance(pd_object, pd.Index):\n",
    "        pd_object = pd_object.to_series()\n",
    "\n",
    "    \n",
    "    match condition['operator']:\n",
    "        #numeric comparison\n",
    "        case operators.bigger_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') >= pd.to_numeric(value)\n",
    "        case operators.smaller_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') <= pd.to_numeric(value)\n",
    "        case operators.bigger:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') > pd.to_numeric(value)\n",
    "        case operators.smaller:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') < pd.to_numeric(value)\n",
    "        \n",
    "        \n",
    "        #regex comparison\n",
    "        case operators.regex_match:\n",
    "            filtered = pd_object.astype(str).str.fullmatch(value) \n",
    "        case operators.regex_search:\n",
    "            filtered = pd_object.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "        #string equality comparison\n",
    "        case operators.strict_equal:\n",
    "            filtered = pd_object.astype(str) == value\n",
    "        case operators.equal:\n",
    "            value_lenient = [value]\n",
    "            try:\n",
    "                value_lenient.append(str(float(value)))\n",
    "                value_lenient.append(str(int(float(value))))\n",
    "            except:\n",
    "                value_lenient.append(value.lower())\n",
    "            filtered = pd_object.astype(str).str.lower().isin(value_lenient)\n",
    "        \n",
    "        #substring comparison\n",
    "        case operators.strict_contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=True, regex=False)\n",
    "        case operators.contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "\n",
    "        #lambda function\n",
    "        case operators.lambda_condition:\n",
    "            filtered = pd_object.apply(lambda x, df=df, series=series, index=index, pd=pd, np=np: eval(value))\n",
    "        case operators.lambda_condition_col:\n",
    "            filtered = eval(value, {'col': pd_object, 'df': df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "\n",
    "\n",
    "        #type checks\n",
    "        case operators.is_bool:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, bool))\n",
    "        case operators.is_str:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, str))\n",
    "        case operators.is_int:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, int))\n",
    "        case operators.is_float:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, float))\n",
    "        case operators.is_num:\n",
    "            filtered = pd_object.apply(lambda x: qp_num(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_date:\n",
    "            filtered = pd_object.apply(lambda x: qp_date(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_datetime:\n",
    "            filtered = pd_object.apply(lambda x: qp_datetime(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_any:\n",
    "            filtered = pd_object.apply(lambda x: True)\n",
    "        case operators.is_na:\n",
    "            filtered = pd_object.apply(lambda x: qp_na(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_nk:\n",
    "            filtered = pd_object.apply(lambda x: qp_nk(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yn:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yes:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', yes=1)) == 1\n",
    "        case operators.is_no:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', no=0)) == 0\n",
    "\n",
    "        case _:\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" is not implemented', level='error', source='_apply_condition()', input=pd_object.qp._input)\n",
    "            filtered = None\n",
    "\n",
    "\n",
    "    if condition['negate']:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    if condition['mode'] in ['col', 'row']:\n",
    "        filtered.iloc[0] = True  #metadata row/column should always be included\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def _apply_modification(pd_object, indices, modification, verbosity=3, series=None, index=None):\n",
    "    modifiers = pd_object.qp._modifiers\n",
    "\n",
    "    #data modification\n",
    "    if modification['modifier'] in modifiers['set_x']:\n",
    "        pd_object[indices] = pd_object[indices].map(lambda x, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "\n",
    "    #type conversion\n",
    "    elif modification['modifier'] == modifiers['to_str']:\n",
    "        pd_object[indices] = pd_object[indices].map(str)\n",
    "    elif modification['modifier'] == modifiers['to_int']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_int)\n",
    "    elif modification['modifier'] == modifiers['to_float']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_float)\n",
    "    elif modification['modifier'] == modifiers['to_num']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_num)\n",
    "    elif modification['modifier'] == modifiers['to_bool']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_bool)\n",
    "    \n",
    "    elif modification['modifier'] == modifiers['to_date']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_date)\n",
    "    elif modification['modifier'] == modifiers['to_datetime']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_datetime)\n",
    "    elif modification['modifier'] == modifiers['to_na']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_na)\n",
    "    elif modification['modifier'] == modifiers['to_nk']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_nk)\n",
    "    elif modification['modifier'] == modifiers['to_yn']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_yn)\n",
    "\n",
    "    return pd_object\n",
    "\n",
    "def _apply_modification_df(df, rows, cols, modification, verbosity=3):\n",
    "    modifiers = df.qp._modifiers\n",
    "\n",
    "    if pd.__version__ >= '2.1.0':\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_yn)\n",
    "\n",
    "    else:\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_yn) \n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def _update_index(values, values_new, connector, i, verbosity=3):\n",
    "    if i == 0:\n",
    "        values = values_new\n",
    "    elif connector == '>>':\n",
    "        values = values_new\n",
    "    elif connector in ['&&', 'all']:\n",
    "        values &= values_new\n",
    "    elif connector in ['//', 'any']:\n",
    "        values |= values_new\n",
    "    else:\n",
    "        if verbosity >= 1:\n",
    "            log(f'connector \"{connector}\" is not implemented', level='error', source='_update_index()')\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for df.q() for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self, num_filters=5):\n",
    "        kwargs = {'df': fixed(self.df)}\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #            tab0 queries&diff            #\n",
    "        ###########################################\n",
    "\n",
    "        ui_label_filter_cols = widgets.Label(value='filter columns')\n",
    "        ui_label_filter_rows = widgets.Label(value='filter rows')\n",
    "        ui_label_modify_data = widgets.Label(value='modify data')\n",
    "        ui_expressions = [ui_label_filter_cols, ui_label_filter_rows, ui_label_modify_data]\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(num_filters):\n",
    "            if i == 0:\n",
    "                placeholder_col = '=name'\n",
    "                placeholder_row = '()john'\n",
    "                placeholder_modify = 'x= x.upper() '\n",
    "            elif i == 1:\n",
    "                placeholder_col = '// =age'\n",
    "                placeholder_row = '&& <0 // >120'\n",
    "                placeholder_modify = 'row#= \"implausible age\" '\n",
    "            elif i == 2:\n",
    "                placeholder_col = '// =weight // =height'\n",
    "                placeholder_row = '!is num'\n",
    "                placeholder_modify = 'to num'\n",
    "            else:\n",
    "                placeholder_col = ''\n",
    "                placeholder_row = ''\n",
    "                placeholder_modify = ''\n",
    "            \n",
    "\n",
    "            col = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_col,\n",
    "                options=['=' + col for col in self.df.columns if col != '#'],\n",
    "                )\n",
    "            kwargs[f'col_expression{i}'] = col\n",
    "            ui_expressions.append(col)\n",
    "            \n",
    "            row = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_row,\n",
    "                options=[\n",
    "                    '>0', '<0', '>=0', '<=0',  #numerical comparison\n",
    "                    '=abc', '!=abc', '==AbC', '!==AbC',  #equality checks\n",
    "                    '()abc', '(())AbC',  #substring checks\n",
    "                    '~*a.c', '~~*a.c',  #regex checks\n",
    "                    \n",
    "                    '? len(x) > 3',  #lambda function condition for each value\n",
    "                    'col? col > df[\"age\"]',  #lambda function condition for whole columns\n",
    "\n",
    "                    #type checks\n",
    "                    'is str', 'is int', 'is float', 'is num', 'is bool',\n",
    "                    'is date', 'is datetime',\n",
    "                    'is any', 'is na', 'is nk',\n",
    "                    'is yn', 'is yes', 'is no'\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'row_expression{i}'] = row\n",
    "            ui_expressions.append(row)\n",
    "            \n",
    "            modify = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_modify,\n",
    "                options=[\n",
    "                    'x= x.upper() ', 'col= df[\"ID\"]', 'row= df.loc[0]',  #change data\n",
    "                    'col#= \"tag\" ', 'col#= x + \"tag\" ', 'row#= \"tag\" ', 'row#= x + \"tag\"',  #change metadata\n",
    "\n",
    "                    #change type\n",
    "                    'to str', 'to int', 'to float', 'to num', 'to bool',\n",
    "                    'to date', 'to datetime',\n",
    "                    'to na', 'to nk', 'to yn',\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'modify_expression{i}'] = modify\n",
    "            ui_expressions.append(modify)\n",
    "        \n",
    "\n",
    "        #show differences\n",
    "        ui_diff = widgets.ToggleButtons(\n",
    "            options=[None, 'mix', 'old', 'new', 'new+'],\n",
    "            description='show differences mode:',\n",
    "            tooltips=[\n",
    "                'dont show differences, just show the new (filtered) dataframe.',\n",
    "                'show new (filtered) dataframe plus all the removed (filtered) values from the old dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show old (unfiltered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe but also adds metadata columns with the prefix \"#\". If a value changed, the metadata column contains the old value. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['diff'] = ui_diff\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #              tab1 settings              #\n",
    "        ###########################################\n",
    "\n",
    "        ui_inplace = widgets.ToggleButtons(\n",
    "            options=[True, False],\n",
    "            value=False,\n",
    "            description='make modifications inplace:',\n",
    "            tooltips=[\n",
    "                'make modifications inplace, e.g. change the original dataframe',\n",
    "                'return a new dataframe with the modifications',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['inplace'] = ui_inplace\n",
    "\n",
    "        ui_verbosity = widgets.ToggleButtons(\n",
    "            options=[0, 1, 2, 3, 4],\n",
    "            value=3,\n",
    "            description='verbosity level:',\n",
    "            tooltips=[\n",
    "                'no logging',\n",
    "                'only errors',\n",
    "                'errors and warnings',\n",
    "                'errors, warnings and info',\n",
    "                'errors, warnings, info and debug',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['verbosity'] = ui_verbosity\n",
    "\n",
    "\n",
    "\n",
    "        cols_num = len(self.df.columns)\n",
    "        rows_num = len(self.df.index)\n",
    "        if '#' not in self.df.columns:\n",
    "            cols_num = len(self.df.columns) + 1\n",
    "        if '#' not in self.df.index:\n",
    "            rows_num = len(self.df.index) + 1\n",
    "\n",
    "        ui_max_cols = widgets.IntSlider(\n",
    "            value=200,\n",
    "            min=0,\n",
    "            max=cols_num*2-1,  #*2 because of metadata columns which get added by diff='new+'\n",
    "            description='columns',\n",
    "            )\n",
    "        kwargs['max_cols'] = ui_max_cols\n",
    "\n",
    "        ui_max_rows = widgets.IntSlider(\n",
    "            value=20,\n",
    "            min=0,\n",
    "            max=rows_num,\n",
    "            description='rows',\n",
    "            )\n",
    "        kwargs['max_rows'] = ui_max_rows\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #                tab2 info                #\n",
    "        ###########################################\n",
    "\n",
    "\n",
    "        ui_gridbox = widgets.GridBox(ui_expressions, layout=widgets.Layout(grid_template_columns=\"repeat(3, 330px)\"))   \n",
    "        tab0 = VBox([ui_gridbox, ui_diff])\n",
    "        tab1 = VBox([ui_inplace, ui_verbosity, HBox([ui_max_cols, ui_max_rows])])\n",
    "        ui_tab = widgets.Tab(\n",
    "            children=[tab0, tab1],\n",
    "            titles=['queries', 'settings'],\n",
    "            )\n",
    "        ui = VBox([ui_tab])\n",
    "        display(ui)\n",
    "\n",
    "\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "\n",
    "        display(out)\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "\n",
    "    df = kwargs.pop('df')\n",
    "    expressions = [val for key, val in kwargs.items() if 'expression' in key]\n",
    "\n",
    "\n",
    "    result = df.q(\n",
    "        *expressions,\n",
    "        diff=kwargs['diff'],\n",
    "        max_cols=kwargs['max_cols'],\n",
    "        max_rows=kwargs['max_rows'],\n",
    "        inplace=kwargs['inplace'],\n",
    "        verbosity=kwargs['verbosity'],\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    display(result)\n",
    "    print('input code: ', df.qp._input)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "df = qp.get_df().format()\n",
    "\n",
    "\n",
    "df.qi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af21f0e21dd7425aba1163fe2f403dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513579024c644827a3f4609f09994a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cards.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         169278 function calls (169224 primitive calls) in 0.420 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 349 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    83233    0.128    0.000    0.186    0.000 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\strings\\object_array.py:144(<lambda>)\n",
      "        2    0.120    0.060    0.306    0.153 {pandas._libs.lib.map_infer_mask}\n",
      "    83234    0.059    0.000    0.059    0.000 {method 'upper' of 'str' objects}\n",
      "        3    0.043    0.014    0.043    0.014 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "        3    0.011    0.004    0.012    0.004 {pandas._libs.lib.maybe_convert_objects}\n",
      "        2    0.011    0.005    0.011    0.005 {built-in method pandas._libs.missing.isnaobj}\n",
      "        2    0.010    0.005    0.010    0.005 {built-in method pandas._libs.lib.ensure_string_array}\n",
      "        4    0.006    0.002    0.008    0.002 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\cast.py:1544(construct_1d_object_array_from_listlike)\n",
      "        3    0.006    0.002    0.006    0.002 {pandas._libs.lib.infer_dtype}\n",
      "       15    0.003    0.000    0.003    0.000 {built-in method numpy.empty}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x2899c2065d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cProfile, pstats\n",
    "import statistics\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "\n",
    "cols = [True for col in cards.columns]\n",
    "rows = [True for row in cards.index]\n",
    "times = []\n",
    "\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True)\n",
    "# print(a)\n",
    "# a = cards.index[rows]\n",
    "# cards.loc[rows, cols]\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n",
    "times.append(stats.total_tt)\n",
    "\n",
    "\n",
    "# print(statistics.mean(times), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "for i in range(100):\n",
    "    cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20989580000000002 [0.2695525, 0.1782757, 0.1733644, 0.17382249999999996, 0.18152440000000003, 0.1757844, 0.17239650000000006, 0.17846470000000003, 0.2548654000000002, 0.34090750000000003]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.types import qp_date, qp_na\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('dat/cards.csv')\n",
    "\n",
    "# cards1 = cards.q('=toughness', '>1 && <4', modify='int(x)+10', inplace=False)\n",
    "\n",
    "# diff(cards1, cards, show='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def qp_int(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return int(float(x))  #float first to handle strings like '1.0'\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to integer.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_float(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to float.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "            \n",
    "def qp_num(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return pd.to_numeric(x)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to numeric.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "            \n",
    "def qp_bool(x, errors='coerce', na=None):\n",
    "    if str(x).lower() in ['y', 'yes', 'true', '1', '1.0', 'positive', 'pos']:\n",
    "        return True\n",
    "    elif str(x).lower() in ['n', 'no', 'false', '0', '0.0', 'negative', 'neg']:\n",
    "        return False\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to boolean.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "\n",
    "def qp_date(x, errors='coerce', na=pd.NaT):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '-')\n",
    "    try:\n",
    "        if re.match(r'\\D*(1|2)\\d\\d\\d', x):\n",
    "            return pd.to_datetime(x, dayfirst=False).date()\n",
    "        else:\n",
    "            return pd.to_datetime(x, dayfirst=True).date()\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to date.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaT\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "       \n",
    "def qp_datetime(x, errors='coerce', na=pd.NaT):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '-')\n",
    "    try:\n",
    "        if re.match(r'\\D*(1|2\\d\\d\\d)', x):\n",
    "            return pd.to_datetime(x, dayfirst=False)\n",
    "        else:\n",
    "            return pd.to_datetime(x, dayfirst=True)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to datetime.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaT\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "\n",
    "def qp_na(x, errors='ignore', na=None):\n",
    "    possible_nas = [\n",
    "        'not available', 'na', 'n/a', 'n.a', 'n.a.', 'na.', 'n.a',\n",
    "        'not a number', 'nan',\n",
    "        'null', 'nil',\n",
    "        'none',\n",
    "        '',\n",
    "        ]\n",
    "    \n",
    "    if pd.isna(x) or str(x).lower() in possible_nas:\n",
    "        return na\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{na}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return None\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_nk(x, errors='ignore', nk='unknown'):\n",
    "    possible_nks = [\n",
    "        'unk', 'unknown', 'not known', 'not known.',\n",
    "        'nk', 'n.k.', 'n.k', 'n/k',\n",
    "        'not specified', 'not specified.',\n",
    "        ]\n",
    "    \n",
    "    if str(x).lower() in possible_nks:\n",
    "        return nk\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{nk}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return None\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_yn(x, errors='coerce', yes='yes', no='no', na=None):\n",
    "    if str(x).lower() in ['y', 'yes', 'true', '1', '1.0', 'positive', 'pos']:\n",
    "        return yes\n",
    "    elif str(x).lower() in ['n', 'no', 'false', '0', '0.0', 'negative', 'neg']:\n",
    "        return no\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{yes}\" or \"{no}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"123,456.789\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mlib.pyx:2368\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"123,456.789\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#assign resulting substring to a\u001b[39;00m\n\u001b[0;32m      4\u001b[0m a \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+([,.]\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123,456.789 0123\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m456_789a4b5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\tools\\numeric.py:222\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    220\u001b[0m coerce_numeric \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     values, new_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]  # noqa: E501\u001b[39;49;00m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mlib.pyx:2410\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"123,456.789\" at position 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_789']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the regex pattern to match a sequence of numbers allowing for different kinds of separators\n",
    "pattern = r\"\\d+([,.\\s_]\\d+)*\"\n",
    "\n",
    "# Example string to match against\n",
    "example_string = \"123,456.789 0123\\t456_789\"\n",
    "\n",
    "# Perform the search\n",
    "matches = re.findall(pattern, example_string)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bashlike\" wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataframe qp.util.logs for tracking log entries\n",
      "use qp.log(message, level, source) or qp.log(message) to add log entries\n",
      "logs are saved in qp.util.logs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_50450_row0_col0, #T_50450_row0_col1, #T_50450_row0_col2, #T_50450_row0_col3, #T_50450_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_50450\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_50450_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_50450_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_50450_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_50450_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_50450_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_50450_row0_col4\" class=\"data row0 col4\" >2024-07-02 11:56:11.806694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d16fa74620>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0a83_row0_col0, #T_f0a83_row0_col1, #T_f0a83_row0_col2, #T_f0a83_row0_col3, #T_f0a83_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0a83\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a83_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_f0a83_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_f0a83_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_f0a83_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_f0a83_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_f0a83_row0_col4\" class=\"data row0 col4\" >2024-07-02 11:56:14.566558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d16f6839e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c8e154872943b68f8a8ca55a894c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ed273938d043489fa5e2419a0c6733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dis\n",
    "import qplib as qp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = qp.get_df().format()\n",
    "\n",
    "df.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2b54a_row0_col0, #T_2b54a_row0_col1, #T_2b54a_row0_col2, #T_2b54a_row0_col3, #T_2b54a_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2b54a\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2b54a_level0_row0\" class=\"row_heading level0 row0\" >4</th>\n",
       "      <td id=\"T_2b54a_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_2b54a_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_2b54a_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_2b54a_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_2b54a_row0_col4\" class=\"data row0 col4\" >2024-07-02 16:23:16.165280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e213e12d80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fc4bf_row0_col0, #T_fc4bf_row0_col1, #T_fc4bf_row0_col2, #T_fc4bf_row0_col3, #T_fc4bf_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fc4bf\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fc4bf_level0_row0\" class=\"row_heading level0 row0\" >5</th>\n",
       "      <td id=\"T_fc4bf_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_fc4bf_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_fc4bf_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_fc4bf_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_fc4bf_row0_col4\" class=\"data row0 col4\" >2024-07-02 16:23:16.172794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e213ddcf80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MartinVölkl-GouyaIns\\OneDrive - Gouya Insights\\Desktop\\qplib\\qplib\\types.py:97: UserWarning: Parsing dates in %m-%d-%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, dayfirst=True).date()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>date of birth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp systole</th>\n",
       "      <th>bp diastole</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>10001</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>170</td>\n",
       "      <td>70.2</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>10kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>10002</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>1990-09-14</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>175.5cm</td>\n",
       "      <td>68</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>Highe</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>10003</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>1985-08-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>72.5lb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15 mg once a day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>20001</td>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>1980-04-06</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>280</td>\n",
       "      <td>na</td>\n",
       "      <td>140</td>\n",
       "      <td>90mmHg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>no</td>\n",
       "      <td>20mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>20002</td>\n",
       "      <td>Eva White</td>\n",
       "      <td>2007-11-05</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>135mmhg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>yes</td>\n",
       "      <td>20 Mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>20003</td>\n",
       "      <td>Frank Miller</td>\n",
       "      <td>1983-06-30</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>185</td>\n",
       "      <td>75kg</td>\n",
       "      <td>125</td>\n",
       "      <td>75</td>\n",
       "      <td>High</td>\n",
       "      <td>yes</td>\n",
       "      <td>25g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>30001</td>\n",
       "      <td>Grace Taylor</td>\n",
       "      <td>1975-05-28</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>30002</td>\n",
       "      <td>Harry Clark</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ft 1in</td>\n",
       "      <td>80.3</td>\n",
       "      <td>122</td>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>30003</td>\n",
       "      <td>Ivy Green</td>\n",
       "      <td>1955-01-09</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-10</td>\n",
       "      <td>130lbs</td>\n",
       "      <td></td>\n",
       "      <td>95</td>\n",
       "      <td>high</td>\n",
       "      <td>None</td>\n",
       "      <td>30 MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>30004</td>\n",
       "      <td>Jack Williams</td>\n",
       "      <td>1950-09-10</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>30005</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1945-10-11</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>200</td>\n",
       "      <td>-65</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>yes</td>\n",
       "      <td>40ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #     ID           name date of birth   age gender   height  weight  \\\n",
       "#                                                                        \n",
       "0     10001       John Doe    1995-01-02  None      M      170    70.2   \n",
       "1     10002     Jane Smith    1990-09-14    30      F  175.5cm      68   \n",
       "2     10003  Alice Johnson    1985-08-23   NaN      F     None  72.5lb   \n",
       "3     20001      Bob Brown    1980-04-06  None      M      280      na   \n",
       "4     20002      Eva White    2007-11-05  40.0  Other      NaN           \n",
       "5     20003   Frank Miller    1983-06-30  None      M      185    75kg   \n",
       "6     30001   Grace Taylor    1975-05-28  None      F        1    None   \n",
       "7     30002    Harry Clark           NaT  None    NaN  6ft 1in    80.3   \n",
       "8     30003      Ivy Green    1955-01-09         None      -10  130lbs   \n",
       "9     30004  Jack Williams    1950-09-10  None      M               82   \n",
       "10    30005       John Doe    1945-10-11    35      F      200     -65   \n",
       "\n",
       "   bp systole bp diastole cholesterol diabetes              dose  \n",
       "#                                                                 \n",
       "0          20          80      Normal       no              10kg  \n",
       "1         130          85       Highe      yes               NaN  \n",
       "2         NaN         nan         NaN     None  15 mg once a day  \n",
       "3         140      90mmHg        GOOD       no              20mg  \n",
       "4     135mmhg         NaN        n.a.      yes             20 Mg  \n",
       "5         125          75        High      yes               25g  \n",
       "6         NAN         NaN      Normal       no               NaN  \n",
       "7         122        None         n/a     None              None  \n",
       "8                      95        high     None             30 MG  \n",
       "9         130           0                   no                35  \n",
       "10         45         NaN      Normal      yes              40ml  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qplib as qp\n",
    "\n",
    "df = qp.get_df().format()\n",
    "\n",
    "df.q(\n",
    "\t'=name', 'is any', 'x = x.title()',\n",
    "\t'=date of birth', 'is any', 'to date',\n",
    "\t'=age', '!is num // <0', 'x=None',\n",
    "\t'=gender', \"? str(x).lower()  in  ['m', 'male', 'mal']\", 'x = \"M\"',\n",
    "    '=gender', \"? str(x).lower()  in  ['f', 'female', 'ff']\", 'x = \"F\"',\n",
    "    '=diabetes', 'is any', 'to yn',\n",
    "\t'>> is any', '>> is any', '',\n",
    "\tdiff=None,\n",
    "\tinplace=False,\n",
    "\tverbosity=3,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disassembly of __call__:\n",
      "              0 MAKE_CELL               37 (modification)\n",
      "\n",
      "442           2 RESUME                   0\n",
      "\n",
      "457           4 LOAD_CONST               1 ('.q(')\n",
      "              6 STORE_FAST               8 (input_str)\n",
      "\n",
      "458           8 LOAD_GLOBAL              1 (NULL + enumerate)\n",
      "             18 LOAD_FAST                6 (expressions)\n",
      "             20 CALL                     1\n",
      "             28 GET_ITER\n",
      "        >>   30 FOR_ITER                35 (to 104)\n",
      "             34 UNPACK_SEQUENCE          2\n",
      "             38 STORE_FAST               9 (i)\n",
      "             40 STORE_FAST              10 (expression)\n",
      "\n",
      "459          42 LOAD_FAST                9 (i)\n",
      "             44 LOAD_CONST               2 (1)\n",
      "             46 BINARY_OP                0 (+)\n",
      "             50 LOAD_CONST               3 (3)\n",
      "             52 BINARY_OP                6 (%)\n",
      "             56 LOAD_CONST               2 (1)\n",
      "             58 COMPARE_OP              40 (==)\n",
      "             62 POP_JUMP_IF_FALSE       10 (to 84)\n",
      "\n",
      "460          64 LOAD_FAST                8 (input_str)\n",
      "             66 LOAD_CONST               4 ('\\n\\t')\n",
      "             68 LOAD_FAST               10 (expression)\n",
      "             70 FORMAT_VALUE             2 (repr)\n",
      "             72 LOAD_CONST               5 (',')\n",
      "             74 BUILD_STRING             3\n",
      "             76 BINARY_OP               13 (+=)\n",
      "             80 STORE_FAST               8 (input_str)\n",
      "             82 JUMP_BACKWARD           27 (to 30)\n",
      "\n",
      "462     >>   84 LOAD_FAST                8 (input_str)\n",
      "             86 LOAD_CONST               6 (' ')\n",
      "             88 LOAD_FAST               10 (expression)\n",
      "             90 FORMAT_VALUE             2 (repr)\n",
      "             92 LOAD_CONST               5 (',')\n",
      "             94 BUILD_STRING             3\n",
      "             96 BINARY_OP               13 (+=)\n",
      "            100 STORE_FAST               8 (input_str)\n",
      "            102 JUMP_BACKWARD           37 (to 30)\n",
      "\n",
      "458     >>  104 END_FOR\n",
      "\n",
      "464         106 LOAD_FAST                1 (diff)\n",
      "            108 POP_JUMP_IF_NONE         9 (to 128)\n",
      "\n",
      "465         110 LOAD_FAST                8 (input_str)\n",
      "            112 LOAD_CONST               7 (\"\\n\\tdiff='\")\n",
      "            114 LOAD_FAST                1 (diff)\n",
      "            116 FORMAT_VALUE             0\n",
      "            118 LOAD_CONST               8 (\"',\")\n",
      "            120 BUILD_STRING             3\n",
      "            122 BINARY_OP               13 (+=)\n",
      "            126 STORE_FAST               8 (input_str)\n",
      "\n",
      "466     >>  128 LOAD_FAST                2 (max_cols)\n",
      "            130 POP_JUMP_IF_NONE         9 (to 150)\n",
      "\n",
      "467         132 LOAD_FAST                8 (input_str)\n",
      "            134 LOAD_CONST               9 ('\\n\\tmax_cols=')\n",
      "            136 LOAD_FAST                2 (max_cols)\n",
      "            138 FORMAT_VALUE             0\n",
      "            140 LOAD_CONST               5 (',')\n",
      "            142 BUILD_STRING             3\n",
      "            144 BINARY_OP               13 (+=)\n",
      "            148 STORE_FAST               8 (input_str)\n",
      "\n",
      "468     >>  150 LOAD_FAST                3 (max_rows)\n",
      "            152 POP_JUMP_IF_NONE         9 (to 172)\n",
      "\n",
      "469         154 LOAD_FAST                8 (input_str)\n",
      "            156 LOAD_CONST              10 ('\\n\\tmax_rows=')\n",
      "            158 LOAD_FAST                3 (max_rows)\n",
      "            160 FORMAT_VALUE             0\n",
      "            162 LOAD_CONST               5 (',')\n",
      "            164 BUILD_STRING             3\n",
      "            166 BINARY_OP               13 (+=)\n",
      "            170 STORE_FAST               8 (input_str)\n",
      "\n",
      "471     >>  172 LOAD_FAST                8 (input_str)\n",
      "            174 LOAD_CONST              11 ('\\n\\tinplace=')\n",
      "            176 LOAD_FAST                4 (inplace)\n",
      "            178 FORMAT_VALUE             0\n",
      "            180 LOAD_CONST               5 (',')\n",
      "            182 BUILD_STRING             3\n",
      "            184 BINARY_OP               13 (+=)\n",
      "            188 STORE_FAST               8 (input_str)\n",
      "\n",
      "472         190 LOAD_FAST                8 (input_str)\n",
      "            192 LOAD_CONST              12 ('\\n\\tverbosity=')\n",
      "            194 LOAD_FAST                5 (verbosity)\n",
      "            196 FORMAT_VALUE             0\n",
      "            198 LOAD_CONST               5 (',')\n",
      "            200 BUILD_STRING             3\n",
      "            202 BINARY_OP               13 (+=)\n",
      "            206 STORE_FAST               8 (input_str)\n",
      "\n",
      "474         208 LOAD_FAST                7 (kwargs)\n",
      "            210 GET_ITER\n",
      "        >>  212 FOR_ITER                17 (to 250)\n",
      "            216 STORE_FAST              11 (kwarg)\n",
      "\n",
      "475         218 LOAD_FAST                8 (input_str)\n",
      "            220 LOAD_CONST               4 ('\\n\\t')\n",
      "            222 LOAD_FAST               11 (kwarg)\n",
      "            224 FORMAT_VALUE             0\n",
      "            226 LOAD_CONST              13 (\"='\")\n",
      "            228 LOAD_FAST                7 (kwargs)\n",
      "            230 LOAD_FAST               11 (kwarg)\n",
      "            232 BINARY_SUBSCR\n",
      "            236 FORMAT_VALUE             0\n",
      "            238 LOAD_CONST              14 (\"'\")\n",
      "            240 BUILD_STRING             5\n",
      "            242 BINARY_OP               13 (+=)\n",
      "            246 STORE_FAST               8 (input_str)\n",
      "            248 JUMP_BACKWARD           19 (to 212)\n",
      "\n",
      "474     >>  250 END_FOR\n",
      "\n",
      "477         252 LOAD_FAST                8 (input_str)\n",
      "            254 LOAD_CONST              15 ('\\n\\t)')\n",
      "            256 BINARY_OP                0 (+)\n",
      "            260 LOAD_FAST                0 (self)\n",
      "            262 LOAD_ATTR                2 (df)\n",
      "            282 LOAD_ATTR                4 (qp)\n",
      "            302 STORE_ATTR               3 (_input)\n",
      "\n",
      "481         312 LOAD_FAST                4 (inplace)\n",
      "            314 LOAD_CONST              16 (False)\n",
      "            316 IS_OP                    0\n",
      "            318 POP_JUMP_IF_FALSE       27 (to 374)\n",
      "\n",
      "482         320 LOAD_FAST                0 (self)\n",
      "            322 LOAD_ATTR                2 (df)\n",
      "            342 LOAD_ATTR                9 (NULL|self + copy)\n",
      "            362 CALL                     0\n",
      "            370 STORE_FAST              12 (df)\n",
      "            372 JUMP_FORWARD            12 (to 398)\n",
      "\n",
      "484     >>  374 LOAD_FAST                0 (self)\n",
      "            376 LOAD_ATTR                2 (df)\n",
      "            396 STORE_FAST              12 (df)\n",
      "\n",
      "486     >>  398 LOAD_FAST                0 (self)\n",
      "            400 LOAD_ATTR                2 (df)\n",
      "            420 LOAD_ATTR                4 (qp)\n",
      "            440 LOAD_FAST               12 (df)\n",
      "            442 STORE_ATTR               2 (qp)\n",
      "\n",
      "492         452 LOAD_CONST              17 ('#')\n",
      "            454 LOAD_FAST               12 (df)\n",
      "            456 LOAD_ATTR               10 (index)\n",
      "            476 CONTAINS_OP              1\n",
      "            478 POP_JUMP_IF_FALSE      142 (to 764)\n",
      "\n",
      "493         480 LOAD_FAST                5 (verbosity)\n",
      "            482 LOAD_CONST              18 (2)\n",
      "            484 COMPARE_OP              92 (>=)\n",
      "            488 POP_JUMP_IF_FALSE       17 (to 524)\n",
      "\n",
      "494         490 LOAD_GLOBAL             13 (NULL + log)\n",
      "            500 LOAD_CONST              19 ('a row named \"#\" containing metadata at location 0 is expected but was not found. ')\n",
      "\n",
      "495         502 LOAD_CONST              20 ('adding metadata row now. its advised to prepare the data with df=df.format().')\n",
      "\n",
      "494         504 BINARY_OP                0 (+)\n",
      "\n",
      "496         508 LOAD_CONST              21 ('warning')\n",
      "            510 LOAD_CONST              22 ('df.q()')\n",
      "\n",
      "494         512 KW_NAMES                23 (('level', 'source'))\n",
      "            514 CALL                     3\n",
      "            522 POP_TOP\n",
      "\n",
      "497     >>  524 LOAD_FAST               12 (df)\n",
      "            526 LOAD_ATTR                9 (NULL|self + copy)\n",
      "            546 CALL                     0\n",
      "            554 STORE_FAST              13 (df_old)\n",
      "\n",
      "498         556 LOAD_FAST               12 (df)\n",
      "            558 LOAD_ATTR               10 (index)\n",
      "            578 STORE_FAST              14 (index_old)\n",
      "\n",
      "499         580 LOAD_GLOBAL             15 (NULL + pd)\n",
      "            590 LOAD_ATTR               16 (Index)\n",
      "            610 LOAD_CONST              17 ('#')\n",
      "            612 BUILD_LIST               1\n",
      "            614 LOAD_FAST               14 (index_old)\n",
      "            616 LIST_EXTEND              1\n",
      "            618 CALL                     1\n",
      "            626 STORE_FAST              15 (index_new)\n",
      "\n",
      "501         628 LOAD_CONST              24 ('')\n",
      "            630 LOAD_FAST               12 (df)\n",
      "            632 LOAD_ATTR               18 (loc)\n",
      "            652 LOAD_CONST              17 ('#')\n",
      "            654 STORE_SUBSCR\n",
      "\n",
      "502         658 LOAD_FAST               12 (df)\n",
      "            660 LOAD_ATTR               21 (NULL|self + set_index)\n",
      "            680 LOAD_FAST               15 (index_new)\n",
      "            682 LOAD_CONST              25 (True)\n",
      "            684 KW_NAMES                26 (('inplace',))\n",
      "            686 CALL                     2\n",
      "            694 POP_TOP\n",
      "\n",
      "503         696 LOAD_FAST               13 (df_old)\n",
      "            698 LOAD_FAST               12 (df)\n",
      "            700 LOAD_ATTR               18 (loc)\n",
      "            720 LOAD_FAST               14 (index_old)\n",
      "            722 LOAD_CONST               0 (None)\n",
      "            724 LOAD_CONST               0 (None)\n",
      "            726 BUILD_SLICE              2\n",
      "            728 BUILD_TUPLE              2\n",
      "            730 STORE_SUBSCR\n",
      "\n",
      "504         734 LOAD_CONST              24 ('')\n",
      "            736 LOAD_FAST               12 (df)\n",
      "            738 LOAD_ATTR               18 (loc)\n",
      "            758 LOAD_CONST              17 ('#')\n",
      "            760 STORE_SUBSCR\n",
      "\n",
      "507     >>  764 LOAD_CONST              17 ('#')\n",
      "            766 LOAD_FAST               12 (df)\n",
      "            768 LOAD_ATTR               22 (columns)\n",
      "            788 CONTAINS_OP              1\n",
      "            790 POP_JUMP_IF_FALSE       41 (to 874)\n",
      "\n",
      "508         792 LOAD_FAST                5 (verbosity)\n",
      "            794 LOAD_CONST              18 (2)\n",
      "            796 COMPARE_OP              92 (>=)\n",
      "            800 POP_JUMP_IF_FALSE       17 (to 836)\n",
      "\n",
      "509         802 LOAD_GLOBAL             13 (NULL + log)\n",
      "            812 LOAD_CONST              27 ('a column named \"#\" containing metadata at location 0 is expected but was not found. ')\n",
      "\n",
      "510         814 LOAD_CONST              28 ('adding metadata column now. its advised to prepare the data with df=df.format().')\n",
      "\n",
      "509         816 BINARY_OP                0 (+)\n",
      "\n",
      "511         820 LOAD_CONST              21 ('warning')\n",
      "            822 LOAD_CONST              22 ('df.q()')\n",
      "\n",
      "509         824 KW_NAMES                23 (('level', 'source'))\n",
      "            826 CALL                     3\n",
      "            834 POP_TOP\n",
      "\n",
      "512     >>  836 LOAD_FAST               12 (df)\n",
      "            838 LOAD_ATTR               25 (NULL|self + insert)\n",
      "            858 LOAD_CONST              29 (0)\n",
      "            860 LOAD_CONST              17 ('#')\n",
      "            862 LOAD_CONST              24 ('')\n",
      "            864 CALL                     3\n",
      "            872 POP_TOP\n",
      "\n",
      "523     >>  874 LOAD_GLOBAL             15 (NULL + pd)\n",
      "            884 LOAD_ATTR               16 (Index)\n",
      "            904 LOAD_FAST               12 (df)\n",
      "            906 LOAD_ATTR               22 (columns)\n",
      "            926 GET_ITER\n",
      "            928 LOAD_FAST_AND_CLEAR     16 (col)\n",
      "            930 SWAP                     2\n",
      "            932 BUILD_LIST               0\n",
      "            934 SWAP                     2\n",
      "        >>  936 FOR_ITER                 4 (to 948)\n",
      "            940 STORE_FAST              16 (col)\n",
      "            942 LOAD_CONST              25 (True)\n",
      "            944 LIST_APPEND              2\n",
      "            946 JUMP_BACKWARD            6 (to 936)\n",
      "        >>  948 END_FOR\n",
      "            950 SWAP                     2\n",
      "            952 STORE_FAST              16 (col)\n",
      "            954 CALL                     1\n",
      "            962 COPY                     1\n",
      "            964 STORE_FAST              17 (cols_filtered)\n",
      "            966 STORE_FAST              18 (cols_filtered_condition)\n",
      "\n",
      "524         968 LOAD_GLOBAL             15 (NULL + pd)\n",
      "            978 LOAD_ATTR               16 (Index)\n",
      "            998 LOAD_FAST               12 (df)\n",
      "           1000 LOAD_ATTR               10 (index)\n",
      "           1020 GET_ITER\n",
      "           1022 LOAD_FAST_AND_CLEAR     19 (row)\n",
      "           1024 SWAP                     2\n",
      "           1026 BUILD_LIST               0\n",
      "           1028 SWAP                     2\n",
      "        >> 1030 FOR_ITER                 4 (to 1042)\n",
      "           1034 STORE_FAST              19 (row)\n",
      "           1036 LOAD_CONST              25 (True)\n",
      "           1038 LIST_APPEND              2\n",
      "           1040 JUMP_BACKWARD            6 (to 1030)\n",
      "        >> 1042 END_FOR\n",
      "           1044 SWAP                     2\n",
      "           1046 STORE_FAST              19 (row)\n",
      "           1048 CALL                     1\n",
      "           1056 COPY                     1\n",
      "           1058 STORE_FAST              20 (rows_filtered)\n",
      "           1060 COPY                     1\n",
      "           1062 STORE_FAST              21 (rows_filtered_condition)\n",
      "           1064 STORE_FAST              22 (rows_filtered_col)\n",
      "\n",
      "527        1066 LOAD_GLOBAL              1 (NULL + enumerate)\n",
      "           1076 LOAD_FAST                6 (expressions)\n",
      "           1078 CALL                     1\n",
      "           1086 GET_ITER\n",
      "        >> 1088 EXTENDED_ARG             3\n",
      "           1090 FOR_ITER               793 (to 2680)\n",
      "           1094 UNPACK_SEQUENCE          2\n",
      "           1098 STORE_FAST              23 (i_expression)\n",
      "           1100 STORE_FAST              10 (expression)\n",
      "\n",
      "528        1102 BUILD_LIST               0\n",
      "           1104 LOAD_CONST              30 (('col', 'row', 'modify'))\n",
      "           1106 LIST_EXTEND              1\n",
      "           1108 LOAD_FAST               23 (i_expression)\n",
      "           1110 LOAD_CONST               3 (3)\n",
      "           1112 BINARY_OP                6 (%)\n",
      "           1116 BINARY_SUBSCR\n",
      "           1120 STORE_FAST              24 (expression_type)\n",
      "\n",
      "529        1122 LOAD_FAST               10 (expression)\n",
      "           1124 LOAD_CONST              24 ('')\n",
      "           1126 COMPARE_OP              40 (==)\n",
      "           1130 POP_JUMP_IF_FALSE        1 (to 1134)\n",
      "\n",
      "530        1132 JUMP_BACKWARD           23 (to 1088)\n",
      "\n",
      "534     >> 1134 LOAD_FAST               24 (expression_type)\n",
      "           1136 LOAD_CONST              31 ('col')\n",
      "           1138 COMPARE_OP              40 (==)\n",
      "           1142 POP_JUMP_IF_FALSE      212 (to 1568)\n",
      "\n",
      "535        1144 LOAD_GLOBAL             27 (NULL + _parse_expression)\n",
      "           1154 LOAD_FAST               12 (df)\n",
      "           1156 LOAD_FAST               10 (expression)\n",
      "           1158 LOAD_FAST               24 (expression_type)\n",
      "           1160 LOAD_FAST                5 (verbosity)\n",
      "           1162 CALL                     4\n",
      "           1170 STORE_FAST              25 (ast)\n",
      "\n",
      "537        1172 LOAD_GLOBAL              1 (NULL + enumerate)\n",
      "           1182 LOAD_FAST               25 (ast)\n",
      "           1184 LOAD_CONST              32 ('conditions')\n",
      "           1186 BINARY_SUBSCR\n",
      "           1190 CALL                     1\n",
      "           1198 GET_ITER\n",
      "        >> 1200 FOR_ITER                96 (to 1396)\n",
      "           1204 UNPACK_SEQUENCE          2\n",
      "           1208 STORE_FAST              26 (i_condition)\n",
      "           1210 STORE_FAST              27 (condition)\n",
      "\n",
      "538        1212 LOAD_FAST               27 (condition)\n",
      "           1214 LOAD_CONST              33 ('by_tag')\n",
      "           1216 BINARY_SUBSCR\n",
      "           1220 LOAD_CONST              34 ('row or col metadata')\n",
      "           1222 COMPARE_OP              40 (==)\n",
      "           1226 POP_JUMP_IF_FALSE       34 (to 1296)\n",
      "\n",
      "539        1228 LOAD_GLOBAL             29 (NULL + _apply_condition)\n",
      "           1238 LOAD_FAST               12 (df)\n",
      "           1240 LOAD_ATTR               18 (loc)\n",
      "           1260 LOAD_CONST              17 ('#')\n",
      "           1262 BINARY_SUBSCR\n",
      "           1266 LOAD_FAST               27 (condition)\n",
      "           1268 LOAD_GLOBAL             30 (_operators)\n",
      "           1278 LOAD_FAST                5 (verbosity)\n",
      "           1280 LOAD_FAST               12 (df)\n",
      "           1282 KW_NAMES                35 (('df',))\n",
      "           1284 CALL                     5\n",
      "           1292 STORE_FAST              28 (cols_filtered_new)\n",
      "           1294 JUMP_FORWARD            30 (to 1356)\n",
      "\n",
      "541     >> 1296 LOAD_GLOBAL             29 (NULL + _apply_condition)\n",
      "           1306 LOAD_FAST               12 (df)\n",
      "           1308 LOAD_ATTR               22 (columns)\n",
      "           1328 LOAD_FAST               27 (condition)\n",
      "           1330 LOAD_GLOBAL             30 (_operators)\n",
      "           1340 LOAD_FAST                5 (verbosity)\n",
      "           1342 LOAD_FAST               12 (df)\n",
      "           1344 KW_NAMES                35 (('df',))\n",
      "           1346 CALL                     5\n",
      "           1354 STORE_FAST              28 (cols_filtered_new)\n",
      "\n",
      "543     >> 1356 LOAD_GLOBAL             33 (NULL + _update_index)\n",
      "           1366 LOAD_FAST               18 (cols_filtered_condition)\n",
      "           1368 LOAD_FAST               28 (cols_filtered_new)\n",
      "           1370 LOAD_FAST               27 (condition)\n",
      "           1372 LOAD_CONST              36 ('condition_connector')\n",
      "           1374 BINARY_SUBSCR\n",
      "           1378 LOAD_FAST               26 (i_condition)\n",
      "           1380 LOAD_FAST                5 (verbosity)\n",
      "           1382 KW_NAMES                37 (('verbosity',))\n",
      "           1384 CALL                     5\n",
      "           1392 STORE_FAST              18 (cols_filtered_condition)\n",
      "           1394 JUMP_BACKWARD           98 (to 1200)\n",
      "\n",
      "537     >> 1396 END_FOR\n",
      "\n",
      "544        1398 LOAD_GLOBAL             33 (NULL + _update_index)\n",
      "           1408 LOAD_FAST               17 (cols_filtered)\n",
      "           1410 LOAD_FAST               18 (cols_filtered_condition)\n",
      "           1412 LOAD_FAST               25 (ast)\n",
      "           1414 LOAD_CONST              38 ('connector')\n",
      "           1416 BINARY_SUBSCR\n",
      "           1420 LOAD_FAST               23 (i_expression)\n",
      "           1422 LOAD_FAST                5 (verbosity)\n",
      "           1424 KW_NAMES                37 (('verbosity',))\n",
      "           1426 CALL                     5\n",
      "           1434 STORE_FAST              17 (cols_filtered)\n",
      "\n",
      "546        1436 LOAD_FAST               17 (cols_filtered)\n",
      "           1438 LOAD_ATTR               35 (NULL|self + any)\n",
      "           1458 CALL                     0\n",
      "           1466 LOAD_CONST              16 (False)\n",
      "           1468 COMPARE_OP              40 (==)\n",
      "           1472 POP_JUMP_IF_TRUE         1 (to 1476)\n",
      "           1474 JUMP_BACKWARD          194 (to 1088)\n",
      "        >> 1476 LOAD_FAST                5 (verbosity)\n",
      "           1478 LOAD_CONST              18 (2)\n",
      "           1480 COMPARE_OP              92 (>=)\n",
      "           1484 POP_JUMP_IF_TRUE         1 (to 1488)\n",
      "           1486 JUMP_BACKWARD          200 (to 1088)\n",
      "\n",
      "547     >> 1488 LOAD_GLOBAL             13 (NULL + log)\n",
      "           1498 LOAD_CONST              39 ('no columns fulfill the condition(s) in \"')\n",
      "           1500 LOAD_FAST               10 (expression)\n",
      "           1502 FORMAT_VALUE             0\n",
      "           1504 LOAD_CONST              40 ('\"')\n",
      "           1506 BUILD_STRING             3\n",
      "           1508 LOAD_CONST              21 ('warning')\n",
      "           1510 LOAD_CONST              41 ('df.q')\n",
      "           1512 LOAD_FAST               12 (df)\n",
      "           1514 LOAD_ATTR                4 (qp)\n",
      "           1534 LOAD_ATTR                6 (_input)\n",
      "           1554 KW_NAMES                42 (('level', 'source', 'input'))\n",
      "           1556 CALL                     4\n",
      "           1564 POP_TOP\n",
      "           1566 JUMP_BACKWARD          240 (to 1088)\n",
      "\n",
      "553     >> 1568 LOAD_FAST               24 (expression_type)\n",
      "           1570 LOAD_CONST              43 ('row')\n",
      "           1572 COMPARE_OP              40 (==)\n",
      "           1576 POP_JUMP_IF_FALSE      255 (to 2088)\n",
      "\n",
      "554        1578 LOAD_GLOBAL             27 (NULL + _parse_expression)\n",
      "           1588 LOAD_FAST               12 (df)\n",
      "           1590 LOAD_FAST               10 (expression)\n",
      "           1592 LOAD_FAST               24 (expression_type)\n",
      "           1594 LOAD_FAST                5 (verbosity)\n",
      "           1596 CALL                     4\n",
      "           1604 STORE_FAST              25 (ast)\n",
      "\n",
      "556        1606 LOAD_GLOBAL              1 (NULL + enumerate)\n",
      "           1616 LOAD_FAST               25 (ast)\n",
      "           1618 LOAD_CONST              32 ('conditions')\n",
      "           1620 BINARY_SUBSCR\n",
      "           1624 CALL                     1\n",
      "           1632 GET_ITER\n",
      "        >> 1634 FOR_ITER               133 (to 1904)\n",
      "           1638 UNPACK_SEQUENCE          2\n",
      "           1642 STORE_FAST              26 (i_condition)\n",
      "           1644 STORE_FAST              27 (condition)\n",
      "\n",
      "557        1646 LOAD_GLOBAL              1 (NULL + enumerate)\n",
      "           1656 LOAD_FAST               12 (df)\n",
      "           1658 LOAD_ATTR               22 (columns)\n",
      "           1678 LOAD_FAST               18 (cols_filtered_condition)\n",
      "           1680 BINARY_SUBSCR\n",
      "           1684 LOAD_CONST               2 (1)\n",
      "           1686 LOAD_CONST               0 (None)\n",
      "           1688 BINARY_SLICE\n",
      "           1690 CALL                     1\n",
      "           1698 GET_ITER\n",
      "        >> 1700 FOR_ITER                79 (to 1862)\n",
      "           1704 UNPACK_SEQUENCE          2\n",
      "           1708 STORE_FAST              29 (i_col)\n",
      "           1710 STORE_FAST              16 (col)\n",
      "\n",
      "558        1712 LOAD_FAST               27 (condition)\n",
      "           1714 LOAD_CONST              33 ('by_tag')\n",
      "           1716 BINARY_SUBSCR\n",
      "           1720 LOAD_CONST              34 ('row or col metadata')\n",
      "           1722 COMPARE_OP              40 (==)\n",
      "           1726 POP_JUMP_IF_FALSE       24 (to 1776)\n",
      "\n",
      "559        1728 LOAD_GLOBAL             29 (NULL + _apply_condition)\n",
      "           1738 LOAD_FAST               12 (df)\n",
      "           1740 LOAD_CONST              17 ('#')\n",
      "           1742 BINARY_SUBSCR\n",
      "           1746 LOAD_FAST               27 (condition)\n",
      "           1748 LOAD_GLOBAL             30 (_operators)\n",
      "           1758 LOAD_FAST                5 (verbosity)\n",
      "           1760 LOAD_FAST               12 (df)\n",
      "           1762 KW_NAMES                35 (('df',))\n",
      "           1764 CALL                     5\n",
      "           1772 STORE_FAST              30 (rows_filtered_new)\n",
      "           1774 JUMP_FORWARD            23 (to 1822)\n",
      "\n",
      "561     >> 1776 LOAD_GLOBAL             29 (NULL + _apply_condition)\n",
      "           1786 LOAD_FAST               12 (df)\n",
      "           1788 LOAD_FAST               16 (col)\n",
      "           1790 BINARY_SUBSCR\n",
      "           1794 LOAD_FAST               27 (condition)\n",
      "           1796 LOAD_GLOBAL             30 (_operators)\n",
      "           1806 LOAD_FAST                5 (verbosity)\n",
      "           1808 LOAD_FAST               12 (df)\n",
      "           1810 KW_NAMES                35 (('df',))\n",
      "           1812 CALL                     5\n",
      "           1820 STORE_FAST              30 (rows_filtered_new)\n",
      "\n",
      "563     >> 1822 LOAD_GLOBAL             33 (NULL + _update_index)\n",
      "           1832 LOAD_FAST               22 (rows_filtered_col)\n",
      "           1834 LOAD_FAST               30 (rows_filtered_new)\n",
      "           1836 LOAD_FAST               27 (condition)\n",
      "           1838 LOAD_CONST              44 ('which_cols')\n",
      "           1840 BINARY_SUBSCR\n",
      "           1844 LOAD_FAST               29 (i_col)\n",
      "           1846 LOAD_FAST                5 (verbosity)\n",
      "           1848 KW_NAMES                37 (('verbosity',))\n",
      "           1850 CALL                     5\n",
      "           1858 STORE_FAST              22 (rows_filtered_col)\n",
      "           1860 JUMP_BACKWARD           81 (to 1700)\n",
      "\n",
      "557     >> 1862 END_FOR\n",
      "\n",
      "564        1864 LOAD_GLOBAL             33 (NULL + _update_index)\n",
      "           1874 LOAD_FAST               21 (rows_filtered_condition)\n",
      "           1876 LOAD_FAST               22 (rows_filtered_col)\n",
      "           1878 LOAD_FAST               27 (condition)\n",
      "           1880 LOAD_CONST              36 ('condition_connector')\n",
      "           1882 BINARY_SUBSCR\n",
      "           1886 LOAD_FAST               26 (i_condition)\n",
      "           1888 LOAD_FAST                5 (verbosity)\n",
      "           1890 KW_NAMES                37 (('verbosity',))\n",
      "           1892 CALL                     5\n",
      "           1900 STORE_FAST              21 (rows_filtered_condition)\n",
      "           1902 JUMP_BACKWARD          135 (to 1634)\n",
      "\n",
      "556     >> 1904 END_FOR\n",
      "\n",
      "565        1906 LOAD_GLOBAL             33 (NULL + _update_index)\n",
      "           1916 LOAD_FAST               20 (rows_filtered)\n",
      "           1918 LOAD_FAST               21 (rows_filtered_condition)\n",
      "           1920 LOAD_FAST               25 (ast)\n",
      "           1922 LOAD_CONST              38 ('connector')\n",
      "           1924 BINARY_SUBSCR\n",
      "           1928 LOAD_FAST               23 (i_expression)\n",
      "           1930 LOAD_CONST               2 (1)\n",
      "           1932 BINARY_OP               10 (-)\n",
      "           1936 LOAD_FAST                5 (verbosity)\n",
      "           1938 KW_NAMES                37 (('verbosity',))\n",
      "           1940 CALL                     5\n",
      "           1948 STORE_FAST              20 (rows_filtered)\n",
      "\n",
      "567        1950 LOAD_FAST               20 (rows_filtered)\n",
      "           1952 LOAD_ATTR               35 (NULL|self + any)\n",
      "           1972 CALL                     0\n",
      "           1980 LOAD_CONST              16 (False)\n",
      "           1982 COMPARE_OP              40 (==)\n",
      "           1986 POP_JUMP_IF_TRUE         2 (to 1992)\n",
      "           1988 EXTENDED_ARG             1\n",
      "           1990 JUMP_BACKWARD          452 (to 1088)\n",
      "        >> 1992 LOAD_FAST                5 (verbosity)\n",
      "           1994 LOAD_CONST              18 (2)\n",
      "           1996 COMPARE_OP              92 (>=)\n",
      "           2000 POP_JUMP_IF_TRUE         2 (to 2006)\n",
      "           2002 EXTENDED_ARG             1\n",
      "           2004 JUMP_BACKWARD          459 (to 1088)\n",
      "\n",
      "568     >> 2006 LOAD_GLOBAL             13 (NULL + log)\n",
      "           2016 LOAD_CONST              45 ('no rows fulfill the condition(s) in \"')\n",
      "           2018 LOAD_FAST               10 (expression)\n",
      "           2020 FORMAT_VALUE             0\n",
      "           2022 LOAD_CONST              40 ('\"')\n",
      "           2024 BUILD_STRING             3\n",
      "           2026 LOAD_CONST              21 ('warning')\n",
      "           2028 LOAD_CONST              41 ('df.q')\n",
      "           2030 LOAD_FAST               12 (df)\n",
      "           2032 LOAD_ATTR                4 (qp)\n",
      "           2052 LOAD_ATTR                6 (_input)\n",
      "           2072 KW_NAMES                42 (('level', 'source', 'input'))\n",
      "           2074 CALL                     4\n",
      "           2082 POP_TOP\n",
      "           2084 EXTENDED_ARG             1\n",
      "           2086 JUMP_BACKWARD          500 (to 1088)\n",
      "\n",
      "573     >> 2088 LOAD_FAST               24 (expression_type)\n",
      "           2090 LOAD_CONST              46 ('modify')\n",
      "           2092 COMPARE_OP              40 (==)\n",
      "           2096 POP_JUMP_IF_TRUE         2 (to 2102)\n",
      "           2098 EXTENDED_ARG             1\n",
      "           2100 JUMP_BACKWARD          507 (to 1088)\n",
      "\n",
      "574     >> 2102 LOAD_FAST               12 (df)\n",
      "           2104 LOAD_ATTR               22 (columns)\n",
      "           2124 LOAD_FAST               17 (cols_filtered)\n",
      "           2126 BINARY_SUBSCR\n",
      "           2130 GET_ITER\n",
      "           2132 LOAD_FAST_AND_CLEAR     16 (col)\n",
      "           2134 SWAP                     2\n",
      "           2136 BUILD_LIST               0\n",
      "           2138 SWAP                     2\n",
      "        >> 2140 FOR_ITER                22 (to 2188)\n",
      "           2144 STORE_FAST              16 (col)\n",
      "           2146 LOAD_FAST               16 (col)\n",
      "           2148 LOAD_ATTR               37 (NULL|self + startswith)\n",
      "           2168 LOAD_CONST              17 ('#')\n",
      "           2170 CALL                     1\n",
      "           2178 POP_JUMP_IF_FALSE        1 (to 2182)\n",
      "           2180 JUMP_BACKWARD           21 (to 2140)\n",
      "        >> 2182 LOAD_FAST               16 (col)\n",
      "           2184 LIST_APPEND              2\n",
      "           2186 JUMP_BACKWARD           24 (to 2140)\n",
      "        >> 2188 END_FOR\n",
      "           2190 STORE_FAST              31 (cols_filtered_no_metadata)\n",
      "           2192 STORE_FAST              16 (col)\n",
      "\n",
      "575        2194 LOAD_FAST               12 (df)\n",
      "           2196 LOAD_ATTR               10 (index)\n",
      "           2216 LOAD_FAST               20 (rows_filtered)\n",
      "           2218 BINARY_SUBSCR\n",
      "           2222 GET_ITER\n",
      "           2224 LOAD_FAST_AND_CLEAR     19 (row)\n",
      "           2226 SWAP                     2\n",
      "           2228 BUILD_LIST               0\n",
      "           2230 SWAP                     2\n",
      "        >> 2232 FOR_ITER                10 (to 2256)\n",
      "           2236 STORE_FAST              19 (row)\n",
      "           2238 LOAD_FAST               19 (row)\n",
      "           2240 LOAD_CONST              17 ('#')\n",
      "           2242 COMPARE_OP              55 (!=)\n",
      "           2246 POP_JUMP_IF_TRUE         1 (to 2250)\n",
      "           2248 JUMP_BACKWARD            9 (to 2232)\n",
      "        >> 2250 LOAD_FAST               19 (row)\n",
      "           2252 LIST_APPEND              2\n",
      "           2254 JUMP_BACKWARD           12 (to 2232)\n",
      "        >> 2256 END_FOR\n",
      "           2258 STORE_FAST              32 (rows_filtered_no_metadata)\n",
      "           2260 STORE_FAST              19 (row)\n",
      "\n",
      "577        2262 LOAD_GLOBAL             39 (NULL + _parse_expression_modify)\n",
      "           2272 LOAD_FAST               12 (df)\n",
      "           2274 LOAD_FAST               10 (expression)\n",
      "           2276 LOAD_FAST               24 (expression_type)\n",
      "           2278 LOAD_FAST                5 (verbosity)\n",
      "           2280 CALL                     4\n",
      "           2288 STORE_FAST              25 (ast)\n",
      "\n",
      "579        2290 LOAD_FAST               25 (ast)\n",
      "           2292 LOAD_CONST              47 ('modifications')\n",
      "           2294 BINARY_SUBSCR\n",
      "           2298 GET_ITER\n",
      "        >> 2300 FOR_ITER               185 (to 2674)\n",
      "           2304 STORE_DEREF             37 (modification)\n",
      "\n",
      "582        2306 LOAD_DEREF              37 (modification)\n",
      "           2308 LOAD_CONST              48 ('modifier')\n",
      "           2310 BINARY_SUBSCR\n",
      "           2314 LOAD_GLOBAL             40 (_modifiers)\n",
      "           2324 LOAD_CONST              49 ('set_col_tags')\n",
      "           2326 BINARY_SUBSCR\n",
      "           2330 CONTAINS_OP              0\n",
      "           2332 POP_JUMP_IF_FALSE       51 (to 2436)\n",
      "\n",
      "583        2334 LOAD_FAST               12 (df)\n",
      "           2336 LOAD_ATTR               18 (loc)\n",
      "           2356 LOAD_CONST              17 ('#')\n",
      "           2358 LOAD_FAST               31 (cols_filtered_no_metadata)\n",
      "           2360 BUILD_TUPLE              2\n",
      "           2362 BINARY_SUBSCR\n",
      "           2366 LOAD_ATTR               43 (NULL|self + apply)\n",
      "\n",
      "584        2386 LOAD_CLOSURE            37 (modification)\n",
      "           2388 BUILD_TUPLE              1\n",
      "           2390 LOAD_CONST              50 (<code object <lambda> at 0x0000014830645DF0, file \"c:\\Users\\MartinVölkl-GouyaIns\\OneDrive - Gouya Insights\\Desktop\\qplib\\qplib\\pd_query.py\", line 584>)\n",
      "           2392 MAKE_FUNCTION            8 (closure)\n",
      "\n",
      "583        2394 CALL                     1\n",
      "           2402 LOAD_FAST               12 (df)\n",
      "           2404 LOAD_ATTR               18 (loc)\n",
      "           2424 LOAD_CONST              17 ('#')\n",
      "           2426 LOAD_FAST               31 (cols_filtered_no_metadata)\n",
      "           2428 BUILD_TUPLE              2\n",
      "           2430 STORE_SUBSCR\n",
      "           2434 JUMP_BACKWARD           68 (to 2300)\n",
      "\n",
      "588     >> 2436 LOAD_DEREF              37 (modification)\n",
      "           2438 LOAD_CONST              48 ('modifier')\n",
      "           2440 BINARY_SUBSCR\n",
      "           2444 LOAD_GLOBAL             40 (_modifiers)\n",
      "           2454 LOAD_CONST              51 ('set_row_tags')\n",
      "           2456 BINARY_SUBSCR\n",
      "           2460 CONTAINS_OP              0\n",
      "           2462 POP_JUMP_IF_FALSE       51 (to 2566)\n",
      "\n",
      "589        2464 LOAD_FAST               12 (df)\n",
      "           2466 LOAD_ATTR               18 (loc)\n",
      "           2486 LOAD_FAST               32 (rows_filtered_no_metadata)\n",
      "           2488 LOAD_CONST              17 ('#')\n",
      "           2490 BUILD_TUPLE              2\n",
      "           2492 BINARY_SUBSCR\n",
      "           2496 LOAD_ATTR               43 (NULL|self + apply)\n",
      "\n",
      "590        2516 LOAD_CLOSURE            37 (modification)\n",
      "           2518 BUILD_TUPLE              1\n",
      "           2520 LOAD_CONST              52 (<code object <lambda> at 0x0000014830645ED0, file \"c:\\Users\\MartinVölkl-GouyaIns\\OneDrive - Gouya Insights\\Desktop\\qplib\\qplib\\pd_query.py\", line 590>)\n",
      "           2522 MAKE_FUNCTION            8 (closure)\n",
      "\n",
      "589        2524 CALL                     1\n",
      "           2532 LOAD_FAST               12 (df)\n",
      "           2534 LOAD_ATTR               18 (loc)\n",
      "           2554 LOAD_FAST               32 (rows_filtered_no_metadata)\n",
      "           2556 LOAD_CONST              17 ('#')\n",
      "           2558 BUILD_TUPLE              2\n",
      "           2560 STORE_SUBSCR\n",
      "           2564 JUMP_BACKWARD          133 (to 2300)\n",
      "\n",
      "595     >> 2566 LOAD_GLOBAL             45 (NULL + _apply_modification_df)\n",
      "           2576 LOAD_FAST               12 (df)\n",
      "           2578 LOAD_FAST               32 (rows_filtered_no_metadata)\n",
      "           2580 LOAD_FAST               31 (cols_filtered_no_metadata)\n",
      "           2582 LOAD_DEREF              37 (modification)\n",
      "           2584 LOAD_FAST                5 (verbosity)\n",
      "           2586 CALL                     5\n",
      "           2594 LOAD_ATTR               18 (loc)\n",
      "           2614 LOAD_CONST               0 (None)\n",
      "           2616 LOAD_CONST               0 (None)\n",
      "           2618 BUILD_SLICE              2\n",
      "           2620 LOAD_CONST               0 (None)\n",
      "           2622 LOAD_CONST               0 (None)\n",
      "           2624 BUILD_SLICE              2\n",
      "           2626 BUILD_TUPLE              2\n",
      "           2628 BINARY_SUBSCR\n",
      "           2632 LOAD_FAST               12 (df)\n",
      "           2634 LOAD_ATTR               18 (loc)\n",
      "           2654 LOAD_CONST               0 (None)\n",
      "           2656 LOAD_CONST               0 (None)\n",
      "           2658 BUILD_SLICE              2\n",
      "           2660 LOAD_CONST               0 (None)\n",
      "           2662 LOAD_CONST               0 (None)\n",
      "           2664 BUILD_SLICE              2\n",
      "           2666 BUILD_TUPLE              2\n",
      "           2668 STORE_SUBSCR\n",
      "           2672 JUMP_BACKWARD          187 (to 2300)\n",
      "\n",
      "579     >> 2674 END_FOR\n",
      "           2676 EXTENDED_ARG             3\n",
      "           2678 JUMP_BACKWARD          796 (to 1088)\n",
      "\n",
      "527     >> 2680 END_FOR\n",
      "\n",
      "606        2682 LOAD_FAST               12 (df)\n",
      "           2684 LOAD_ATTR               18 (loc)\n",
      "           2704 LOAD_FAST               20 (rows_filtered)\n",
      "           2706 LOAD_FAST               17 (cols_filtered)\n",
      "           2708 BUILD_TUPLE              2\n",
      "           2710 BINARY_SUBSCR\n",
      "           2714 STORE_FAST              33 (df_filtered)\n",
      "\n",
      "607        2716 LOAD_FAST                0 (self)\n",
      "           2718 LOAD_ATTR                2 (df)\n",
      "           2738 LOAD_ATTR                4 (qp)\n",
      "           2758 LOAD_FAST               33 (df_filtered)\n",
      "           2760 STORE_ATTR               2 (qp)\n",
      "\n",
      "609        2770 LOAD_FAST                1 (diff)\n",
      "           2772 POP_JUMP_IF_NOT_NONE   219 (to 3212)\n",
      "\n",
      "611        2774 LOAD_GLOBAL             47 (NULL + len)\n",
      "           2784 LOAD_FAST               12 (df)\n",
      "           2786 LOAD_ATTR               22 (columns)\n",
      "           2806 LOAD_FAST               17 (cols_filtered)\n",
      "           2808 BINARY_SUBSCR\n",
      "           2812 CALL                     1\n",
      "           2820 STORE_FAST              34 (cols_num)\n",
      "\n",
      "612        2822 LOAD_GLOBAL             47 (NULL + len)\n",
      "           2832 LOAD_FAST               12 (df)\n",
      "           2834 LOAD_ATTR               10 (index)\n",
      "           2854 LOAD_FAST               20 (rows_filtered)\n",
      "           2856 BINARY_SUBSCR\n",
      "           2860 CALL                     1\n",
      "           2868 STORE_FAST              35 (rows_num)\n",
      "\n",
      "614        2870 LOAD_FAST                5 (verbosity)\n",
      "           2872 LOAD_CONST              18 (2)\n",
      "           2874 COMPARE_OP              92 (>=)\n",
      "           2878 POP_JUMP_IF_FALSE       98 (to 3076)\n",
      "\n",
      "615        2880 LOAD_FAST                2 (max_cols)\n",
      "           2882 POP_JUMP_IF_NONE        47 (to 2978)\n",
      "           2884 LOAD_FAST                2 (max_cols)\n",
      "           2886 LOAD_FAST               34 (cols_num)\n",
      "           2888 COMPARE_OP               2 (<)\n",
      "           2892 POP_JUMP_IF_FALSE       42 (to 2978)\n",
      "\n",
      "616        2894 LOAD_GLOBAL             13 (NULL + log)\n",
      "           2904 LOAD_CONST              53 ('showing ')\n",
      "           2906 LOAD_FAST                2 (max_cols)\n",
      "           2908 FORMAT_VALUE             0\n",
      "           2910 LOAD_CONST              54 (' out of ')\n",
      "           2912 LOAD_FAST               34 (cols_num)\n",
      "           2914 FORMAT_VALUE             0\n",
      "           2916 LOAD_CONST              55 (' columns')\n",
      "           2918 BUILD_STRING             5\n",
      "           2920 LOAD_CONST              21 ('warning')\n",
      "           2922 LOAD_CONST              41 ('df.q')\n",
      "           2924 LOAD_FAST               12 (df)\n",
      "           2926 LOAD_ATTR                4 (qp)\n",
      "           2946 LOAD_ATTR                6 (_input)\n",
      "           2966 KW_NAMES                42 (('level', 'source', 'input'))\n",
      "           2968 CALL                     4\n",
      "           2976 POP_TOP\n",
      "\n",
      "617     >> 2978 LOAD_FAST                3 (max_rows)\n",
      "           2980 POP_JUMP_IF_NONE        47 (to 3076)\n",
      "           2982 LOAD_FAST                3 (max_rows)\n",
      "           2984 LOAD_FAST               35 (rows_num)\n",
      "           2986 COMPARE_OP               2 (<)\n",
      "           2990 POP_JUMP_IF_FALSE       42 (to 3076)\n",
      "\n",
      "618        2992 LOAD_GLOBAL             13 (NULL + log)\n",
      "           3002 LOAD_CONST              53 ('showing ')\n",
      "           3004 LOAD_FAST                3 (max_rows)\n",
      "           3006 FORMAT_VALUE             0\n",
      "           3008 LOAD_CONST              54 (' out of ')\n",
      "           3010 LOAD_FAST               35 (rows_num)\n",
      "           3012 FORMAT_VALUE             0\n",
      "           3014 LOAD_CONST              56 (' rows')\n",
      "           3016 BUILD_STRING             5\n",
      "           3018 LOAD_CONST              21 ('warning')\n",
      "           3020 LOAD_CONST              41 ('df.q')\n",
      "           3022 LOAD_FAST               12 (df)\n",
      "           3024 LOAD_ATTR                4 (qp)\n",
      "           3044 LOAD_ATTR                6 (_input)\n",
      "           3064 KW_NAMES                42 (('level', 'source', 'input'))\n",
      "           3066 CALL                     4\n",
      "           3074 POP_TOP\n",
      "\n",
      "620     >> 3076 LOAD_GLOBAL             15 (NULL + pd)\n",
      "           3086 LOAD_ATTR               48 (set_option)\n",
      "           3106 LOAD_CONST              57 ('display.max_columns')\n",
      "           3108 LOAD_FAST                2 (max_cols)\n",
      "           3110 CALL                     2\n",
      "           3118 POP_TOP\n",
      "\n",
      "621        3120 LOAD_GLOBAL             15 (NULL + pd)\n",
      "           3130 LOAD_ATTR               48 (set_option)\n",
      "           3150 LOAD_CONST              58 ('display.max_rows')\n",
      "           3152 LOAD_FAST                3 (max_rows)\n",
      "           3154 CALL                     2\n",
      "           3162 POP_TOP\n",
      "\n",
      "622        3164 LOAD_GLOBAL             15 (NULL + pd)\n",
      "           3174 LOAD_ATTR               48 (set_option)\n",
      "           3194 LOAD_CONST              59 ('display.min_rows')\n",
      "           3196 LOAD_FAST                3 (max_rows)\n",
      "           3198 CALL                     2\n",
      "           3206 POP_TOP\n",
      "\n",
      "624        3208 LOAD_FAST               33 (df_filtered)\n",
      "           3210 RETURN_VALUE\n",
      "\n",
      "630     >> 3212 LOAD_GLOBAL              5 (NULL + qp)\n",
      "           3222 LOAD_ATTR               50 (diff)\n",
      "\n",
      "631        3242 LOAD_FAST               33 (df_filtered)\n",
      "           3244 LOAD_FAST                0 (self)\n",
      "           3246 LOAD_ATTR                2 (df)\n",
      "           3266 LOAD_FAST                1 (diff)\n",
      "\n",
      "632        3268 LOAD_FAST                2 (max_cols)\n",
      "           3270 LOAD_FAST                3 (max_rows)\n",
      "\n",
      "633        3272 LOAD_FAST                5 (verbosity)\n",
      "\n",
      "630        3274 KW_NAMES                60 (('show', 'max_cols', 'max_rows', 'verbosity'))\n",
      "           3276 CALL                     6\n",
      "           3284 STORE_FAST              36 (result)\n",
      "\n",
      "634        3286 LOAD_FAST               36 (result)\n",
      "           3288 RETURN_VALUE\n",
      "        >> 3290 SWAP                     2\n",
      "           3292 POP_TOP\n",
      "\n",
      "523        3294 SWAP                     2\n",
      "           3296 STORE_FAST              16 (col)\n",
      "           3298 RERAISE                  0\n",
      "        >> 3300 SWAP                     2\n",
      "           3302 POP_TOP\n",
      "\n",
      "524        3304 SWAP                     2\n",
      "           3306 STORE_FAST              19 (row)\n",
      "           3308 RERAISE                  0\n",
      "        >> 3310 SWAP                     2\n",
      "           3312 POP_TOP\n",
      "\n",
      "574        3314 SWAP                     2\n",
      "           3316 STORE_FAST              16 (col)\n",
      "           3318 RERAISE                  0\n",
      "        >> 3320 SWAP                     2\n",
      "           3322 POP_TOP\n",
      "\n",
      "575        3324 SWAP                     2\n",
      "           3326 STORE_FAST              19 (row)\n",
      "           3328 RERAISE                  0\n",
      "ExceptionTable:\n",
      "  932 to 948 -> 3290 [4]\n",
      "  1026 to 1042 -> 3300 [4]\n",
      "  2136 to 2178 -> 3310 [3]\n",
      "  2182 to 2188 -> 3310 [3]\n",
      "  2228 to 2246 -> 3320 [3]\n",
      "  2250 to 2256 -> 3320 [3]\n",
      "\n",
      "Disassembly of <code object <lambda> at 0x0000014830645DF0, file \"c:\\Users\\MartinVölkl-GouyaIns\\OneDrive - Gouya Insights\\Desktop\\qplib\\qplib\\pd_query.py\", line 584>:\n",
      "              0 COPY_FREE_VARS           1\n",
      "\n",
      "584           2 RESUME                   0\n",
      "              4 LOAD_GLOBAL              1 (NULL + eval)\n",
      "             14 LOAD_DEREF               1 (modification)\n",
      "             16 LOAD_CONST               1 ('value')\n",
      "             18 BINARY_SUBSCR\n",
      "             22 CALL                     1\n",
      "             30 RETURN_VALUE\n",
      "\n",
      "Disassembly of <code object <lambda> at 0x0000014830645ED0, file \"c:\\Users\\MartinVölkl-GouyaIns\\OneDrive - Gouya Insights\\Desktop\\qplib\\qplib\\pd_query.py\", line 590>:\n",
      "              0 COPY_FREE_VARS           1\n",
      "\n",
      "590           2 RESUME                   0\n",
      "              4 LOAD_GLOBAL              1 (NULL + eval)\n",
      "             14 LOAD_DEREF               1 (modification)\n",
      "             16 LOAD_CONST               1 ('value')\n",
      "             18 BINARY_SUBSCR\n",
      "             22 CALL                     1\n",
      "             30 RETURN_VALUE\n",
      "\n",
      "Disassembly of __init__:\n",
      "431           0 RESUME                   0\n",
      "\n",
      "432           2 LOAD_GLOBAL              1 (NULL + _check_df)\n",
      "             12 LOAD_FAST                1 (df)\n",
      "             14 CALL                     1\n",
      "             22 POP_TOP\n",
      "\n",
      "433          24 LOAD_FAST                1 (df)\n",
      "             26 LOAD_FAST                0 (self)\n",
      "             28 STORE_ATTR               1 (df)\n",
      "\n",
      "434          38 LOAD_GLOBAL              4 (_operators)\n",
      "             48 LOAD_FAST                0 (self)\n",
      "             50 LOAD_ATTR                2 (df)\n",
      "             70 LOAD_ATTR                6 (qp)\n",
      "             90 STORE_ATTR               2 (_operators)\n",
      "\n",
      "435         100 LOAD_GLOBAL              8 (_modifiers)\n",
      "            110 LOAD_FAST                0 (self)\n",
      "            112 LOAD_ATTR                2 (df)\n",
      "            132 LOAD_ATTR                6 (qp)\n",
      "            152 STORE_ATTR               4 (_modifiers)\n",
      "            162 RETURN_CONST             0 (None)\n",
      "\n",
      "Disassembly of __repr__:\n",
      "438           0 RESUME                   0\n",
      "\n",
      "439           2 LOAD_CONST               1 ('docstring of dataframe accessor pd_object.q():')\n",
      "              4 LOAD_FAST                0 (self)\n",
      "              6 LOAD_ATTR                0 (__doc__)\n",
      "             26 BINARY_OP                0 (+)\n",
      "             30 RETURN_VALUE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import dis\n",
    "from qplib.pd_query import DataFrameQuery\n",
    "\n",
    "dis.dis(DataFrameQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20           0 RESUME                   0\n",
      "\n",
      " 21           2 LOAD_GLOBAL              1 (NULL + str)\n",
      "             12 LOAD_CONST               1 (2)\n",
      "             14 CALL                     1\n",
      "             22 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "    'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "    'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "    'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "    'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "    'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "    'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "    'bp systole': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "    'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "    'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "    'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "    'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "    })\n",
    "\n",
    "\n",
    "def test():\n",
    "    return str(2)\n",
    "\n",
    "dis.dis(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1           0 RESUME                   0\n",
      "\n",
      "  2           2 LOAD_GLOBAL              1 (NULL + str)\n",
      "             12 LOAD_CONST               1 (2)\n",
      "             14 CALL                     1\n",
      "             22 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    return str(2)\n",
    "\n",
    "dis.dis(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
