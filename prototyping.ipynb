{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "import qplib as qp\n",
    "from qplib import log, na, nk, num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:93: UserWarning: registration of accessor <class '__main__.IndexQuery'> under name 'q' for type <class 'pandas.core.indexes.base.Index'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_index_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:223: UserWarning: registration of accessor <class '__main__.SeriesQuery'> under name 'q' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_series_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:349: UserWarning: registration of accessor <class '__main__.DataFrameQuery'> under name 'q' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:1025: UserWarning: registration of accessor <class '__main__.DataFrameQueryInteractiveMode'> under name 'qi' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('qi')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_14808\\3524496744.py:1230: DtypeWarning: Columns (2,3,7,12,16,20,23,47,52,53,61,62,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cards = pd.read_csv('data/cards.csv').format()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataframe qp.util.logs for tracking log entries\n",
      "use qp.log(message, level, source) or qp.log(message) to add log entries\n",
      "logs are saved in qp.util.logs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fc6ab_row0_col0, #T_fc6ab_row0_col1, #T_fc6ab_row0_col2, #T_fc6ab_row0_col3, #T_fc6ab_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fc6ab\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fc6ab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fc6ab_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_fc6ab_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_fc6ab_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_fc6ab_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_fc6ab_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:36:56.638555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e1750b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dd7cf_row0_col0, #T_dd7cf_row0_col1, #T_dd7cf_row0_col2, #T_dd7cf_row0_col3, #T_dd7cf_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dd7cf\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dd7cf_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_dd7cf_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_dd7cf_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_dd7cf_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_dd7cf_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_dd7cf_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:36:58.485038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e646ba40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6edf2_row0_col0, #T_6edf2_row0_col1, #T_6edf2_row0_col2, #T_6edf2_row0_col3, #T_6edf2_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6edf2\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6edf2_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_6edf2_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_6edf2_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_6edf2_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_6edf2_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_6edf2_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:37:02.090504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e640c380>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6069_row0_col0, #T_c6069_row0_col1, #T_c6069_row0_col2, #T_c6069_row0_col3, #T_c6069_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6069\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6069_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_c6069_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_c6069_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_c6069_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_c6069_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_c6069_row0_col4\" class=\"data row0 col4\" >2024-06-28 15:37:02.100506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4e646ba40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb46804a2bf4d90b645d98394855c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d892fe59ded9489dbbf48251e15814a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.pd_util import _check_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "from qplib.pd_util import diff as mv_diff\n",
    "\n",
    "\n",
    "\n",
    "from qplib.types import qp_int, qp_float, qp_num, qp_bool, qp_datetime, qp_date, qp_na, qp_nk, qp_yn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_operators1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'bigger_equal': '>=',\n",
    "    'smaller_equal': '<=',\n",
    "    'bigger': '>',\n",
    "    'smaller': '<',\n",
    "    'strict_equal': '==',\n",
    "    'equal': '=',\n",
    "    'regex_match': '~~',\n",
    "    'regex_search': '~',\n",
    "    'strict_contains': '(())',\n",
    "    'contains': '()',\n",
    "\n",
    "    'lambda_condition': '?',\n",
    "    'lambda_condition_col': 'col?',\n",
    "    })\n",
    "_operators2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'is_str': 'is str',\n",
    "    'is_int': 'is int',\n",
    "    'is_float': 'is float',\n",
    "    'is_num': 'is num',\n",
    "    'is_bool': 'is bool',\n",
    "\n",
    "    'is_datetime': 'is datetime',\n",
    "    'is_date': 'is date',\n",
    "\n",
    "    'is_any': 'is any',\n",
    "    'is_na': 'is na',\n",
    "    'is_nk': 'is nk',\n",
    "    'is_yn': 'is yn',\n",
    "    'is_yes': 'is yes',\n",
    "    'is_no': 'is no',\n",
    "    })\n",
    "_operators = qpDict({**_operators1, **_operators2})\n",
    "_operators_only_df = qpDict({\n",
    "    'lambda_condition_col': _operators['lambda_condition_col'],\n",
    "    })\n",
    "\n",
    "_modifiers1 = qpDict({\n",
    "    #need a value for comparison or modification\n",
    "    'set_x': ['x=', 'x ='],\n",
    "    'set_col': ['col=', 'col ='],\n",
    "    'set_row': ['row=', 'row ='],\n",
    "    'set_col_tags': ['col#=', 'col# =', 'col #=', 'col # ='],\n",
    "    'set_row_tags': ['row#=', 'row# =', 'row #=', 'row # ='],\n",
    "    })\n",
    "_modifiers2 = qpDict({\n",
    "    #these dont need a values for comparison or modification\n",
    "    'to_str': 'to str',\n",
    "    'to_int': 'to int',\n",
    "    'to_float': 'to float',\n",
    "    'to_num': 'to num',\n",
    "    'to_bool': 'to bool',\n",
    "\n",
    "    'to_datetime': 'to datetime',\n",
    "    'to_date': 'to date',\n",
    "\n",
    "    'to_na': 'to na',\n",
    "    'to_nk': 'to nk',\n",
    "    'to_yn': 'to yn',\n",
    "\n",
    "    'get_num': 'get num',\n",
    "    })\n",
    "_modifiers = qpDict({**_modifiers1, **_modifiers2})\n",
    "_modifiers_only_df = qpDict({\n",
    "    'set_col': _modifiers['set_col'],\n",
    "    'set_row': _modifiers['set_row'],\n",
    "    'set_col_tags': _modifiers['set_col_tags'],\n",
    "    'set_row_tags': _modifiers['set_row_tags'],\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_index_accessor('q')\n",
    "class IndexQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Indices.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, idx: pd.Index):\n",
    "        idx.qp._operators = _operators\n",
    "        idx.qp._operators_only_df = _operators_only_df\n",
    "        idx.qp._modifiers = _modifiers\n",
    "        idx.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.idx = idx \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_index(self.idx)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        idx = self.idx\n",
    "        idx.qp = self.idx.qp\n",
    "        idx.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in idx])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter index', 'modify index'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter index':\n",
    "                ast = _parse_expression(idx, expression, 'filter index', verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(idx, condition, _operators, verbosity, index=idx)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                        log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='idx.q', input=idx.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify index':\n",
    "                ast = _parse_expression_modify(idx, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = idx.to_series()\n",
    "                    se.qp = idx.qp\n",
    "                    idx = pd.Index(_apply_modification(se, index_expression, modification, verbosity, index=idx))\n",
    "                    idx.qp = self.idx.qp\n",
    "        \n",
    "\n",
    "\n",
    "        idx_filtered = idx[index_expression]\n",
    "        idx_filtered.qp = idx.qp\n",
    "\n",
    "        return idx_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_series_accessor('q')\n",
    "class SeriesQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data  in pandas Series.\n",
    "\n",
    "    each query consists of 2 string expressions, each of which can be left empty:\n",
    "        1. filter: '=abc', '!=1', 'is int && >0'\n",
    "        2. data modification: 'to num', 'x= str(x)'\n",
    "\n",
    "    eg.: se.q('is str', 'x= \"prefix\" + x')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, se: pd.Series):\n",
    "        se.qp._operators = _operators\n",
    "        se.qp._operators_only_df = _operators_only_df\n",
    "        se.qp._modifiers = _modifiers\n",
    "        se.qp._modifiers_only_df = _modifiers_only_df\n",
    "        self.se = se \n",
    "\n",
    "\n",
    "    #wip\n",
    "    # def check(self):\n",
    "    #     _check_series(self.se)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self, *expressions, verbosity=3):\n",
    "\n",
    "        #setup\n",
    "        se = copy.deepcopy(self.se)\n",
    "        se.qp = self.se.qp\n",
    "        se.qp._input = f\".q{expressions}\"\n",
    "        \n",
    "        index_expression = index_condition = pd.Index([True for i in se])\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['filter series', 'modify series'][i_expression%2]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            if expression_type == 'filter series':\n",
    "                ast = _parse_expression(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for condition in ast['conditions']:\n",
    "                    index_new = _apply_condition(se, condition, _operators, verbosity, series=se)\n",
    "\n",
    "                    index_condition = _update_index(index_condition, index_new, condition['condition_connector'], i=None, verbosity=verbosity)\n",
    "                index_expression = _update_index(index_expression, index_condition, ast['connector'], i=None, verbosity=verbosity)\n",
    "\n",
    "                if index_expression.any() == False and verbosity >= 2:\n",
    "                    log(f'no values fulfill the condition(s) in \"{expression}\"', level='warning', source='se.q', input=se.qp._input)\n",
    "\n",
    "\n",
    "            elif expression_type == 'modify series':\n",
    "                ast = _parse_expression_modify(se, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                    se = _apply_modification(se, index_expression, modification, verbosity, series=se)\n",
    "                    se.qp = self.se.qp\n",
    "\n",
    "\n",
    "        se_filtered = se[index_expression]\n",
    "        se_filtered.qp = se.qp\n",
    "        return se_filtered\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    A custom query language for filtering and modifying data and metadata in pandas DataFrames.\n",
    "\n",
    "    each query consists of 3 string expressions, any of which can be left empty:\n",
    "        1. column filter: '=col1', '!=col2', '()1 // ()2'\n",
    "        2. row filter: 'is date', 'is int && >0', '? len(str(x)) > 5'\n",
    "        3. (meta-)data modification: 'x= str(x)', 'col#= integer column', 'row#= positive'\n",
    "\n",
    "    eg.: df.q('=col1', 'is int && >0', 'row#= positive')\n",
    "\n",
    "    multiple conditions in an expression as well as multiple whole queries can be connected.\n",
    "\n",
    "    Connectors:\n",
    "        &&: the previous conditions AND this new conditions have to apply\n",
    "        //: the previous conditions OR this new conditions have to apply\n",
    "        >>: ignore previous conditions and use these new conditions INSTEAD\n",
    "\n",
    "    Operators:\n",
    "        >: bigger\n",
    "        <: smaller\n",
    "        >=: bigger or equal\n",
    "        <=: smaller or equal\n",
    "        \n",
    "        ~: contains a regex pattern (re.search)\n",
    "        ~~: matches a regex pattern (re.match)\n",
    "\n",
    "        =: equal\n",
    "        ==: strictly equal (case sensitive)\n",
    "\n",
    "        (): contains a string\n",
    "        (()): contains a string (case sensitive)\n",
    "\n",
    "        ?: filter using a python expression (must evaluate to True or False)\n",
    "\n",
    "        is str: is a string\n",
    "        is int: is an integer\n",
    "        is float: is a float\n",
    "        is num: is a number (int or float)\n",
    "        is bool: is a boolean\n",
    "\n",
    "        is date: is a date (quite format lenient but defaults to european formats)\n",
    "        is datetime: is a datetime\n",
    "\n",
    "        is any: matches any value, use to select all\n",
    "        is na: not available data (quite lenient)\n",
    "        is nk: not known data (quite lenient)\n",
    "        is yk: is a yes or no value\n",
    "        is yes: is a yes value\n",
    "        is no: is a no value\n",
    "\n",
    "    Modifiers:\n",
    "        x=: set x to a value\n",
    "        col=: set whole column to a value\n",
    "        row=: set whole row to a value\n",
    "        col#=: tag columns\n",
    "        row#=: tag rows\n",
    "\n",
    "        to str: convert to string\n",
    "        to int: convert to integer\n",
    "        to float: convert to float\n",
    "        to num: convert to number\n",
    "        to bool: convert to boolean\n",
    "\n",
    "        to date: convert to date\n",
    "        to datetime: convert to datetime\n",
    "\n",
    "        to na: convert to not available\n",
    "        to nk: convert to not known\n",
    "        to yn: convert to yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        _check_df(df)\n",
    "        self.df = df\n",
    "        self.df.qp._operators = _operators\n",
    "        self.df.qp._modifiers = _modifiers\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "\n",
    "    def __call__(self,\n",
    "            *expressions,  #string expressions for filtering and modifying data\n",
    "            diff=None,  #[None, 'mix', 'old', 'new', 'new+']\n",
    "            max_cols=200,  #maximum number of columns to display. None: show all\n",
    "            max_rows=20,  #maximum number of rows to display. None: show all\n",
    "            inplace=True,  #make modifications inplace or just return a new dataframe\n",
    "            verbosity=3,  #verbosity level for logging. 0: no logging, 1: errors, 2: warnings, 3: info, 4: debug\n",
    "            **kwargs\n",
    "            ):\n",
    "\n",
    "        ###########################################\n",
    "        #                  setup                  #\n",
    "        ###########################################\n",
    "\n",
    "        #input string for logging\n",
    "        input_str = \".q(\"\n",
    "        for i,expression in enumerate(expressions):\n",
    "            if (i+1)%3 == 1:\n",
    "                input_str += f\"\\n\\t{expression !r},\"\n",
    "            else:\n",
    "                input_str += f\" {expression !r},\"\n",
    "   \n",
    "        if diff is not None:\n",
    "            input_str += f\"\\n\\tdiff='{diff}',\"\n",
    "        if max_cols is not None:\n",
    "            input_str += f\"\\n\\tmax_cols={max_cols},\"\n",
    "        if max_rows is not None:\n",
    "            input_str += f\"\\n\\tmax_rows={max_rows},\"\n",
    "        \n",
    "        input_str += f\"\\n\\tinplace={inplace},\"\n",
    "        input_str += f\"\\n\\tverbosity={verbosity},\"\n",
    "\n",
    "        for kwarg in kwargs:\n",
    "            input_str += f\"\\n\\t{kwarg}='{kwargs[kwarg]}'\"\n",
    "\n",
    "        self.df.qp._input = input_str + \"\\n\\t)\"\n",
    "\n",
    "\n",
    "    \n",
    "        if inplace is False:\n",
    "            df = self.df.copy()\n",
    "        else:\n",
    "            df = self.df\n",
    "            \n",
    "        df.qp = self.df.qp\n",
    "\n",
    "        \n",
    "\n",
    "        #inserting metadata row at the top, sadly a bit hacky\n",
    "        #because there does not seem to be an inplace function for that\n",
    "        if '#' not in df.index:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a row named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata row now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df_old = df.copy()\n",
    "            index_old = df.index\n",
    "            index_new = pd.Index(['#', *index_old])\n",
    "            \n",
    "            df.loc['#'] = ''\n",
    "            df.set_index(index_new, inplace=True)\n",
    "            df.loc[index_old, :] = df_old\n",
    "            df.loc['#'] = ''\n",
    "\n",
    "        #inserting metadata column at the start\n",
    "        if '#' not in df.columns:\n",
    "            if verbosity >= 2:\n",
    "                log(f'a column named \"#\" containing metadata at location 0 is expected but was not found. '\n",
    "                    +'adding metadata column now. its advised to prepare the data with df=df.format().',\n",
    "                    level='warning', source='df.q()')\n",
    "            df.insert(0, '#', '')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        ###########################################\n",
    "        #               run queries               #\n",
    "        ###########################################\n",
    "\n",
    "        cols_filtered = cols_filtered_condition = pd.Index([True for col in df.columns])\n",
    "        rows_filtered = rows_filtered_condition = rows_filtered_col = pd.Index([True for row in df.index])\n",
    "        \n",
    "\n",
    "        for i_expression,expression in enumerate(expressions):\n",
    "            expression_type = ['col', 'row', 'modify'][i_expression%3]\n",
    "            if expression == '':\n",
    "                continue\n",
    "\n",
    "\n",
    "            #filter columns\n",
    "            if expression_type == 'col':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    if condition['by_tag'] == 'row or col metadata':\n",
    "                        cols_filtered_new = _apply_condition(df.loc['#'], condition, _operators, verbosity, df=df)\n",
    "                    else:\n",
    "                        cols_filtered_new = _apply_condition(df.columns, condition, _operators, verbosity, df=df)\n",
    "\n",
    "                    cols_filtered_condition = _update_index(cols_filtered_condition, cols_filtered_new, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                cols_filtered = _update_index(cols_filtered, cols_filtered_condition, ast['connector'], i_expression, verbosity=verbosity)\n",
    "\n",
    "                if cols_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no columns fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            #filter rows\n",
    "            elif expression_type == 'row':\n",
    "                ast = _parse_expression(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for i_condition,condition in enumerate(ast['conditions']):\n",
    "                    for i_col,col in enumerate(df.columns[cols_filtered_condition][1:]):  #ignore metadata column\n",
    "                        if condition['by_tag'] == 'row or col metadata':\n",
    "                            rows_filtered_new = _apply_condition(df['#'], condition, _operators, verbosity, df=df)\n",
    "                        else:\n",
    "                            rows_filtered_new = _apply_condition(df[col], condition, _operators, verbosity, df=df)\n",
    "\n",
    "                        rows_filtered_col = _update_index(rows_filtered_col, rows_filtered_new, condition['which_cols'], i_col, verbosity=verbosity)\n",
    "                    rows_filtered_condition = _update_index(rows_filtered_condition, rows_filtered_col, condition['condition_connector'], i_condition, verbosity=verbosity)\n",
    "                rows_filtered = _update_index(rows_filtered, rows_filtered_condition, ast['connector'], i_expression-1, verbosity=verbosity)\n",
    "\n",
    "                if rows_filtered.any() == False and verbosity >= 2:\n",
    "                    log(f'no rows fulfill the condition(s) in \"{expression}\"', level='warning', source='df.q', input=df.qp._input)\n",
    "\n",
    "\n",
    "\n",
    "            #modify data\n",
    "            elif expression_type == 'modify':\n",
    "                cols_filtered_no_metadata = [col for col in df.columns[cols_filtered] if not col.startswith('#')]\n",
    "                rows_filtered_no_metadata = [row for row in df.index[rows_filtered] if row != '#']\n",
    "\n",
    "                ast = _parse_expression_modify(df, expression, expression_type, verbosity)\n",
    "\n",
    "                for modification in ast['modifications']:\n",
    "                            \n",
    "                    #tag columns\n",
    "                    if modification['modifier'] in _modifiers['set_col_tags']:\n",
    "                        df.loc['#', cols_filtered_no_metadata] = df.loc['#', cols_filtered_no_metadata].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #tag rows\n",
    "                    elif modification['modifier'] in _modifiers['set_row_tags']:\n",
    "                        df.loc[rows_filtered_no_metadata, '#'] = df.loc[rows_filtered_no_metadata, '#'].apply(\n",
    "                            lambda x: eval(modification['value'])\n",
    "                            )\n",
    "                    \n",
    "                    #modify filtered data\n",
    "                    else:\n",
    "                        df.loc[:, :] = _apply_modification_df(df, rows_filtered_no_metadata, cols_filtered_no_metadata, modification, verbosity).loc[:, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################\n",
    "        #            display settings            #\n",
    "        ##########################################\n",
    "   \n",
    "        df_filtered = df.loc[rows_filtered, cols_filtered]\n",
    "        df_filtered.qp = self.df.qp\n",
    "    \n",
    "        if diff is None:\n",
    "\n",
    "            cols_num = len(df.columns[cols_filtered])\n",
    "            rows_num = len(df.index[rows_filtered])\n",
    "\n",
    "            if verbosity >= 2:\n",
    "                if max_cols is not None and max_cols < cols_num:\n",
    "                    log(f'showing {max_cols} out of {cols_num} columns', level='warning', source='df.q', input=df.qp._input)\n",
    "                if max_rows is not None and max_rows < rows_num:\n",
    "                    log(f'showing {max_rows} out of {rows_num} rows', level='warning', source='df.q', input=df.qp._input)\n",
    " \n",
    "            pd.set_option('display.max_columns', max_cols)\n",
    "            pd.set_option('display.max_rows', max_rows)\n",
    "            pd.set_option('display.min_rows', max_rows)\n",
    "\n",
    "            return df_filtered\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            #show difference before and after filtering\n",
    "            result = qp.diff(\n",
    "                df_filtered, self.df, show=diff,\n",
    "                max_cols=max_cols, max_rows=max_rows,\n",
    "                verbosity=verbosity)  \n",
    "            return  result\n",
    "\n",
    "\n",
    "\n",
    "def _parse_expression(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'connector': None,\n",
    "        'conditions': [],\n",
    "        }\n",
    "    \n",
    "    if expression[:2] not in ['&&', '//', '>>']:\n",
    "        expression = '>>' + expression\n",
    "\n",
    "    ast['connector'] = expression[:2]\n",
    "\n",
    "\n",
    "    expressions = re.split('(&&|//|>>)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {'expression': expressions[ind], 'mode': mode}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&', '//', '>>']:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if expressions[ind-1] == '&&':  #and\n",
    "            condition['condition_connector'] = '&&'\n",
    "        elif expressions[ind-1] == '//':  #inclusive or\n",
    "            condition['condition_connector'] = '//'\n",
    "        elif expressions[ind-1] == '>>':  #reset\n",
    "            condition['condition_connector'] = '>>'\n",
    "\n",
    "        \n",
    "        #row conditions also specify in which cols the condition is applied. default: any\n",
    "        if mode == 'row':\n",
    "            if condition_str.startswith('any'):\n",
    "                condition['which_cols'] = 'any'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            elif condition_str.startswith('all'):\n",
    "                condition['which_cols'] = 'all'\n",
    "                condition_str = condition_str[3:].lstrip()\n",
    "            else:\n",
    "                condition['which_cols'] = 'any'\n",
    "\n",
    "\n",
    "        #rows and cols can be filtered by metadata\n",
    "        if condition_str.startswith('#'):\n",
    "            condition['by_tag'] = 'row or col metadata'\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['by_tag'] = False\n",
    "\n",
    "        #wip\n",
    "        # if condition_str.startswith('x#'):\n",
    "        #     condition['by_tag_value'] = 'value metadata'\n",
    "        #     condition_str = condition_str[1:].lstrip()\n",
    "        # else:\n",
    "        #     condition['by_tag_value'] = False\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #should the condition be negated. default: False\n",
    "        if condition_str.startswith('!'):\n",
    "            condition['negate'] = True\n",
    "            condition_str = condition_str[1:].lstrip()\n",
    "        else:\n",
    "            condition['negate'] = False\n",
    "\n",
    "\n",
    "        #operator for condition. default: =\n",
    "        for operator in _operators.values_flat():\n",
    "            if condition_str.startswith(operator):\n",
    "                condition['operator'] = operator\n",
    "                condition_str = condition_str[len(operator):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'operator' not in condition:\n",
    "            if verbosity >= 3:\n",
    "                log(f'no operator found in condition \"{condition_str}\". Using default operator \"=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['operator'] = '='\n",
    "\n",
    "\n",
    "        if mode in ['filter series', 'filter index'] and condition['operator'] in _operators_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "        \n",
    "        if condition['operator'] in _operators2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #value for comparison\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['conditions'].append(condition)\n",
    "\n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "        \n",
    "    return ast\n",
    "\n",
    "def _parse_expression_modify(pd_object, expression, mode, verbosity=3):\n",
    "\n",
    "    ast = {\n",
    "        'expression': expression,\n",
    "        'mode': mode,\n",
    "        'modifications': [],\n",
    "        }\n",
    "    \n",
    "\n",
    "    expressions = re.split('(&&)', expression)\n",
    "    for ind in range(len(expressions)):\n",
    "\n",
    "        condition = {}\n",
    "        condition_str = expressions[ind].strip()\n",
    "\n",
    "        if len(condition_str) == 0 or condition_str in ['&&']:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #modifier to use. default: \"set x:\"\n",
    "        for modifier in _modifiers.values_flat():\n",
    "            if condition_str.startswith(modifier):\n",
    "                condition['modifier'] = modifier\n",
    "                condition_str = condition_str[len(modifier):].lstrip()\n",
    "                break\n",
    "        \n",
    "        if 'modifier' not in condition:\n",
    "            if verbosity > 3:\n",
    "                log(f'no modifier found in condition \"{condition_str}\". Using default modifier \"x=\"',\n",
    "                    level='info', source='_parse_expression', input=pd_object.qp._input)\n",
    "            condition['modifier'] = 'x='\n",
    "\n",
    "        if mode in ['modify series', 'modify index'] and condition['modifier'] in _modifiers_only_df.values_flat():\n",
    "            if verbosity >= 1:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" only works with dataframes. Ignoring condition \"{condition_str}\"',\n",
    "                    level='error', source='_parse_expression', input=pd_object.qp._input)\n",
    "            continue\n",
    "\n",
    "        if condition['modifier'] in _modifiers2.values_flat() and len(condition_str) > 0:\n",
    "            if verbosity >= 2:\n",
    "                modifier_temp = condition['modifier']\n",
    "                log(f'modifier \"{modifier_temp}\" does not need a value for comparison. Ignoring value \"{condition_str}\"',\n",
    "                    level='warning', source='_parse_expression', input=pd_object.qp._input)\n",
    "\n",
    "\n",
    "        #expression used for modification\n",
    "        condition['value'] = condition_str.strip()\n",
    "    \n",
    "        ast['modifications'].append(condition)\n",
    "        \n",
    "    if verbosity >= 4:\n",
    "        display(f'abstract syntax tree for expression \"{expression}\":', ast)\n",
    "    \n",
    "    return ast\n",
    "\n",
    "\n",
    "def _apply_condition(pd_object, condition, operators, verbosity=3, df=None, series=None, index=None):\n",
    "    \"\"\"\n",
    "    filters a pandas object using a query condition\n",
    "    \"\"\"\n",
    "\n",
    "    value = condition['value']\n",
    "\n",
    "    if isinstance(pd_object, pd.Index):\n",
    "        pd_object = pd_object.to_series()\n",
    "\n",
    "    \n",
    "    match condition['operator']:\n",
    "        #numeric comparison\n",
    "        case operators.bigger_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') >= pd.to_numeric(value)\n",
    "        case operators.smaller_equal:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') <= pd.to_numeric(value)\n",
    "        case operators.bigger:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') > pd.to_numeric(value)\n",
    "        case operators.smaller:\n",
    "            filtered = pd.to_numeric(pd_object, errors='coerce') < pd.to_numeric(value)\n",
    "        \n",
    "        \n",
    "        #regex comparison\n",
    "        case operators.regex_match:\n",
    "            filtered = pd_object.astype(str).str.fullmatch(value) \n",
    "        case operators.regex_search:\n",
    "            filtered = pd_object.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "        #string equality comparison\n",
    "        case operators.strict_equal:\n",
    "            filtered = pd_object.astype(str) == value\n",
    "        case operators.equal:\n",
    "            value_lenient = [value]\n",
    "            try:\n",
    "                value_lenient.append(str(float(value)))\n",
    "                value_lenient.append(str(int(float(value))))\n",
    "            except:\n",
    "                value_lenient.append(value.lower())\n",
    "            filtered = pd_object.astype(str).str.lower().isin(value_lenient)\n",
    "        \n",
    "        #substring comparison\n",
    "        case operators.strict_contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=True, regex=False)\n",
    "        case operators.contains:\n",
    "            filtered = pd_object.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "\n",
    "        #lambda function\n",
    "        case operators.lambda_condition:\n",
    "            filtered = pd_object.apply(lambda x, df=df, series=series, index=index, pd=pd, np=np: eval(value))\n",
    "        case operators.lambda_condition_col:\n",
    "            filtered = eval(value, {'col': pd_object, 'df': df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "\n",
    "\n",
    "        #type checks\n",
    "        case operators.is_bool:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, bool))\n",
    "        case operators.is_str:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, str))\n",
    "        case operators.is_int:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, int))\n",
    "        case operators.is_float:\n",
    "            filtered = pd_object.apply(lambda x: isinstance(x, float))\n",
    "        case operators.is_num:\n",
    "            filtered = pd_object.apply(lambda x: qp_num(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_date:\n",
    "            filtered = pd_object.apply(lambda x: qp_date(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_datetime:\n",
    "            filtered = pd_object.apply(lambda x: qp_datetime(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "        case operators.is_any:\n",
    "            filtered = pd_object.apply(lambda x: True)\n",
    "        case operators.is_na:\n",
    "            filtered = pd_object.apply(lambda x: qp_na(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_nk:\n",
    "            filtered = pd_object.apply(lambda x: qp_nk(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yn:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR')) != 'ERROR'\n",
    "        case operators.is_yes:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', yes=1)) == 1\n",
    "        case operators.is_no:\n",
    "            filtered = pd_object.apply(lambda x: qp_yn(x, errors='ERROR', no=0)) == 0\n",
    "\n",
    "        case _:\n",
    "            if verbosity >= 1:\n",
    "                operator_temp = condition['operator']\n",
    "                log(f'operator \"{operator_temp}\" is not implemented', level='error', source='_apply_condition()', input=pd_object.qp._input)\n",
    "            filtered = None\n",
    "\n",
    "\n",
    "    if condition['negate']:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    if condition['mode'] in ['col', 'row']:\n",
    "        filtered.iloc[0] = True  #metadata row/column should always be included\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def _apply_modification(pd_object, indices, modification, verbosity=3, series=None, index=None):\n",
    "    modifiers = pd_object.qp._modifiers\n",
    "\n",
    "    #data modification\n",
    "    if modification['modifier'] in modifiers['set_x']:\n",
    "        pd_object[indices] = pd_object[indices].map(lambda x, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "\n",
    "    #type conversion\n",
    "    elif modification['modifier'] == modifiers['to_str']:\n",
    "        pd_object[indices] = pd_object[indices].map(str)\n",
    "    elif modification['modifier'] == modifiers['to_int']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_int)\n",
    "    elif modification['modifier'] == modifiers['to_float']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_float)\n",
    "    elif modification['modifier'] == modifiers['to_num']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_num)\n",
    "    elif modification['modifier'] == modifiers['to_bool']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_bool)\n",
    "    \n",
    "    elif modification['modifier'] == modifiers['to_date']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_date)\n",
    "    elif modification['modifier'] == modifiers['to_datetime']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_datetime)\n",
    "    elif modification['modifier'] == modifiers['to_na']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_na)\n",
    "    elif modification['modifier'] == modifiers['to_nk']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_nk)\n",
    "    elif modification['modifier'] == modifiers['to_yn']:\n",
    "        pd_object[indices] = pd_object[indices].map(qp_yn)\n",
    "\n",
    "    return pd_object\n",
    "\n",
    "def _apply_modification_df(df, rows, cols, modification, verbosity=3):\n",
    "    modifiers = df.qp._modifiers\n",
    "\n",
    "    if pd.__version__ >= '2.1.0':\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].map(qp_yn)\n",
    "\n",
    "    else:\n",
    "        #data modification\n",
    "        if modification['modifier'] in modifiers['set_x']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']))\n",
    "                \n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_col']:\n",
    "            df.loc[:, cols] = df.loc[:, cols].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=0)\n",
    "\n",
    "        elif modification['modifier'] in modifiers['set_row']:\n",
    "            df.loc[rows, :] = df.loc[rows, :].apply(lambda x, df=df, pd=pd, np=np, qp=qp: eval(modification['value']), axis=1)\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif modification['modifier'] == modifiers['to_str']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(str)\n",
    "        elif modification['modifier'] == modifiers['to_int']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_int)\n",
    "        elif modification['modifier'] == modifiers['to_float']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_float)\n",
    "        elif modification['modifier'] == modifiers['to_num']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_num)\n",
    "        elif modification['modifier'] == modifiers['to_bool']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_bool)\n",
    "        \n",
    "        elif modification['modifier'] == modifiers['to_date']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_date)\n",
    "        elif modification['modifier'] == modifiers['to_datetime']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_datetime)\n",
    "\n",
    "        elif modification['modifier'] == modifiers['to_na']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_na)\n",
    "        elif modification['modifier'] == modifiers['to_nk']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_nk)\n",
    "        elif modification['modifier'] == modifiers['to_yn']:\n",
    "            df.loc[rows, cols] = df.loc[rows, cols].applymap(qp_yn) \n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def _update_index(values, values_new, connector, i, verbosity=3):\n",
    "    if i == 0:\n",
    "        values = values_new\n",
    "    elif connector == '>>':\n",
    "        values = values_new\n",
    "    elif connector in ['&&', 'all']:\n",
    "        values &= values_new\n",
    "    elif connector in ['//', 'any']:\n",
    "        values |= values_new\n",
    "    else:\n",
    "        if verbosity >= 1:\n",
    "            log(f'connector \"{connector}\" is not implemented', level='error', source='_update_index()')\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for df.q() for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self, num_filters=5):\n",
    "        kwargs = {'df': fixed(self.df)}\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #            tab0 queries&diff            #\n",
    "        ###########################################\n",
    "\n",
    "        ui_label_filter_cols = widgets.Label(value='filter columns')\n",
    "        ui_label_filter_rows = widgets.Label(value='filter rows')\n",
    "        ui_label_modify_data = widgets.Label(value='modify data')\n",
    "        ui_expressions = [ui_label_filter_cols, ui_label_filter_rows, ui_label_modify_data]\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(num_filters):\n",
    "            if i == 0:\n",
    "                placeholder_col = '=name'\n",
    "                placeholder_row = '()john'\n",
    "                placeholder_modify = 'x= x.upper() '\n",
    "            elif i == 1:\n",
    "                placeholder_col = '// =age'\n",
    "                placeholder_row = '&& <0 // >120'\n",
    "                placeholder_modify = 'row#= \"implausible age\" '\n",
    "            elif i == 2:\n",
    "                placeholder_col = '// =weight // =height'\n",
    "                placeholder_row = '!is num'\n",
    "                placeholder_modify = 'to num'\n",
    "            else:\n",
    "                placeholder_col = ''\n",
    "                placeholder_row = ''\n",
    "                placeholder_modify = ''\n",
    "            \n",
    "\n",
    "            col = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_col,\n",
    "                options=['=' + col for col in self.df.columns if col != '#'],\n",
    "                )\n",
    "            kwargs[f'col_expression{i}'] = col\n",
    "            ui_expressions.append(col)\n",
    "            \n",
    "            row = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_row,\n",
    "                options=[\n",
    "                    '>0', '<0', '>=0', '<=0',  #numerical comparison\n",
    "                    '=abc', '!=abc', '==AbC', '!==AbC',  #equality checks\n",
    "                    '()abc', '(())AbC',  #substring checks\n",
    "                    '~*a.c', '~~*a.c',  #regex checks\n",
    "                    \n",
    "                    '? len(x) > 3',  #lambda function condition for each value\n",
    "                    'col? col > df[\"age\"]',  #lambda function condition for whole columns\n",
    "\n",
    "                    #type checks\n",
    "                    'is str', 'is int', 'is float', 'is num', 'is bool',\n",
    "                    'is date', 'is datetime',\n",
    "                    'is any', 'is na', 'is nk',\n",
    "                    'is yn', 'is yes', 'is no'\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'row_expression{i}'] = row\n",
    "            ui_expressions.append(row)\n",
    "            \n",
    "            modify = widgets.Combobox(\n",
    "                value='',\n",
    "                placeholder=placeholder_modify,\n",
    "                options=[\n",
    "                    'x= x.upper() ', 'col= df[\"ID\"]', 'row= df.loc[0]',  #change data\n",
    "                    'col#= \"tag\" ', 'col#= x + \"tag\" ', 'row#= \"tag\" ', 'row#= x + \"tag\"',  #change metadata\n",
    "\n",
    "                    #change type\n",
    "                    'to str', 'to int', 'to float', 'to num', 'to bool',\n",
    "                    'to date', 'to datetime',\n",
    "                    'to na', 'to nk', 'to yn',\n",
    "                    ]\n",
    "                )\n",
    "            kwargs[f'modify_expression{i}'] = modify\n",
    "            ui_expressions.append(modify)\n",
    "        \n",
    "\n",
    "        #show differences\n",
    "        ui_diff = widgets.ToggleButtons(\n",
    "            options=[None, 'mix', 'old', 'new', 'new+'],\n",
    "            description='show differences mode:',\n",
    "            tooltips=[\n",
    "                'dont show differences, just show the new (filtered) dataframe.',\n",
    "                'show new (filtered) dataframe plus all the removed (filtered) values from the old dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show old (unfiltered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe but also adds metadata columns with the prefix \"#\". If a value changed, the metadata column contains the old value. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['diff'] = ui_diff\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #              tab1 settings              #\n",
    "        ###########################################\n",
    "\n",
    "        ui_inplace = widgets.ToggleButtons(\n",
    "            options=[True, False],\n",
    "            value=False,\n",
    "            description='make modifications inplace:',\n",
    "            tooltips=[\n",
    "                'make modifications inplace, e.g. change the original dataframe',\n",
    "                'return a new dataframe with the modifications',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['inplace'] = ui_inplace\n",
    "\n",
    "        ui_verbosity = widgets.ToggleButtons(\n",
    "            options=[0, 1, 2, 3, 4],\n",
    "            value=3,\n",
    "            description='verbosity level:',\n",
    "            tooltips=[\n",
    "                'no logging',\n",
    "                'only errors',\n",
    "                'errors and warnings',\n",
    "                'errors, warnings and info',\n",
    "                'errors, warnings, info and debug',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['verbosity'] = ui_verbosity\n",
    "\n",
    "\n",
    "\n",
    "        cols_num = len(self.df.columns)\n",
    "        rows_num = len(self.df.index)\n",
    "        if '#' not in self.df.columns:\n",
    "            cols_num = len(self.df.columns) + 1\n",
    "        if '#' not in self.df.index:\n",
    "            rows_num = len(self.df.index) + 1\n",
    "\n",
    "        ui_max_cols = widgets.IntSlider(\n",
    "            value=200,\n",
    "            min=0,\n",
    "            max=cols_num*2-1,  #*2 because of metadata columns which get added by diff='new+'\n",
    "            description='columns',\n",
    "            )\n",
    "        kwargs['max_cols'] = ui_max_cols\n",
    "\n",
    "        ui_max_rows = widgets.IntSlider(\n",
    "            value=20,\n",
    "            min=0,\n",
    "            max=rows_num,\n",
    "            description='rows',\n",
    "            )\n",
    "        kwargs['max_rows'] = ui_max_rows\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        #                tab2 info                #\n",
    "        ###########################################\n",
    "\n",
    "\n",
    "        ui_gridbox = widgets.GridBox(ui_expressions, layout=widgets.Layout(grid_template_columns=\"repeat(3, 330px)\"))   \n",
    "        tab0 = VBox([ui_gridbox, ui_diff])\n",
    "        tab1 = VBox([ui_inplace, ui_verbosity, HBox([ui_max_cols, ui_max_rows])])\n",
    "        ui_tab = widgets.Tab(\n",
    "            children=[tab0, tab1],\n",
    "            titles=['queries', 'settings'],\n",
    "            )\n",
    "        ui = VBox([ui_tab])\n",
    "        display(ui)\n",
    "\n",
    "\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "\n",
    "        display(out)\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "\n",
    "    df = kwargs.pop('df')\n",
    "    expressions = [val for key, val in kwargs.items() if 'expression' in key]\n",
    "\n",
    "\n",
    "    result = df.q(\n",
    "        *expressions,\n",
    "        diff=kwargs['diff'],\n",
    "        max_cols=kwargs['max_cols'],\n",
    "        max_rows=kwargs['max_rows'],\n",
    "        inplace=kwargs['inplace'],\n",
    "        verbosity=kwargs['verbosity'],\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    display(result)\n",
    "    print('input code: ', df.qp._input)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "df = qp.get_df().format()\n",
    "\n",
    "\n",
    "df.qi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af21f0e21dd7425aba1163fe2f403dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513579024c644827a3f4609f09994a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cards.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         169278 function calls (169224 primitive calls) in 0.420 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 349 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    83233    0.128    0.000    0.186    0.000 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\strings\\object_array.py:144(<lambda>)\n",
      "        2    0.120    0.060    0.306    0.153 {pandas._libs.lib.map_infer_mask}\n",
      "    83234    0.059    0.000    0.059    0.000 {method 'upper' of 'str' objects}\n",
      "        3    0.043    0.014    0.043    0.014 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "        3    0.011    0.004    0.012    0.004 {pandas._libs.lib.maybe_convert_objects}\n",
      "        2    0.011    0.005    0.011    0.005 {built-in method pandas._libs.missing.isnaobj}\n",
      "        2    0.010    0.005    0.010    0.005 {built-in method pandas._libs.lib.ensure_string_array}\n",
      "        4    0.006    0.002    0.008    0.002 C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\cast.py:1544(construct_1d_object_array_from_listlike)\n",
      "        3    0.006    0.002    0.006    0.002 {pandas._libs.lib.infer_dtype}\n",
      "       15    0.003    0.000    0.003    0.000 {built-in method numpy.empty}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x2899c2065d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cProfile, pstats\n",
    "import statistics\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('data/cards.csv').format()\n",
    "\n",
    "cols = [True for col in cards.columns]\n",
    "rows = [True for row in cards.index]\n",
    "times = []\n",
    "\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "cards.q('name', '()a', inplace=True)\n",
    "# print(a)\n",
    "# a = cards.index[rows]\n",
    "# cards.loc[rows, cols]\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n",
    "times.append(stats.total_tt)\n",
    "\n",
    "\n",
    "# print(statistics.mean(times), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "for i in range(100):\n",
    "    cards.q('name', '()a', inplace=True, verbosity=0)\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.20989580000000002 [0.2695525, 0.1782757, 0.1733644, 0.17382249999999996, 0.18152440000000003, 0.1757844, 0.17239650000000006, 0.17846470000000003, 0.2548654000000002, 0.34090750000000003]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.types import qp_date, qp_na\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'cards' not in globals():\n",
    "    cards = pd.read_csv('dat/cards.csv')\n",
    "\n",
    "# cards1 = cards.q('=toughness', '>1 && <4', modify='int(x)+10', inplace=False)\n",
    "\n",
    "# diff(cards1, cards, show='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def qp_int(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return int(float(x))  #float first to handle strings like '1.0'\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to integer.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_float(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to float.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "            \n",
    "def qp_num(x, errors='coerce', na=np.nan):\n",
    "    try:\n",
    "        return pd.to_numeric(x)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to numeric.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns np.nan\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "            \n",
    "def qp_bool(x, errors='coerce', na=None):\n",
    "    if str(x).lower() in ['y', 'yes', 'true', '1', '1.0', 'positive', 'pos']:\n",
    "        return True\n",
    "    elif str(x).lower() in ['n', 'no', 'false', '0', '0.0', 'negative', 'neg']:\n",
    "        return False\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to boolean.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "\n",
    "def qp_date(x, errors='coerce', na=pd.NaT):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '-')\n",
    "    try:\n",
    "        if re.match(r'\\D*(1|2)\\d\\d\\d', x):\n",
    "            return pd.to_datetime(x, dayfirst=False).date()\n",
    "        else:\n",
    "            return pd.to_datetime(x, dayfirst=True).date()\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to date.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaT\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "       \n",
    "def qp_datetime(x, errors='coerce', na=pd.NaT):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '-')\n",
    "    try:\n",
    "        if re.match(r'\\D*(1|2\\d\\d\\d)', x):\n",
    "            return pd.to_datetime(x, dayfirst=False)\n",
    "        else:\n",
    "            return pd.to_datetime(x, dayfirst=True)\n",
    "    except:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to datetime.\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaT\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "\n",
    "def qp_na(x, errors='ignore', na=None):\n",
    "    possible_nas = [\n",
    "        'not available', 'na', 'n/a', 'n.a', 'n.a.', 'na.', 'n.a',\n",
    "        'not a number', 'nan',\n",
    "        'null', 'nil',\n",
    "        'none',\n",
    "        '',\n",
    "        ]\n",
    "    \n",
    "    if pd.isna(x) or str(x).lower() in possible_nas:\n",
    "        return na\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{na}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return None\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_nk(x, errors='ignore', nk='unknown'):\n",
    "    possible_nks = [\n",
    "        'unk', 'unknown', 'not known', 'not known.',\n",
    "        'nk', 'n.k.', 'n.k', 'n/k',\n",
    "        'not specified', 'not specified.',\n",
    "        ]\n",
    "    \n",
    "    if str(x).lower() in possible_nks:\n",
    "        return nk\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{nk}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return None\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "def qp_yn(x, errors='coerce', yes='yes', no='no', na=None):\n",
    "    if str(x).lower() in ['y', 'yes', 'true', '1', '1.0', 'positive', 'pos']:\n",
    "        return yes\n",
    "    elif str(x).lower() in ['n', 'no', 'false', '0', '0.0', 'negative', 'neg']:\n",
    "        return no\n",
    "    else:\n",
    "        match errors:\n",
    "            case 'raise':\n",
    "                raise ValueError(f\"\"\"could not convert \"{x}\" to \"{yes}\" or \"{no}\".\n",
    "                    Error handling:\n",
    "                    errors='ignore': returns the original value\n",
    "                    errors='raise': raises a ValueError\n",
    "                    errors='coerce': returns NaN\n",
    "                    errors=<any other value>: returns <any other value>\n",
    "                    \"\"\")\n",
    "            case 'ignore':\n",
    "                return x\n",
    "            case 'coerce':\n",
    "                return na\n",
    "            case _:\n",
    "                return errors\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"123,456.789\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mlib.pyx:2368\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"123,456.789\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#assign resulting substring to a\u001b[39;00m\n\u001b[0;32m      4\u001b[0m a \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+([,.]\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123,456.789 0123\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m456_789a4b5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\tools\\numeric.py:222\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    220\u001b[0m coerce_numeric \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     values, new_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]  # noqa: E501\u001b[39;49;00m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mlib.pyx:2410\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"123,456.789\" at position 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_789']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the regex pattern to match a sequence of numbers allowing for different kinds of separators\n",
    "pattern = r\"\\d+([,.\\s_]\\d+)*\"\n",
    "\n",
    "# Example string to match against\n",
    "example_string = \"123,456.789 0123\\t456_789\"\n",
    "\n",
    "# Perform the search\n",
    "matches = re.findall(pattern, example_string)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bashlike\" wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dataframe qp.util.logs for tracking log entries\n",
      "use qp.log(message, level, source) or qp.log(message) to add log entries\n",
      "logs are saved in qp.util.logs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5460c_row0_col0, #T_5460c_row0_col1, #T_5460c_row0_col2, #T_5460c_row0_col3, #T_5460c_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5460c\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5460c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5460c_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_5460c_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_5460c_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_5460c_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_5460c_row0_col4\" class=\"data row0 col4\" >2024-07-04 16:45:06.353200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x270b3733620>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7cb9_row0_col0, #T_f7cb9_row0_col1, #T_f7cb9_row0_col2, #T_f7cb9_row0_col3, #T_f7cb9_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7cb9\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7cb9_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_f7cb9_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_f7cb9_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_f7cb9_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_f7cb9_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_f7cb9_row0_col4\" class=\"data row0 col4\" >2024-07-04 16:45:07.875228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x270b5d6a900>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bc5b7bf6a14b3393231c719c542948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(GridBox(children=(Label(value='filter columns'), Label(value='filt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba56ec4fc5141c08de76f4b7d5aa500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dis\n",
    "import qplib as qp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = qp.get_df().format()\n",
    "\n",
    "df.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5ee32_row0_col0, #T_5ee32_row0_col1, #T_5ee32_row0_col2, #T_5ee32_row0_col3, #T_5ee32_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5ee32\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5ee32_level0_row0\" class=\"row_heading level0 row0\" >87</th>\n",
       "      <td id=\"T_5ee32_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_5ee32_row0_col1\" class=\"data row0 col1\" >striping column headers of leading and trailing whitespace, replacing \"//\" with \"/ /\", \"&&\" with \"& &\" and \">>\" with \"> >\"</td>\n",
       "      <td id=\"T_5ee32_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_5ee32_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_5ee32_row0_col4\" class=\"data row0 col4\" >2024-07-04 16:52:33.374622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x270b7629f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2963c_row0_col0, #T_2963c_row0_col1, #T_2963c_row0_col2, #T_2963c_row0_col3, #T_2963c_row0_col4 {\n",
       "  background-color: #59A859;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2963c\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2963c_level0_row0\" class=\"row_heading level0 row0\" >88</th>\n",
       "      <td id=\"T_2963c_row0_col0\" class=\"data row0 col0\" >info</td>\n",
       "      <td id=\"T_2963c_row0_col1\" class=\"data row0 col1\" >adding metadata row and column</td>\n",
       "      <td id=\"T_2963c_row0_col2\" class=\"data row0 col2\" >qp.df.format()</td>\n",
       "      <td id=\"T_2963c_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_2963c_row0_col4\" class=\"data row0 col4\" >2024-07-04 16:52:33.386517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x270b762a8a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MartinVölkl-GouyaIns\\Gouya Insights\\Data Management GoIn - Dokumente\\08_Python\\git_test\\qplib\\qplib\\types.py:97: UserWarning: Parsing dates in %m-%d-%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, dayfirst=True).date()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>date of birth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp systole</th>\n",
       "      <th>bp diastole</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>10001</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>170</td>\n",
       "      <td>70.2</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>10kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>10002</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>1990-09-14</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>175.5cm</td>\n",
       "      <td>68</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>Highe</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>10003</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>1985-08-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>72.5lb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>15 mg once a day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>20001</td>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>1980-04-06</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>280</td>\n",
       "      <td>na</td>\n",
       "      <td>140</td>\n",
       "      <td>90mmHg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>no</td>\n",
       "      <td>20mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>20002</td>\n",
       "      <td>Eva White</td>\n",
       "      <td>2007-11-05</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>135mmhg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>yes</td>\n",
       "      <td>20 Mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>20003</td>\n",
       "      <td>Frank Miller</td>\n",
       "      <td>1983-06-30</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>185</td>\n",
       "      <td>75kg</td>\n",
       "      <td>125</td>\n",
       "      <td>75</td>\n",
       "      <td>High</td>\n",
       "      <td>yes</td>\n",
       "      <td>25g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>30001</td>\n",
       "      <td>Grace Taylor</td>\n",
       "      <td>1975-05-28</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>30002</td>\n",
       "      <td>Harry Clark</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ft 1in</td>\n",
       "      <td>80.3</td>\n",
       "      <td>122</td>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>30003</td>\n",
       "      <td>Ivy Green</td>\n",
       "      <td>1955-01-09</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-10</td>\n",
       "      <td>130lbs</td>\n",
       "      <td></td>\n",
       "      <td>95</td>\n",
       "      <td>high</td>\n",
       "      <td>None</td>\n",
       "      <td>30 MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>30004</td>\n",
       "      <td>Jack Williams</td>\n",
       "      <td>1950-09-10</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>30005</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1945-10-11</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>200</td>\n",
       "      <td>-65</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>yes</td>\n",
       "      <td>40ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #     ID           name date of birth   age gender   height  weight  \\\n",
       "#                                                                        \n",
       "0     10001       John Doe    1995-01-02  None      M      170    70.2   \n",
       "1     10002     Jane Smith    1990-09-14    30      F  175.5cm      68   \n",
       "2     10003  Alice Johnson    1985-08-23   NaN      F     None  72.5lb   \n",
       "3     20001      Bob Brown    1980-04-06  None      M      280      na   \n",
       "4     20002      Eva White    2007-11-05  40.0  Other      NaN           \n",
       "5     20003   Frank Miller    1983-06-30  None      M      185    75kg   \n",
       "6     30001   Grace Taylor    1975-05-28  None      F        1    None   \n",
       "7     30002    Harry Clark           NaT  None    NaN  6ft 1in    80.3   \n",
       "8     30003      Ivy Green    1955-01-09         None      -10  130lbs   \n",
       "9     30004  Jack Williams    1950-09-10  None      M               82   \n",
       "10    30005       John Doe    1945-10-11    35      F      200     -65   \n",
       "\n",
       "   bp systole bp diastole cholesterol diabetes              dose  \n",
       "#                                                                 \n",
       "0          20          80      Normal       no              10kg  \n",
       "1         130          85       Highe      yes               NaN  \n",
       "2         NaN         nan         NaN     None  15 mg once a day  \n",
       "3         140      90mmHg        GOOD       no              20mg  \n",
       "4     135mmhg         NaN        n.a.      yes             20 Mg  \n",
       "5         125          75        High      yes               25g  \n",
       "6         NAN         NaN      Normal       no               NaN  \n",
       "7         122        None         n/a     None              None  \n",
       "8                      95        high     None             30 MG  \n",
       "9         130           0                   no                35  \n",
       "10         45         NaN      Normal      yes              40ml  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qplib as qp\n",
    "\n",
    "df = qp.get_df().format()\n",
    "\n",
    "df.q(\n",
    "\t'=name',\n",
    "\t\t'is any',\n",
    "\t\t\t'x = x.title()',\n",
    "\t'=date of birth',\n",
    "\t\t'is any',\n",
    "\t\t\t'to date',\n",
    "\t'=age',\n",
    "\t\t'!is num // <0',\n",
    "\t\t\t'x=None',\n",
    "\t'=gender',\n",
    "\t\t\"? str(x).lower()  in  ['m', 'male', 'mal']\",\n",
    "\t\t\t'x = \"M\"',\n",
    "    '=gender',\n",
    "\t\t\"? str(x).lower()  in  ['f', 'female', 'ff']\",\n",
    "\t\t\t'x = \"F\"',\n",
    "    '=diabetes',\n",
    "\t\t'is any',\n",
    "\t\t\t'to yn',\n",
    "\t'is any',\n",
    "\t\t'is any',\n",
    "\t\t\t'',\n",
    "\tdiff=None,\n",
    "\tinplace=False,\n",
    "\tverbosity=3,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
